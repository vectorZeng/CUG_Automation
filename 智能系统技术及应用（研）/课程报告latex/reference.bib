@book{sutton2018reinforcement,
  title        = {Reinforcement Learning: An Introduction},
  author       = {Sutton, Richard S. and Barto, Andrew G.},
  year         = {2018},
  publisher    = {MIT Press},
  address      = {Cambridge, MA},
  edition      = {2},
}

@article{levine2018learning,
  title        = {Learning Dexterous Manipulation Skills for Real-World Robots},
  author       = {Levine, Sergey and Pastor, Peter and Krizhevsky, Alex and Quillen, Deirdre},
  journal      = {International Journal of Robotics Research},
  volume       = {37},
  number       = {1},
  pages        = {3--20},
  year         = {2018},
}

@article{li2018deep,
  title        = {Deep Reinforcement Learning: An Overview},
  author       = {Li, Yuxi},
  journal      = {arXiv preprint arXiv:1701.07274},
  year         = {2018},
}

@book{kajita2014introduction,
  title        = {Introduction to Humanoid Robotics},
  author       = {Kajita, Shuuji and Hirukawa, Hirohisa and Harada, Kensuke and Yokoi, Kazuhito},
  publisher    = {Springer},
  address      = {Berlin},
  year         = {2014},
}

@article{grimes2019model,
  title        = {Model-Based and Model-Free Reinforcement Learning for Robotic Manipulation: A Survey},
  author       = {Grimes, Daniel and others},
  journal      = {Robotics and Autonomous Systems},
  volume       = {122},
  pages        = {103289},
  year         = {2019},
}

@article{mnih2015human,
  title        = {Human-Level Control Through Deep Reinforcement Learning},
  author       = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and others},
  journal      = {Nature},
  volume       = {518},
  number       = {7540},
  pages        = {529--533},
  year         = {2015},
}

@article{lillicrap2015continuous,
  title        = {Continuous Control with Deep Reinforcement Learning},
  author       = {Lillicrap, Timothy P. and others},
  journal      = {arXiv preprint arXiv:1509.02971},
  year         = {2015},
}

@inproceedings{schulman2017proximal,
  title        = {Proximal Policy Optimization Algorithms},
  author       = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and others},
  booktitle    = {Proceedings of the 34th International Conference on Machine Learning},
  year         = {2017},
}

@article{haarnoja2018soft,
  title        = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author       = {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal      = {Proceedings of the 35th International Conference on Machine Learning},
  year         = {2018},
}

@phdthesis{watkins1992q,
  title        = {Q-Learning},
  author       = {Watkins, Christopher J. C. H.},
  school       = {University of Cambridge},
  year         = {1992},
}

@inproceedings{sutton2000policy,
  title        = {Policy Gradient Methods for Reinforcement Learning with Function Approximation},
  author       = {Sutton, Richard S. and McAllester, David and Singh, Satinder and Mansour, Yishay},
  booktitle    = {Proceedings of the 13th International Conference on Neural Information Processing Systems},
  pages        = {1057--1063},
  year         = {2000},
}

@inproceedings{silver2014deterministic,
  title        = {Deterministic Policy Gradient Algorithms},
  author       = {Silver, David and Lever, Guy and Heess, Nicolas and others},
  booktitle    = {Proceedings of the 31st International Conference on Machine Learning},
  pages        = {387--395},
  year         = {2014},
}

@article{konda2000actor,
  title        = {Actor-Critic Algorithms},
  author       = {Konda, Vijay R. and Tsitsiklis, John N.},
  journal      = {Advances in Neural Information Processing Systems},
  volume       = {12},
  pages        = {1008--1014},
  year         = {2000},
}

@article{salimans2017evolution,
  title        = {Evolution Strategies as a Scalable Alternative to Reinforcement Learning},
  author       = {Salimans, Tim and Ho, Jonathan and Chen, Xi and Sidor, Szymon and Sutskever, Ilya},
  journal      = {arXiv preprint arXiv:1703.03864},
  year         = {2017},
}

@article{beyer2002evolution,
  title        = {Evolution Strategies: A Comprehensive Introduction},
  author       = {Beyer, Hans-Georg and Schwefel, Hans-Paul},
  journal      = {Natural Computing},
  volume       = {1},
  number       = {1},
  pages        = {3--52},
  year         = {2002},
}

@inproceedings{hansen2001completely,
  title        = {Completely Derandomized Self-Adaptation in Evolution Strategies},
  author       = {Hansen, Nikolaus and Ostermeier, Andreas},
  booktitle    = {Evolutionary Computation},
  volume       = {9},
  number       = {2},
  pages        = {159--195},
  year         = {2001},
}

@article{heess2017emergence,
  title        = {Emergence of Locomotion Behaviours in Rich Environments},
  author       = {Heess, Nicolas and others},
  journal      = {arXiv preprint arXiv:1707.02286},
  year         = {2017},
}

@inproceedings{hornby2000evolving,
  title        = {Evolving Biped Locomotion Using Both Genetic Algorithms and Genetic Programming},
  author       = {Hornby, Gregory S. and Takamura, Shuichi and Yokono, Junji and Hanagata, Okuno and Fujita, Masayuki},
  booktitle    = {Proceedings of the 2000 IEEE International Conference on Robotics and Automation},
  pages        = {2030--2037},
  year         = {2000},
}

@article{reher2020dynamic,
  title        = {Dynamic Locomotion for Passive-Ankle Biped Robots and Humanoids Using Whole-Body Locomotion Control},
  author       = {Reher, Jason and Rotella, Nicholas and others},
  journal      = {The International Journal of Robotics Research},
  volume       = {39},
  number       = {9},
  pages        = {1085--1120},
  year         = {2020},
}

@inproceedings{tobin2017domain,
  title        = {Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World},
  author       = {Tobin, Josh and Fong, Rachel and Ray, Alex and Schneider, Jonas and Zaremba, Wojciech and Abbeel, Pieter},
  booktitle    = {2017 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages        = {23--30},
  year         = {2017},
}

@article{peng2018sim,
  title        = {Sim-to-Real Transfer of Robotic Control with Dynamics Randomization},
  author       = {Peng, Xue Bin and Andrychowicz, Marcin and Zaremba, Wojciech and Abbeel, Pieter},
  journal      = {2018 IEEE International Conference on Robotics and Automation},
  pages        = {3803--3810},
  year         = {2018},
}

@inproceedings{conti2018improving,
  title        = {Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents},
  author       = {Conti, Edoardo and Madhavan, Vashisht and Petroski Such, Felipe and Lehman, Joel and Stanley, Kenneth O. and Clune, Jeff},
  booktitle    = {Advances in Neural Information Processing Systems},
  volume       = {31},
  year         = {2018},
}

@article{wierstra2014natural,
  title        = {Natural Evolution Strategies},
  author       = {Wierstra, Daan and Schaul, Tom and Peters, Jan and Schmidhuber, J\"urgen},
  journal      = {Journal of Machine Learning Research},
  volume       = {15},
  number       = {1},
  pages        = {949--980},
  year         = {2014},
}

@inproceedings{kolter2010learning,
  title        = {Learning to Walk via Memory-Based Control},
  author       = {Kolter, J. Zico and Ng, Andrew Y.},
  booktitle    = {Robotics: Science and Systems},
  year         = {2010},
}

@article{li2019reinforcement,
  title        = {Reinforcement Learning-Based Bipedal Locomotion: A Survey},
  author       = {Li, Bo and others},
  journal      = {Robotics and Autonomous Systems},
  volume       = {119},
  pages        = {1--12},
  year         = {2019},
}

@article{chebotar2019closing,
  title        = {Closing the Sim-to-Real Loop: Adapting Simulation Randomization with Real World Experience},
  author       = {Chebotar, Yevgen and others},
  journal      = {2019 International Conference on Robotics and Automation},
  pages        = {8973--8979},
  year         = {2019},
}

@article{zhao2019sim,
  title        = {Sim-to-Real Transfer in Deep Reinforcement Learning for Robotics: A Survey},
  author       = {Zhao, Rui and others},
  journal      = {arXiv preprint arXiv:1907.04707},
  year         = {2019},
}

@article{zhao2020robust,
  title        = {Robust Reinforcement Learning for Continuous Control with Model Misspecification},
  author       = {Zhao, Jinliang and others},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  volume       = {31},
  number       = {10},
  pages        = {3894--3907},
  year         = {2020},
}

@article{khadka2018evolution,
  title        = {Evolutionary Reinforcement Learning},
  author       = {Khadka, Shauharda and Tumer, Kagan},
  journal      = {arXiv preprint arXiv:1805.07917},
  year         = {2018},
}

@article{parker2020effective,
  title        = {Effective Use of Evolutionary Strategies for Continuous Control with Deep Reinforcement Learning},
  author       = {Parker-Holder, Jack and others},
  journal      = {arXiv preprint arXiv:2003.01302},
  year         = {2020},
}

@misc{mathworks_biped,
  title        = {Train Biped Robot to Walk Using Evolutionary Strategy},
  howpublished = {\url{https://ww2.mathworks.cn/help/reinforcement-learning/ug/train-biped-robot-to-walk-using-evolutionary-strategy.html}},
  note         = {Accessed: 2025-11-28},
  year         = {2023},
}

@misc{mathworks_video,
  title        = {Reinforcement Learning, Part 4: The Walking Robot Problem},
  howpublished = {\url{https://ww2.mathworks.cn/videos/reinforcement-learning-part-4-the-walking-robot-problem-1557482052319.html}},
  note         = {Accessed: 2025-11-28},
  year         = {2020},
}