@techreport{ISO10218-1:2025,
  author = {{International Organization for Standardization (ISO)}},
  institution = {ISO},
  title = {Robotics — Safety requirements — Part 1: Industrial robots},
  type = {Technical Specification},
  number = {ISO 10218-1:2025},
  year = {2025},
  url = {https://www.iso.org/standard/73933.html},
}

@inproceedings{song2025robospatial,
  title={Robospatial: Teaching spatial understanding to 2d and 3d vision-language models for robotics},
  author={Song, Chan Hee and Blukis, Valts and Tremblay, Jonathan and Tyree, Stephen and Su, Yu and Birchfield, Stan},
  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
  pages={15768--15780},
  year={2025}
}

@article{cheng2025pointarena,
  title={PointArena: Probing Multimodal Grounding Through Language-Guided Pointing},
  author={Cheng, Long and Duan, Jiafei and Wang, Yi Ru and Fang, Haoquan and Li, Boyang and Huang, Yushan and Wang, Elvis and Eftekhar, Ainaz and Lee, Jason and Yuan, Wentao and others},
  journal={arXiv preprint arXiv:2505.09990},
  year={2025}
}

@book{reason2016managing,
  title={Managing the risks of organizational accidents},
  author={Reason, James},
  year={2016},
  publisher={Routledge}
}

@article{comanici2025gemini,
  title={Gemini 2.5: Pushing the frontier with advanced reasoning, multimodality, long context, and next generation agentic capabilities},
  author={Comanici, Gheorghe and Bieber, Eric and Schaekermann, Mike and Pasupat, Ice and Sachdeva, Noveen and Dhillon, Inderjit and Blistein, Marcel and Ram, Ori and Zhang, Dan and Rosen, Evan and others},
  journal={arXiv preprint arXiv:2507.06261},
  year={2025}
}
@techreport{ISO_TS_15066_2016,
  author = {{International Organization for Standardization (ISO)}},
  title = {Robots and robotic devices -- Collaborative robots},
  institution = {ISO},
  type = {Technical Specification},
  number = {ISO/TS 15066:2016},
  year = {2016},
  address = {Geneva, Switzerland}
}

@article{du2023vision,
  title={Vision-language models as success detectors},
  author={Du, Yuqing and Konyushkova, Ksenia and Denil, Misha and Raju, Akhil and Landon, Jessica and Hill, Felix and De Freitas, Nando and Cabi, Serkan},
  journal={arXiv preprint arXiv:2303.07280},
  year={2023}
}

@article{rocamonde2023vision,

  title={Vision-Language Models are Zero-Shot Reward Models for Reinforcement Learning},

  author={Rocamonde, Juan and Montesinos, Victoriano and Nava, Elvis and Perez, Ethan and Lindner, David},

  journal={arXiv preprint arXiv:2310.12921},

  year={2023}

}

@misc{ma2024generative,
      title={Vision Language Models are In-Context Value Learners}, 
      author={Yecheng Jason Ma and Joey Hejna and Ayzaan Wahid and Chuyuan Fu and Dhruv Shah and Jacky Liang and Zhuo Xu and Sean Kirmani and Peng Xu and Danny Driess and Ted Xiao and Jonathan Tompson and Osbert Bastani and Dinesh Jayaraman and Wenhao Yu and Tingnan Zhang and Dorsa Sadigh and Fei Xia},
      year={2024},
      eprint={2411.04549},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2411.04549}, 
}

@article{miller2024adding,
  title={Adding error bars to evals: A statistical approach to language model evaluations},
  author={Miller, Evan},
  journal={arXiv preprint arXiv:2411.00640},
  year={2024}
}

@misc{tong2024cambrian1,
      title={Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs},
      author={Shengbang Tong and Ellis Brown and Penghao Wu and Sanghyun Woo and Manoj Middepogu and Sai Charitha Akula and Jihan Yang and Shusheng Yang and Adithya Iyer and Xichen Pan and Austin Wang and Rob Fergus and Yann LeCun and Saining Xie},
      year={2024},
      eprint={2406.16860},
}
      

@inproceedings{dasari2021rb2,
  title={RB2: Robotic Manipulation Benchmarking with a Twist},
  author={Dasari, Sudeep and Wang, Jianren and Hong, Joyce and Bahl, Shikhar and Lin, Yixin and Wang, Austin S and Thankaraj, Abitha and Chahal, Karanbir Singh and Calli, Berk and Gupta, Saurabh and others},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
  year={2021}
}

@inproceedings{
dwibedi2024flexcap,
title={Flex{C}ap: Describe Anything in Images in Controllable Detail},
author={Debidatta Dwibedi and Vidhi Jain and Jonathan Tompson and Andrew Zisserman and Yusuf Aytar},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=P5dEZeECGu}
}

@misc{google_sustainability,
  author = {Google},
  title = {Our Goals for Sustainable Operations - Google Sustainability},
  url = {https://sustainability.google/operating-sustainably/},
  urldate = {2025-02-12},
  month = feb,
  year = {2025},
  note = {Last updated February 6, 2025}
}

@misc{RealworldQA_huggingface,
  title = {{RealworldQA: a dataset of real-world questions from the XAI-Bench suite}},
  author = {XAI-org},
  howpublished = {\url{https://huggingface.co/datasets/xai-org/RealworldQA}},
  year = {2024}
}

@misc{ragusa2022meccano,
title={MECCANO: A Multimodal Egocentric Dataset for Humans Behavior Understanding in the Industrial-like Domain},
author={Francesco Ragusa and Antonino Furnari and Giovanni Maria Farinella},
year={2022},
eprint={2209.08691},
archivePrefix={arXiv},
primaryClass={cs.CV}
}

@inproceedings{ragusa2021meccano,
  title = {The MECCANO Dataset: Understanding Human-Object Interactions from Egocentric Videos in an Industrial-like Domain},
  author = {Francesco Ragusa and Antonino Furnari and Salvatore Livatino and Giovanni Maria Farinella},
  year = {2021},
  eprint = {2010.05654},
  booktitle = {IEEE Winter Conference on Application of Computer Vision (WACV)}
}

@inproceedings{ramanathan2023paco,
  title={Paco: Parts and attributes of common objects},
  author={Ramanathan, Vignesh and Kalia, Anmol and Petrovic, Vladan and Wen, Yi and Zheng, Baixue and Guo, Baishan and Wang, Rui and Marquez, Aaron and Kovvuri, Rama and Kadian, Abhishek and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7141--7151},
  year={2023}
}

@article{deitke2024molmo,
  title={Molmo and pixmo: Open weights and open data for state-of-the-art multimodal models},
  author={Deitke, Matt and Clark, Christopher and Lee, Sangho and Tripathi, Rohun and Yang, Yue and Park, Jae Sung and Salehi, Mohammadreza and Muennighoff, Niklas and Lo, Kyle and Soldaini, Luca and others},
  journal={arXiv preprint arXiv:2409.17146},
  year={2024}
}

@inproceedings{vecerik2024robotap,
  title={Robotap: Tracking arbitrary points for few-shot visual imitation},
  author={Vecerik, Mel and Doersch, Carl and Yang, Yi and Davchev, Todor and Aytar, Yusuf and Zhou, Guangyao and Hadsell, Raia and Agapito, Lourdes and Scholz, Jon},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={5397--5403},
  year={2024},
  organization={IEEE}
}

@article{li2025hamster,
  title={HAMSTER: Hierarchical Action Models For Open-World Robot Manipulation},
  author={Li, Yi and Deng, Yuquan and Zhang, Jesse and Jang, Joel and Memme, Marius and Yu, Raymond and Garrett, Caelan Reed and Ramos, Fabio and Fox, Dieter and Li, Anqi and others},
  journal={arXiv preprint arXiv:2502.05485},
  year={2025}
}

@inproceedings{song2015sun,
  title={{SUN RGB-D}: A {RGB-D} scene understanding benchmark suite},
  author={Song, Shuran and Lichtenberg, Samuel P and Xiao, Jianxiong},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={567--576},
  year={2015}
}

@inproceedings{fu2024blink,
  title={{BLINK}: Multimodal large language models can see but not perceive},
  author={Fu, Xingyu and Hu, Yushi and Li, Bangzheng and Feng, Yu and Wang, Haoyu and Lin, Xudong and Roth, Dan and Smith, Noah A and Ma, Wei-Chiu and Krishna, Ranjay},
  booktitle={European Conference on Computer Vision},
  pages={148--166},
  year={2024},
  organization={Springer}
}

@inproceedings{manzini2024,
author = {Manzini, Arianna and Keeling, Geoff and Marchal, Nahema and McKee, Kevin R. and Rieser, Verena and Gabriel, Iason},
title = {Should Users Trust Advanced AI Assistants? Justified Trust As a Function of Competence and Alignment},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658964},
doi = {10.1145/3630106.3658964},
abstract = {As AI assistants become increasingly sophisticated and deeply integrated into our lives, questions of trust rise to the forefront. In this paper, we build on philosophical studies of trust to investigate when user trust in AI assistants is justified. By moving beyond a focus on the technical artefact in isolation, we consider the broader societal system in which AI assistants are developed and deployed. We conceptualise user trust in AI assistants as encompassing two main targets, namely AI assistants and their developers. We argue that – as AI assistants become more human like and exhibit increased agency – discerning when user trust is justified requires consideration not only of competence, on the part of AI assistants and their developers, but also alignment between the competing interests, values or incentives of AI assistants, developers and users. To help users understand if and when their trust in the competence and alignment of AI assistants and developers is justified, we propose a sociotechnical approach that requires evidence to be collected at three levels: AI assistant design, organisational practices and third-party governance. Taken together, these measures can help harness the transformative potential of AI assistants while also ensuring their operation is ethical and value aligned.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1174–1186},
numpages = {13},
keywords = {AI assistants, alignment, ethics, governance, philosophy, sociotechnical systems, trust, trustworthy},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@misc{hao2019,
  title = {Self-driving cars may be more likely to hit you if you have dark skin},
  author = {Hao, Karen},
  howpublished = {MIT Technology Review},
  year = {2019},
  month = {Mar}, 
  day = {1}, 
  url = {https://www.technologyreview.com/2019/03/01/136808/self-driving-cars-are-coming-but-accidents-may-not-be-evenly-distributed/},
  note = {Accessed: 2025-02-05}
}

@misc{henley2022,
  title = {Chess robot grabs and breaks finger of seven-year-old opponent},
  author = {The Guardian},
  author = {Henley, Jon},
  year = {2022},
  month = {Jul},
  day = {24},
  url = {https://www.theguardian.com/sport/2022/jul/24/chess-robot-grabs-and-breaks-finger-of-seven-year-old-opponent-moscow},
  note = {Accessed: 2025-02-05}
}

@ARTICLE{su2023,
AUTHOR={Su, Hang  and Qi, Wen  and Chen, Jiahao  and Yang, Chenguang  and Sandoval, Juan  and Laribi, Med Amine },
TITLE={Recent advancements in multimodal human–robot interaction},
JOURNAL={Frontiers in Neurorobotics},
VOLUME={17},
YEAR={2023},
URL={https://www.frontiersin.org/journals/neurorobotics/articles/10.3389/fnbot.2023.1084000},
DOI={10.3389/fnbot.2023.1084000},
ISSN={1662-5218},
ABSTRACT={<p>Robotics have advanced significantly over the years, and human–robot interaction (HRI) is now playing an important role in delivering the best user experience, cutting down on laborious tasks, and raising public acceptance of robots. New HRI approaches are necessary to promote the evolution of robots, with a more natural and flexible interaction manner clearly the most crucial. As a newly emerging approach to HRI, multimodal HRI is a method for individuals to communicate with a robot using various modalities, including voice, image, text, eye movement, and touch, as well as bio-signals like EEG and ECG. It is a broad field closely related to cognitive science, ergonomics, multimedia technology, and virtual reality, with numerous applications springing up each year. However, little research has been done to summarize the current development and future trend of HRI. To this end, this paper systematically reviews the state of the art of multimodal HRI on its applications by summing up the latest research articles relevant to this field. Moreover, the research development in terms of the input signal and the output signal is also covered in this manuscript.</p>}}

@misc{sellafield2023,
  title = {Sellafield robots leading an evolution in nuclear decommissioning},
  howpublished = {Website},
  author = {{Sellafield Ltd}},
  year = {2023},
  url = {https://www.gov.uk/government/news/sellafield-robots-leading-an-evolution-in-nuclear-decommissioning},
  note = {Accessed: 2025-02-05}
}

@article{choux2024,
title = {To shred or to disassemble – A techno-economic assessment of automated disassembly vs. shredding in lithium-ion battery module recycling},
journal = {Resources, Conservation and Recycling},
volume = {203},
pages = {107430},
year = {2024},
issn = {0921-3449},
doi = {https://doi.org/10.1016/j.resconrec.2024.107430},
url = {https://www.sciencedirect.com/science/article/pii/S0921344924000247},
author = {Martin Choux and Simon Waldemar Pripp and Frode Kvalnes and Magnus Hellström},
keywords = {Lithium-ion battery, Robotic disassembly, Techno-economic assessment, Battery recycling},
abstract = {The global adoption of electric vehicles (EVs) is driving a surge in the use of lithium-ion batteries (LIBs), creating an urgent need for sophisticated recycling techniques to recover valuable materials and manage waste. Particularly, automating the laborintensive disassembly process is critical for scaling up recycling efforts. This study provides a techno-economic evaluation of a robotic line for disassembling EV LIB modules, exploring whether it's more profitable to extend automation to the cell level. Three different EV modules are examined, and several scenarios are proposed, showing that investments in robotic disassembly could be financially sound, particularly with the anticipated rise in end-of-life EV LIBs. The key to profitability lies in disassembling to the cell level, which enables the recovery of more valuable materials and reduces downstream processing requirements. This research offers practical guidelines for automating the disassembly process in line with future waste management demands.}
}

@article{gemini2025,
  title={Gemini-v2-TR},
  author={Google},
  journal={arXiv preprint arXiv:2312.11805},
  URL="",
  year={2025},
}

@misc{google-ai-policy,
  author={Google},
  title={Generative AI Prohibited Use Policy},
  url={https://policies.google.com/terms/generative-ai/use-policy},
  year={2024},
  note={Accessed 2025-02-01},
}

@misc{google-ai-principles,
  title={Responsible {AI} Progress Report},
  author={Google},
  year={2025},
  url={https://ai.google/static/documents/ai-responsibility-update-published-february-2025.pdf},
  note={Accessed 2025-02-05}
}

@book{mccarthy1963situations,
  title={Situations, actions, and causal laws},
  author={McCarthy, John and others},
  year={1963},
  publisher={Comtex Scientific}
}
@book{russell2016artificial,
  title={Artificial intelligence: a modern approach},
  author={Russell, Stuart J and Norvig, Peter},
  year={2016},
  publisher={Pearson}
}

@inproceedings{agarwal2024policy,
  title={On-policy distillation of language models: Learning from self-generated mistakes},
  author={Agarwal, Rishabh and Vieillard, Nino and Zhou, Yongchao and Stanczyk, Piotr and Garea, Sabela Ramos and Geist, Matthieu and Bachem, Olivier},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@article{sermanet2025scifi,
  author    = {Pierre Sermanet and Anirudha Majumdar and Vikas Sindhwani},
  title     = "{SciFi-Bench: How Would AI-Powered Robots Behave in Science Fiction Literature?}",
  journal   = {arXiv preprint arXiv:2503.10706},
  url       = {http://arxiv.org/abs/2503.10706},
  year      = {2025},
}

@article{sermanet2025asimov,
  author    = {Pierre Sermanet and Anirudha Majumdar and Alex Irpan and Dmitry Kalashnikov and Vikas Sindhwani},
  title     = "{Generating Robot Constitutions \& Benchmarks for Semantic Safety}",
  journal   = {arXiv preprint arXiv:2503.08663},
  url       = {https://arxiv.org/abs/2503.08663},
  year      = {2025},
}

@inproceedings{MATH-AI-Panel-2023,
  author={MATH-AI-2023-Panel},
  title = {Panel Discussion},
  booktitle = {MATH-AI Workshop at NeurIPS 2023},
  year = {2023},
  month = {December},
  address = {New Orleans, Louisiana, USA},
  url = {https://mathai2023.github.io/}
}

@inproceedings{AIME2024,
  author={MAA},
  title = {American Invitational Mathematics Examination - AIME},
  booktitle = {American Invitational Mathematics Examination - AIME 2024},
  year = {2024},
  month = {February},
  url = {https://maa.org/math-competitions/american-invitational-mathematics-examination-aime}
}

@inproceedings{tdc2023,
  title={TDC 2023 (LLM Edition): The Trojan Detection Challenge},
  author={Mantas Mazeika and Andy Zou and Norman Mu and Long Phan and Zifan Wang and Chunru Yu and Adam Khoja and Fengqing Jiang and Aidan O'Gara and Ellie Sakhaee and Zhen Xiang and Arezoo Rajabi and Dan Hendrycks and Radha Poovendran and Bo Li and David Forsyth},
  booktitle={NeurIPS Competition Track},
  year={2023}
}
@article{mazeika2024harmbench,
  title={HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal},
  author={Mazeika, Mantas and Phan, Long and Yin, Xuwang and Zou, Andy and Wang, Zifan and Mu, Norman and Sakhaee, Elham and Li, Nathaniel and Basart, Steven and Li, Bo and Forsyth, David and Hendrycks, Dan},
  journal={arXiv preprint arXiv:2402.04249},
  year={2024}
}

@misc{netmindmath,
  author = {Netmind.AI},
  title = {Odyssey-Math},
  year = {2024},
  publisher = {GitHub},
  journal = {GitHub Repository},
  howpublished = {\url{https://github.com/protagolabs/odyssey-math/tree/main}},
  note = {Accessed: April 22, 2024}
}

@article{fang2024mathodyssey,
  title={MathOdyssey: Benchmarking Mathematical Problem-Solving Skills in Large Language Models Using Odyssey Math Data}, 
  author={Fang, Meng and Wan, Xiangpeng and Lu, Fei and Xing, Fei and Zou, Kai},
  journal={arXiv preprint arXiv:2406.18321},
  year={2024}
}

@book{LaValle_2006, place={Cambridge}, title={Planning Algorithms}, publisher={Cambridge University Press}, author={LaValle, Steven M.}, year={2006}} 
@article{silver2023generalized,
  title={Generalized planning in pddl domains with pretrained large language models},
  author={Silver, Tom and Dan, Soham and Srinivas, Kavitha and Tenenbaum, Joshua B and Kaelbling, Leslie Pack and Katz, Michael},
  journal={arXiv preprint arXiv:2305.11014},
  year={2023}
}


@book{camacho2007constrained,
  title={Constrained model predictive control},
  author={Camacho, Eduardo F and Bordons, Carlos and Camacho, Eduardo F and Bordons, Carlos},
  year={2007},
  publisher={Springer}
}

@inproceedings{zhang2015mobile,
  title={Mobile Robot Planning Using Action Language with an Abstraction Hierarchy},
  author={Zhang, Shiqi and Yang, Fangkai and Khandelwal, Piyush and Stone, Peter},
  booktitle={International Conference on Logic Programming and Nonmonotonic Reasoning},
  pages={502--516},
  year={2015},
  organization={Springer}
}

@article{jiang2019task,
  title={Task planning in robotics: an empirical comparison of pddl-and asp-based systems},
  author={Jiang, Yu-qian and Zhang, Shi-qi and Khandelwal, Piyush and Stone, Peter},
  journal={Frontiers of Information Technology \& Electronic Engineering},
  volume={20},
  pages={363--373},
  year={2019},
  publisher={Springer}
}

@article{lagriffoul2018platform,
  title={Platform-independent benchmarks for task and motion planning},
  author={Lagriffoul, Fabien and Dantam, Neil T and Garrett, Caelan and Akbari, Aliakbar and Srivastava, Siddharth and Kavraki, Lydia E},
  journal={IEEE Robotics and Automation Letters},
  volume={3},
  number={4},
  pages={3765--3772},
  year={2018},
  publisher={IEEE}
}
@article{zou2023universal,
  title={Universal and transferable adversarial attacks on aligned language models},
  author={Zou, Andy and Wang, Zifan and Kolter, J Zico and Fredrikson, Matt},
  journal={arXiv preprint arXiv:2307.15043},
  year={2023}
}
@article{Sermanet2023RoboVQA,
  author = {
    Pierre Sermanet and
    Tianli Ding and
    Jeffrey Zhao and
    Fei Xia and
    Debidatta Dwibedi and
    Keerthana Gopalakrishnan and
    Christine Chan and
    Gabriel Dulac-Arnold and
    Sharath Maddineni and
    Nikhil J Joshi and
    Pete Florence and
    Wei Han and
    Robert Baruch and
    Yao Lu and
    Suvir Mirchandani and
    Peng Xu and
    Pannag Sanketi and
    Karol Hausman and
    Izhak Shafran and
    Brian Ichter and
    Yuan Cao},
  title     = {RoboVQA: Multimodal Long-Horizon Reasoning for Robotics},
  journal   = {Proceedings of International Conference in Robotics and Automation (ICRA)},
  year      = {2024},
  url       = {http://arxiv.org/abs/2311.00899},
  biburl    = {https://github.com/sermanet/sermanet.github.io/blob/master/assets/bib/Sermanet2024RoboVQA.bib},
}
@article{asimov1942runaround,
  author={Asimov, Isaac},
  journal={Runaround},
  year={1942}
}
@inproceedings{huang2024collective,
  title={Collective Constitutional {AI}: Aligning a Language Model with Public Input},
  author={Huang, Saffron and Siddarth, Divya and Lovitt, Liane and Liao, Thomas I and Durmus, Esin and Tamkin, Alex and Ganguli, Deep},
  booktitle={The 2024 ACM Conference on Fairness, Accountability, and Transparency},
  pages={1395--1417},
  year={2024}
}
@misc{gdm2024autort,
      title={Auto{RT}: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents}, 
      author={Michael Ahn and Debidatta Dwibedi and Chelsea Finn and Montse Gonzalez Arenas and Keerthana Gopalakrishnan and Karol Hausman and Brian Ichter and Alex Irpan and Nikhil Joshi and Ryan Julian and Sean Kirmani and Isabel Leal and Edward Lee and Sergey Levine and Yao Lu and Isabel Leal and Sharath Maddineni and Kanishka Rao and Dorsa Sadigh and Pannag Sanketi and Pierre Sermanet and Quan Vuong and Stefan Welker and Fei Xia and Ted Xiao and Peng Xu and Steve Xu and Zhuo Xu},
      year={2024},
      eprint={2401.12963},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}
@misc{kavukcuoglu2022our,
  title={How our principles helped define {A}lpha{F}old’s release},
  author={Kavukcuoglu, Koray and Kohli, Pushmeet and Ibrahim, Lila and Bloxwich, Dawn and Brown, Sasha},
  year={2022},
  publisher={DeepMind. https://perma. cc/3ARS-XLNV}
}
@article{kundu2023specific,
  title={Specific versus general principles for constitutional {AI}},
  author={Kundu, Sandipan and Bai, Yuntao and Kadavath, Saurav and Askell, Amanda and Callahan, Andrew and Chen, Anna and Goldie, Anna and Balwit, Avital and Mirhoseini, Azalia and McLean, Brayden and others},
  journal={arXiv preprint arXiv:2310.13798},
  year={2023}
}
@article{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@inproceedings{hundt2022robots,
  title={Robots enact malignant stereotypes},
  author={Hundt, Andrew and Agnew, William and Zeng, Vicky and Kacianka, Severin and Gombolay, Matthew},
  booktitle={2022 ACM Conference on Fairness, Accountability, and Transparency},
  pages={743--756},
  year={2022}
}

@article{jiang2019multi,
  title={Multi-robot planning with conflicts and synergies},
  author={Jiang, Yuqian and Yedidsion, Harel and Zhang, Shiqi and Sharon, Guni and Stone, Peter},
  journal={Autonomous Robots},
  volume={43},
  number={8},
  pages={2011--2032},
  year={2019},
  publisher={Springer}
}

@inproceedings{ding2020task,
  title={Task-motion planning for safe and efficient urban driving},
  author={Ding, Yan and Zhang, Xiaohan and Zhan, Xingyue and Zhang, Shiqi},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={2119--2125},
  year={2020},
  organization={IEEE}
}

@article{huang2022inner,
  title={Inner monologue: Embodied reasoning through planning with language models},
  author={Huang, Wenlong and Xia, Fei and Xiao, Ted and Chan, Harris and Liang, Jacky and Florence, Pete and Zeng, Andy and Tompson, Jonathan and Mordatch, Igor and Chebotar, Yevgen and others},
  journal={arXiv preprint arXiv:2207.05608},
  year={2022}
}

@inproceedings{singh2023progprompt,
  title={Progprompt: Generating situated robot task plans using large language models},
  author={Singh, Ishika and Blukis, Valts and Mousavian, Arsalan and Goyal, Ankit and Xu, Danfei and Tremblay, Jonathan and Fox, Dieter and Thomason, Jesse and Garg, Animesh},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={11523--11530},
  year={2023},
  organization={IEEE}
}

@inproceedings{lora,
  author       = {Edward J. Hu and
                  Yelong Shen and
                  Phillip Wallis and
                  Zeyuan Allen{-}Zhu and
                  Yuanzhi Li and
                  Shean Wang and
                  Lu Wang and
                  Weizhu Chen},
  title        = {LoRA: Low-Rank Adaptation of Large Language Models},
  booktitle    = {The Tenth International Conference on Learning Representations, {ICLR}
                  2022, Virtual Event, April 25-29, 2022},
  publisher    = {OpenReview.net},
  year         = {2022},
  url          = {https://openreview.net/forum?id=nZeVKeeFYf9},
  timestamp    = {Sat, 20 Aug 2022 01:15:42 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/HuSWALWWC22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{sarart2024,
  author       = {Isabel Leal and
                  Krzysztof Choromanski and
                  Deepali Jain and
                  Avinava Dubey and
                  Jake Varley and
                  Michael S. Ryoo and
                  Yao Lu and
                  Frederick Liu and
                  Vikas Sindhwani and
                  Quan Vuong and
                  Tam{\'{a}}s Sarl{\'{o}}s and
                  Ken Oslund and
                  Karol Hausman and
                  Kanishka Rao},
  title        = {{SARA-RT:} Scaling up Robotics Transformers with Self-Adaptive Robust
                  Attention},
  booktitle    = {{IEEE} International Conference on Robotics and Automation, {ICRA}
                  2024, Yokohama, Japan, May 13-17, 2024},
  pages        = {6920--6927},
  publisher    = {{IEEE}},
  year         = {2024},
  url          = {https://doi.org/10.1109/ICRA57147.2024.10611597},
  doi          = {10.1109/ICRA57147.2024.10611597},
  timestamp    = {Mon, 19 Aug 2024 15:59:36 +0200},
  biburl       = {https://dblp.org/rec/conf/icra/LealCJDVR0LSVSO24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ding2023task,
  title={Task and motion planning with large language models for object rearrangement},
  author={Ding, Yan and Zhang, Xiaohan and Paxton, Chris and Zhang, Shiqi},
  booktitle={2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={2086--2092},
  year={2023},
  organization={IEEE}
}

@article{valmeekam2024planning,
  title={On the planning abilities of large language models-a critical investigation},
  author={Valmeekam, Karthik and Marquez, Matthew and Sreedharan, Sarath and Kambhampati, Subbarao},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{hao2023reasoning,
  title={Reasoning with language model is planning with world model},
  author={Hao, Shibo and Gu, Yi and Ma, Haodi and Hong, Joshua Jiahua and Wang, Zhen and Wang, Daisy Zhe and Hu, Zhiting},
  journal={arXiv preprint arXiv:2305.14992},
  year={2023}
}

@article{guan2024leveraging,
  title={Leveraging pre-trained large language models to construct and utilize world models for model-based task planning},
  author={Guan, Lin and Valmeekam, Karthik and Sreedharan, Sarath and Kambhampati, Subbarao},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}


@misc{srivastava2024functional,
      title={Functional Benchmarks for Robust Evaluation of Reasoning Performance, and the Reasoning Gap}, 
      author={Saurabh Srivastava and Annarose M B and Anto P V au2 and Shashank Menon and Ajay Sukumar and Adwaith Samod T and Alan Philipose and Stevin Prince and Sooraj Thomas},
      year={2024},
      eprint={2402.19450},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}


@InProceedings{pmlr-v270-xu25b,
  title = 	 {Mobility {VLA}: Multimodal Instruction Navigation with Long-Context {VLM}s and Topological Graphs},
  author =       {Chiang, Hao-Tien Lewis and Xu, Zhuo and Fu, Zipeng and Jacob, Mithun George and Zhang, Tingnan and Lee, Tsang-Wei Edward and Yu, Wenhao and Schenck, Connor and Rendleman, David and Shah, Dhruv and Xia, Fei and Hsu, Jasmine and Hoech, Jonathan and Florence, Pete and Kirmani, Sean and Singh, Sumeet and Sindhwani, Vikas and Parada, Carolina and Finn, Chelsea and Xu, Peng and Levine, Sergey and Tan, Jie},
  booktitle = 	 {Proceedings of The 8th Conference on Robot Learning},
  pages = 	 {3866--3887},
  year = 	 {2025},
  volume = 	 {270},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--09 Nov},
  publisher =    {PMLR},
  pdf = 	 {https://raw.githubusercontent.com/mlresearch/v270/main/assets/xu25b/xu25b.pdf},
  url = 	 {https://proceedings.mlr.press/v270/xu25b.html},
}


@article{varley2024embodied,
  title={Embodied {AI} with Two Arms: Zero-shot Learning, Safety and Modularity},
  author={Varley, Jake and Singh, Sumeet and Jain, Deepali and Choromanski, Krzysztof and Zeng, Andy and Chowdhury, Somnath Basu Roy and Dubey, Avinava and Sindhwani, Vikas},
  journal={arXiv preprint arXiv:2404.03570},
  year={2024}
}

@inproceedings{conf/iros/VarleySJC0CDS24,
  author = {Varley, Jake and Singh, Sumeet and Jain, Deepali and Choromanski, Krzysztof and Zeng, Andy and Chowdhury, Somnath Basu Roy and Dubey, Avinava and Sindhwani, Vikas},
  biburl = {https://www.bibsonomy.org/bibtex/246723f750f69a6ad659ae4be0df53e2d/dblp},
  booktitle = {IROS},
  ee = {https://doi.org/10.1109/IROS58592.2024.10802181},
  isbn = {979-8-3503-7770-5},
  keywords = {dblp},
  pages = {3651-3657},
  publisher = {IEEE},
  title = {Embodied {AI} with Two Arms: Zero-shot Learning, Safety and Modularity.},
  url = {http://dblp.uni-trier.de/db/conf/iros/iros2024.html#VarleySJC0CDS24},
  year = 2024
}

@misc{neiss,
 author={NEISS},
  title = {{National Electronic Injury Surveillance System - All Injury Program (NEISS-AIP)}},
  year={2024},
}

@article{anilmany,
  title={Many-shot Jailbreaking},
  year={2024},
  author={Anil, Cem and Durmus, Esin and Sharma, Mrinank and Benton, Joe and Kundu, Sandipan and Batson, Joshua and Rimsky, Nina and Tong, Meg and Mu, Jesse and Ford, Daniel and others}
}

@article{andriushchenko2024jailbreaking,
  title={Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks},
  author={Andriushchenko, Maksym and Croce, Francesco and Flammarion, Nicolas},
  journal={arXiv preprint arXiv:2404.02151},
  year={2024}
}
@book{international2011iso,
  title={I{SO} 10218: Robots and Robotic Devices : Safety Requirements for Industrial Robots},
  author={International Organization for Standardization},
  number={pt. 1},
  series={ISO 10218: Robots and Robotic Devices : Safety Requirements for Industrial Robots},
  url={https://books.google.com/books?id=BaF-AQAACAAJ},
  year={2011},
  publisher={ISO}
}
@book{zhou1998essentials,
  title={Essentials of robust control},
  author={Zhou, Kemin and Doyle, John Comstock},
  volume={104},
  year={1998},
  publisher={Prentice hall Upper Saddle River, NJ}
}
@article{villani2016force,
  title={Force control},
  author={Villani, Luigi and De Schutter, Joris},
  journal={Springer handbook of robotics},
  pages={195--220},
  year={2016},
  publisher={Springer}
}
@inproceedings{ames2019control,
  title={Control barrier functions: Theory and applications},
  author={Ames, Aaron D and Coogan, Samuel and Egerstedt, Magnus and Notomista, Gennaro and Sreenath, Koushil and Tabuada, Paulo},
  booktitle={2019 18th European control conference (ECC)},
  pages={3420--3431},
  year={2019},
  organization={IEEE}
}
@book{lavalle2006planning,
  title={Planning algorithms},
  author={LaValle, Steven M},
  year={2006},
  publisher={Cambridge university press}
}
@misc{ria_r15_06_2012,
title = {A{NSI}/{RIA} {R}15.06-2012: Safety Requirements for Industrial Robots and Robot Systems},
author = {Robotic Industries Association (RIA)},
year = {2012},
publisher = {American National Standards Institute (ANSI)},
}

@INPROCEEDINGS{6840202,
  author={Jacobs, Theo and Virk, Gurvinder Singh},
  booktitle={ISR/Robotik 2014; 41st International Symposium on Robotics}, 
  title={{ISO} 13482 - The new safety standard for personal care robots}, 
  year={2014},
  volume={},
  number={},
  pages={1-6},
  keywords={},
  doi={}}
  
@misc{chao2024jailbreakbench,
      title={JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models}, 
      author={Patrick Chao and Edoardo Debenedetti and Alexander Robey and Maksym Andriushchenko and Francesco Croce and Vikash Sehwag and Edgar Dobriban and Nicolas Flammarion and George J. Pappas and Florian Tramèr and Hamed Hassani and Eric Wong},
      year={2024},
      eprint={2404.01318},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}
@article{robey2024jailbreaking,
    title={Jailbreaking LLM-Controlled Robots},
    author={Robey, Alexander and Ravichandran, Zachary and Kumar, Vijay and Hassani, Hamed and Pappas, George J.},
    journal={arXiv preprint arXiv:2410.13691},
    year={2024}
}

@article{biderman2024emergent,
  title={Emergent and predictable memorization in large language models},
  author={Biderman, Stella and PRASHANTH, USVSN and Sutawika, Lintang and Schoelkopf, Hailey and Anthony, Quentin and Purohit, Shivanshu and Raff, Edward},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{yuan2024robopoint,
  title={RoboPoint: A Vision-Language Model for Spatial Affordance Prediction for Robotics},
  author={Yuan, Wentao and Duan, Jiafei and Blukis, Valts and Pumacay, Wilbert and Krishna, Ranjay and Murali, Adithyavairavan and Mousavian, Arsalan and Fox, Dieter},
  journal={arXiv preprint arXiv:2406.10721},
  year={2024}
}

@inproceedings{rein2024gpqa,
      title={{GPQA}: A Graduate-Level Google-Proof Q\&A Benchmark},
      author={David Rein and Betty Li Hou and Asa Cooper Stickland and Jackson Petty and Richard Yuanzhe Pang and Julien Dirani and Julian Michael and Samuel R. Bowman},
      booktitle={First Conference on Language Modeling},
      year={2024},
      url={https://openreview.net/forum?id=Ti67584b98}
}

@misc{Gauthier2024aider,
    author       = {Gauthier, Paul},
    title        = {GPT code editing benchmarks --- aider.chat},
    howpublished = {\url{https://aider.chat/docs/leaderboards/\#polyglot-leaderboard}},
    year         = {2024},
    note         = {[Accessed 16-09-2025]},
}

@inproceedings{yue2023mmmu,
    title={MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI},
    author={Xiang Yue and Yuansheng Ni and Kai Zhang and Tianyu Zheng and Ruoqi Liu and Ge Zhang and Samuel Stevens and Dongfu Jiang and Weiming Ren and Yuxuan Sun and Cong Wei and Botao Yu and Ruibin Yuan and Renliang Sun and Ming Yin and Boyuan Zheng and Zhenzhu Yang and Yibo Liu and Wenhao Huang and Huan Sun and Yu Su and Wenhu Chen},
    booktitle={Proceedings of CVPR},
    year={2024},
  }
    

@article{zhou2025roborefer,
    title={RoboRefer: Towards Spatial Referring with Reasoning in Vision-Language Models for Robotics},
    author={Zhou, Enshen and An, Jingkun and Chi, Cheng and Han, Yi and Rong, Shanyu and Zhang, Chi and Wang, Pengwei and Wang, Zhongyuan and Huang, Tiejun and Sheng, Lu and others},
    journal={arXiv preprint arXiv:2506.04308},
    year={2025}
}

@article{team2025gemini,
  title={Gemini robotics: Bringing ai into the physical world},
  author={Gemini-Robotics-Team and Abeyruwan, Saminda and Ainslie, Joshua and Alayrac, Jean-Baptiste and Arenas, Montserrat Gonzalez and Armstrong, Travis and Balakrishna, Ashwin and Baruch, Robert and Bauza, Maria and Blokzijl, Michiel and others},
  journal={arXiv preprint arXiv:2503.20020},
  year={2025}
}
@article{team2024gemma,
  title={Gemma: Open models based on gemini research and technology},
  author={Gemma-Team and Mesnard, Thomas and Hardin, Cassidy and Dadashi, Robert and Bhupatiraju, Surya and Pathak, Shreya and Sifre, Laurent and Rivi{\`e}re, Morgane and Kale, Mihir Sanjay and Love, Juliette and others},
  journal={arXiv preprint arXiv:2403.08295},
  year={2024}
}

@inproceedings{TodorovET12,
  author = {Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle = {IROS},
  isbn = {978-1-4673-1737-5},
  keywords = {dblp},
  pages = {5026-5033},
  publisher = {IEEE},
  title = {MuJoCo: A physics engine for model-based control.},
  year = 2012
}

@article{anil2023palm,
  title={Palm 2 technical report},
  author={Anil, Rohan and Dai, Andrew M and Firat, Orhan and Johnson, Melvin and Lepikhin, Dmitry and Passos, Alexandre and Shakeri, Siamak and Taropa, Emanuel and Bailey, Paige and Chen, Zhifeng and others},
  journal={arXiv preprint arXiv:2305.10403},
  year={2023}
}
@misc{kudugunta2023madlad400,
      title={MADLAD-400: A Multilingual And Document-Level Large Audited Dataset}, 
      author={Sneha Kudugunta and Isaac Caswell and Biao Zhang and Xavier Garcia and Christopher A. Choquette-Choo and Katherine Lee and Derrick Xin and Aditya Kusupati and Romi Stella and Ankur Bapna and Orhan Firat},
      year={2023},
      eprint={2309.04662},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{garcia2023unreasonable,
      title={The unreasonable effectiveness of few-shot learning for machine translation}, 
      author={Xavier Garcia and Yamini Bansal and Colin Cherry and George Foster and Maxim Krikun and Fangxiaoyu Feng and Melvin Johnson and Orhan Firat},
      year={2023},
      eprint={2302.01398},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{chowdhery2023palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={240},
  pages={1--113},
  year={2023}
}

@article{yeung2024new,
    title = "New Google Gemini vulnerability enabling profound misuse",
    author = "Yeung, Kenneth",
    year = "2024",
    url = "https://hiddenlayer.com/research/new-google-gemini-content-manipulation-vulns-found/#Indirect-Injections-are-back!"
}

@misc{wunderwuzzi2023hacking,
    title = {{Hacking Google Bard - From Prompt Injection to Data Exfiltration}},
    author = "wunderwuzzi",
    year = "2023",
    howpublished = "https://embracethered.com/blog/posts/2023/google-bard-data-exfiltration/"
}

@article{wu2022promptchainer,
  title={Prompt{C}hainer: Chaining Large Language Model Prompts through Visual Programming},
  author={Wu, Tongshuang and Jiang, Ellen and Donsbach, Aaron and Gray, Jeff and Molina, Alejandra and Terry, Michael and Cai, Carrie J},
  journal={CHI Extended Abstracts},
  year={2022},
  url={https://dl.acm.org/doi/abs/10.1145/3491101.3519729}
}

@article{carlini2022quantifying,
  title={Quantifying memorization across neural language models},
  author={Carlini, Nicholas and Ippolito, Daphne and Jagielski, Matthew and Lee, Katherine and Tramer, Florian and Zhang, Chiyuan},
  journal={arXiv preprint arXiv:2202.07646},
  year={2022},
  url={https://arxiv.org/abs/2202.07646}
}

@article{jiang2024mixtral,
  title={Mixtral of experts},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Roux, Antoine and Mensch, Arthur and Savary, Blanche and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Hanna, Emma Bou and Bressand, Florian and others},
  journal={arXiv preprint arXiv:2401.04088},
  year={2024}
}

@article{jacobs1991adaptive,
  title={Adaptive mixtures of local experts},
  author={Jacobs, Robert A and Jordan, Michael I and Nowlan, Steven J and Hinton, Geoffrey E},
  journal={Neural computation},
  volume={3},
  number={1},
  pages={79--87},
  year={1991},
  publisher={MIT Press}
}

@article{chen1999empirical,
  title={An empirical study of smoothing techniques for language modeling},
  author={Chen, Stanley F and Goodman, Joshua},
  journal={Computer Speech \& Language},
  volume={13},
  number={4},
  pages={359--394},
  year={1999},
  publisher={Elsevier}
}

@book{jelinek1998statistical,
  title={Statistical methods for speech recognition},
  author={Jelinek, Frederick},
  year={1998},
  publisher={MIT press}
}

@inproceedings{kneser1995improved,
  title={Improved backing-off for m-gram language modeling},
  author={Kneser, Reinhard and Ney, Hermann},
  booktitle={1995 international conference on acoustics, speech, and signal processing},
  volume={1},
  pages={181--184},
  year={1995},
  organization={IEEE}
}

@article{vstar,
  title={V*: Guided Visual Search as a Core Mechanism in Multimodal LLMs},
  author={Penghao Wu and Saining Xie},
  year={2023},
  journal={arXiv preprint arXiv:2312.14135},
}

@article{jagielski2022measuring,
  title={Measuring forgetting of memorized training examples},
  author={Jagielski, Matthew and Thakkar, Om and Tramer, Florian and Ippolito, Daphne and Lee, Katherine and Carlini, Nicholas and Wallace, Eric and Song, Shuang and Thakurta, Abhradeep and Papernot, Nicolas and others},
  journal={arXiv preprint arXiv:2207.00099},
  year={2022},
  url={https://arxiv.org/abs/2207.00099}
}

@software{flax2020github,
  author = {Jonathan Heek and Anselm Levskaya and Avital Oliver and Marvin Ritter and Bertrand Rondepierre and Andreas Steiner and Marc van {Z}ee},
  title = {{F}lax: A neural network library and ecosystem for {JAX}},
  url = {http://github.com/google/flax},
  version = {0.8.1},
  year = {2023},
}

@inproceedings{carlini2019secret,
  title={The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks.},
  author={Carlini, Nicholas and Liu, Chang and Erlingsson, {\'U}lfar and Kos, Jernej and Song, Dawn},
  booktitle={USENIX Security Symposium},
  volume={267},
  year={2019}
}

@article{dictionaria-kalamang,
  address   = {Leipzig},
  author    = {Visser, Eline},
  journal   = {Dictionaria},
  number    = {13},
  pages     = {1-2737},
  publisher = {Max Planck Institute for Evolutionary Anthropology},
  title     = {Kalamang dictionary},
  url       = {https://dictionaria.clld.org/contributions/kalamang},
  year      = {2020}
}

@article{visser2020grammar,
  title = {A Grammar of Kalamang: The Papuan Language of the Karas Islands},
  author = {Eline Visser},
  school = {General Linguistics},
  year = {2020},
  type = {Doctoral Thesis (monograph)},
}

@article{lee2021deduplicating,
  title={Deduplicating training data makes language models better},
  author={Lee, Katherine and Ippolito, Daphne and Nystrom, Andrew and Zhang, Chiyuan and Eck, Douglas and Callison-Burch, Chris and Carlini, Nicholas},
  journal={arXiv preprint arXiv:2107.06499},
  year={2021},
  url={https://arxiv.org/abs/2107.06499}
}

@article{feldman2019does,
  title={Does Learning Require Memorization? A Short Tale about a Long Tail. CoRR abs/1906.05271 (2019)},
  author={Feldman, Vitaly},
  journal={arXiv preprint arXiv:1906.05271},
  year={2019},
  url={https://arxiv.org/abs/1906.05271}
}

@inproceedings{carlini2021extracting,
  title={Extracting Training Data from Large Language Models.},
  author={Carlini, Nicholas and Tramer, Florian and Wallace, Eric and Jagielski, Matthew and Herbert-Voss, Ariel and Lee, Katherine and Roberts, Adam and Brown, Tom B and Song, Dawn and Erlingsson, Ulfar and others},
  booktitle={USENIX Security Symposium},
  volume={6},
  year={2021}
}

@article{carlini2022privacy,
  title={The privacy onion effect: Memorization is relative},
  author={Carlini, Nicholas and Jagielski, Matthew and Papernot, Nicolas and Terzis, Andreas and Tramer, Florian and Zhang, Chiyuan},
  journal={arXiv preprint arXiv:2206.10469},
  year={2022},
  url={https://arxiv.org/abs/2206.10469}
}

@article{wiegreffe-etal-2021-measuring,
    title = "{M}easuring Association Between Labels and Free-Text Rationales",
    author = "Wiegreffe, Sarah  and
      Marasovi{\'c}, Ana  and
      Smith, Noah A.",
    journal = "EMNLP",
    year = "2021",
    url = "https://aclanthology.org/2021.emnlp-main.804",
}

@article{kreutzer2022quality,
  title={Quality at a glance: An audit of web-crawled multilingual datasets},
  author={Kreutzer, Julia and Caswell, Isaac and Wang, Lisa and Wahab, Ahsan and van Esch, Daan and Ulzii-Orshikh, Nasanbayar and Tapo, Allahsera and Subramani, Nishant and Sokolov, Artem and Sikasote, Claytone and others},
  journal={Transactions of the Association for Computational Linguistics},
  volume={10},
  pages={50--72},
  year={2022},
  publisher={MIT Press}
}

@article{ippolito2022preventing,
  title={Preventing Verbatim Memorization in Language Models Gives a False Sense of Privacy},
  author={Ippolito, Daphne and Tram{\`e}r, Florian and Nasr, Milad and Zhang, Chiyuan and Jagielski, Matthew and Lee, Katherine and Choquette-Choo, Christopher A and Carlini, Nicholas},
  journal={arXiv preprint arXiv:2210.17546},
  year={2022},
  url={https://arxiv.org/abs/210.17546}
}

@article{clark-etal-2020-tydi,
    title = "{T}y{D}i{QA}: A Benchmark for Information-Seeking Question Answering in Typologically Diverse Languages",
    author = "Clark, Jonathan H.  and
      Choi, Eunsol  and
      Collins, Michael  and
      Garrette, Dan  and
      Kwiatkowski, Tom  and
      Nikolaev, Vitaly  and
      Palomaki, Jennimaria",
    journal = "TACL",
    year = "2020",
    url = "https://aclanthology.org/2020.tacl-1.30",
}
@article{mishra2021cross,
  title={Cross-task generalization via natural language crowdsourcing instructions},
  author={Mishra, Swaroop and Khashabi, Daniel and Baral, Chitta and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2104.08773},
  year={2021}
}
@article{kwiatkowski2019natural,
  title={Natural questions: a benchmark for question answering research},
  author={Kwiatkowski, Tom and Palomaki, Jennimaria and Redfield, Olivia and Collins, Michael and Parikh, Ankur and Alberti, Chris and Epstein, Danielle and Polosukhin, Illia and Devlin, Jacob and Lee, Kenton and others},
  journal={Transactions of the Association for Computational Linguistics},
  volume={7},
  pages={453--466},
  year={2019},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}
@article{kasai2022realtime,
  title={RealTime QA: What's the Answer Right Now?},
  author={Kasai, Jungo and Sakaguchi, Keisuke and Takahashi, Yoichi and Bras, Ronan Le and Asai, Akari and Yu, Xinyan and Radev, Dragomir and Smith, Noah A and Choi, Yejin and Inui, Kentaro},
  journal={arXiv preprint arXiv:2207.13332},
  year={2022}
}
@article{hendrycks2020measuring,
  title={Measuring massive multitask language understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={ICLR},
  year={2020},
  url={https://arxiv.org/abs/2009.03300},
}

@article{tay2022transcending,
  title={Transcending scaling laws with 0.1\% extra compute},
  author={Tay, Yi and Wei, Jason and Chung, Hyung Won and Tran, Vinh Q and So, David R and Shakeri, Siamak and Garcia, Xavier and Zheng, Huaixiu Steven and Rao, Jinfeng and Chowdhery, Aakanksha and others},
  journal={arXiv preprint arXiv:2210.11399},
  year={2022},
  url={https://arxiv.org/abs/2210.11399}
}

@article{srivastava2022beyond,
  title={Beyond the {I}mitation {G}ame: Quantifying and extrapolating the capabilities of language models},
  author={Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adri{\`a} and others},
  journal={arXiv preprint arXiv:2206.04615},
  year={2022},
  url={https://arxiv.org/abs/2206.04615}
}

@inproceedings{chiang-chen-2019-semantically,
    title = "Semantically-Aligned Equation Generation for Solving and Reasoning Math Word Problems",
    author = "Chiang, Ting-Rui  and
      Chen, Yun-Nung",
    booktitle = "NAACL",
    year = "2019",
    url = "https://aclanthology.org/N19-1272",
}

@article{hendrycks2021measuring,
  title={Measuring mathematical problem solving with the {MATH} dataset},
  author={Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and Arora, Akul and Basart, Steven and Tang, Eric and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2103.03874},
  year={2021},
  url={https://arxiv.org/abs/2103.03874}
}

@article{andreas-etal-2018-learning,
    title = "Learning with Latent Language",
    author = "Andreas, Jacob  and
      Klein, Dan  and
      Levine, Sergey",
    journal = "NAACL",
    year = "2018",
    url = "https://aclanthology.org/N18-1197",
}

@article{ahn2022can,
  title={Do as {I} can, not as {I} say: Grounding language in robotic affordances},
  author={Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and others},
  journal={arXiv preprint arXiv:2204.01691},
  year={2022},
  url={https://arxiv.org/abs/2204.01691}
}

@misc{mmmu,
      title={MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI}, 
      author={Xiang Yue and Yuansheng Ni and Kai Zhang and Tianyu Zheng and Ruoqi Liu and Ge Zhang and Samuel Stevens and Dongfu Jiang and Weiming Ren and Yuxuan Sun and Cong Wei and Botao Yu and Ruibin Yuan and Renliang Sun and Ming Yin and Boyuan Zheng and Zhenzhu Yang and Yibo Liu and Wenhao Huang and Huan Sun and Yu Su and Wenhu Chen},
      year={2023},
      eprint={2311.16502},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{wei2022chain,
  title={Chain-of-{T}hought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
  journal={NeurIPS},
  year={2022},
  url={https://arxiv.org/abs/2201.11903},
}

@inproceedings{10.5555/3600270.3602070,
author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed H. and Le, Quoc V. and Zhou, Denny},
title = "{Chain-of-Thought prompting elicits reasoning in large language models}",
year = {2022},
isbn = {9781713871088},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We explore how generating a chain of thought—a series of intermediate reasoning steps—significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain-of-thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting.Experiments on three large language models show that chain-of-thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a PaLM 540B with just eight chain-of-thought exemplars achieves state-of-the-art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.},
booktitle = {Proceedings of the 36th International Conference on Neural Information Processing Systems},
articleno = {1800},
numpages = {14},
location = {New Orleans, LA, USA},
series = {NIPS '22}
}

@article{wu2022ai,
  title={A{I} chains: {T}ransparent and controllable human-{AI} interaction by chaining large language model prompts},
  author={Wu, Tongshuang and Terry, Michael and Cai, Carrie Jun},
  journal={CHI},
  year={2022},
  url={https://dl.acm.org/doi/abs/10.1145/3491102.3517582},
}

@article{yan2020neural,
  title={Neural execution engines: {L}earning to execute subroutines},
  author={Yan, Yujun and Swersky, Kevin and Koutra, Danai and Ranganathan, Parthasarathy and Hashemi, Milad},
  journal={NeurIPS},
  year={2020},
  url={https://arxiv.org/abs/2006.08084},
}

@article{cai2017making,
  title={Making neural programming architectures generalize via recursion},
  author={Cai, Jonathon and Shin, Richard and Song, Dawn},
  journal={ICLR},
  year={2017},
  url={https://arxiv.org/abs/1704.06611}
}

@article{austin2021program,
  title={Program synthesis with large language models},
  author={Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalewski, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others},
  journal={arXiv preprint arXiv:2108.07732},
  year={2021},
  url={https://arxiv.org/abs/2108.07732},
}

@article{ellis2019write,
  title={Write, execute, assess: {P}rogram synthesis with a repl},
  author={Ellis, Kevin and Nye, Maxwell and Pu, Yewen and Sosa, Felix and Tenenbaum, Josh and Solar-Lezama, Armando},
  journal={NeurIPS},
  year={2019},
  url={https://arxiv.org/abs/1906.04604},
}

@article{chen2022can,
  title={Can Rationalization Improve Robustness?},
  author={Chen, Howard and He, Jacqueline and Narasimhan, Karthik and Chen, Danqi},
  journal={NAACL},
  year={2022},
  url={https://arxiv.org/abs/2204.11790}
}

@article{yao2021refining,
  title={Refining language models with compositional explanations},
  author={Yao, Huihan and Chen, Ying and Ye, Qinyuan and Jin, Xisen and Ren, Xiang},
  journal={NeurIPS},
  year={2021},
  url={https://proceedings.neurips.cc/paper/2021/hash/4b26dc4663ccf960c8538d595d0a1d3a-Abstract.html}
}

@article{dua-etal-2020-benefits,
    title = "Benefits of Intermediate Annotations in Reading Comprehension",
    author = "Dua, Dheeru  and
      Singh, Sameer  and
      Gardner, Matt",
    journal = "ACL",
    url = "https://aclanthology.org/2020.acl-main.497",
    year = "2020"
}


@article{zaidan-etal-2007-using,
    title = "Using {``}Annotator Rationales{''} to Improve Machine Learning for Text Categorization",
    author = "Zaidan, Omar  and
      Eisner, Jason  and
      Piatko, Christine",
    journal = "NAACL",
    year = "2007",
    url = "https://aclanthology.org/N07-1033",
}

@article{patel-etal-2021-nlp,
    title = "Are {NLP} Models really able to Solve Simple Math Word Problems?",
    author = "Patel, Arkil  and
      Bhattamishra, Satwik  and
      Goyal, Navin",
    journal = "NAACL",
    year = "2021",
    url = "https://aclanthology.org/2021.naacl-main.168.pdf"
}

@article{min2022rethinking,
  title={Rethinking the Role of Demonstrations: {W}hat Makes In-Context Learning Work?},
  author={Min, Sewon and Lyu, Xinxi and Holtzman, Ari and Artetxe, Mikel and Lewis, Mike and Hajishirzi, Hannaneh and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2202.12837},
  year={2022},
  url={https://arxiv.org/abs/2202.12837}
}

@article{jie2022learning,
  title={Learning to Reason Deductively: {M}ath Word Problem Solving as Complex Relation Extraction},
  author={Jie, Zhanming and Li, Jierui and Lu, Wei},
  journal={arXiv preprint arXiv:2203.10316},
  year={2022},
  url={https://arxiv.org/abs/2203.10316}
}

@article{wang2022benchmarking,
  title={Benchmarking Generalization via In-Context Instructions on 1,600+ Language Tasks},
  author={Wang, Yizhong and Mishra, Swaroop and Alipoormolabashi, Pegah and Kordi, Yeganeh and Mirzaei, Amirreza and Arunkumar, Anjana and Ashok, Arjun and Dhanasekaran, Arut Selvan and Naik, Atharva and Stap, David and others},
  journal={arXiv preprint arXiv:2204.07705},
  year={2022},
  url={https://arxiv.org/abs/2204.07705}
}

@article{so2021searching,
  title={Searching for Efficient Transformers for Language Modeling},
  author={So, David and Ma{\'n}ke, Wojciech and Liu, Hanxiao and Dai, Zihang and Shazeer, Noam and Le, Quoc V.},
  journal={Advances in Neural Information Processing Systems},
  year={2021},
  url={https://arxiv.org/abs/2109.08668},
}

@article{sanh2021multitask,
  title={Multitask prompted training enables zero-shot task generalization},
  author={Sanh, Victor and Webson, Albert and Raffel, Colin and Bach, Stephen H. and Sutawika, Lintang and Alyafeai, Zaid and Chaffin, Antoine and Stiegler, Arnaud and Scao, Teven Le and Raja, Arun and others},
  journal={ICLR 2022},
  year={2021},
  url={https://arxiv.org/abs/2110.08207}
}

@inproceedings{ouyang2022training,
title={Training language models to follow instructions with human feedback},
author={Long Ouyang and Jeffrey Wu and Xu Jiang and Diogo Almeida and Carroll Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Gray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=TG8KACxEON}
}
@article{lampinen2022can,
  title={Can language models learn from explanations in context?},
  author={Lampinen, Andrew K. and Dasgupta, Ishita and Chan, Stephanie C.Y. and Matthewson, Kory and Tessler, Michael Henry and Creswell, Antonia and McClelland, James L. and Wang, Jane X. and Hill, Felix},
  journal={arXiv preprint arXiv:2204.02329},
  year={2022},
  url={https://arxiv.org/abs/2204.02329},
}

@article{zaremba2014learning,
  title={Learning to execute},
  author={Zaremba, Wojciech and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1410.4615},
  year={2014},
  url={https://arxiv.org/abs/1410.4615}
}

@article{raffel2020exploring,
  title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.},
  journal={Journal of Machine Learning Research},
  volume={21},
  pages={1--67},
  year={2020},
  url={https://arxiv.org/abs/1910.10683}
}

@article{peters-etal-2018-deep,
    title = "Deep Contextualized Word Representations",
    author = "Peters, Matthew E.  and
      Neumann, Mark  and
      Iyyer, Mohit  and
      Gardner, Matt  and
      Clark, Christopher  and
      Lee, Kenton  and
      Zettlemoyer, Luke",
    journal = "NAACL",
    year = "2018",
    url = "https://aclanthology.org/N18-1202",
}

@article{pi2022reasoning,
  title={Reasoning Like Program Executors},
  author={Pi, Xinyu and Liu, Qian and Chen, Bei and Ziyadi, Morteza and Lin, Zeqi and Gao, Yan and Fu, Qiang and Lou, Jian-Guang and Chen, Weizhu},
  journal={arXiv preprint arXiv:2201.11473},
  year={2022},
  url={https://arxiv.org/abs/2201.11473}
}

@article{zhou2020towards,
  title={Towards interpretable natural language understanding with explanations as latent variables},
  author={Zhou, Wangchunshu and Hu, Jinyi and Zhang, Hanlin and Liang, Xiaodan and Sun, Maosong and Xiong, Chenyan and Tang, Jian},
  journal={NeurIPS},
  year={2020},
  url={https://proceedings.neurips.cc/paper/2020/file/4be2c8f27b8a420492f2d44463933eb6-Paper.pdf}
}

@article{zelikman2022star,
  title={S{T}a{R}: {B}ootstrapping Reasoning With Reasoning},
  author={Zelikman, Eric and Wu, Yuhuai and Goodman, Noah D.},
  journal={arXiv preprint arXiv:2203.14465},
  year={2022},
  url={https://arxiv.org/abs/2203.14465},
}

@article{palm,
  author  = {Aakanksha Chowdhery and Sharan Narang and Jacob Devlin and Maarten Bosma and Gaurav Mishra and Adam Roberts and Paul Barham and Hyung Won Chung and Charles Sutton and Sebastian Gehrmann and others},
  title   = {{PaLM: Scaling Language Modeling with Pathways}},
  journal = {Journal of Machine Learning Research},
  year    = {2023},
  volume  = {24},
  number  = {240},
  pages   = {1--113},
  url     = {http://jmlr.org/papers/v24/22-1144.html}
}



%article{palm,
%  author  = {Aakanksha Chowdhery and Sharan Narang and Jacob Devlin and Maarten Bosma and Gaurav Mishra and Adam Roberts and Paul Barham and Hyung Won Chung and Charles Sutton and Sebastian Gehrmann and Parker Schuh and Kensen Shi and Sasha Tsvyashchenko and Joshua Maynez and Abhishek Rao and Parker Barnes and Yi Tay and Noam Shazeer and Vinodkumar Prabhakaran and Emily Reif and Nan Du and Ben Hutchinson and Reiner Pope and James Bradbury and Jacob Austin and Michael Isard and Guy Gur-Ari and Pengcheng Yin and Toju Duke and Anselm Levskaya and Sanjay Ghemawat and Sunipa Dev and Henryk Michalewski and Xavier Garcia and Vedant Misra and Kevin Robinson and Liam Fedus and Denny Zhou and Daphne Ippolito and David Luan and Hyeontaek Lim and Barret Zoph and Alexander Spiridonov and Ryan Sepassi and David Dohan and Shivani Agrawal and Mark Omernick and Andrew M. Dai and Thanumalayan Sankaranarayana Pillai and Marie Pellat and Aitor Lewkowycz and Erica Moreira and Rewon Child and Oleksandr Polozov and Katherine Lee and Zongwei Zhou and Xuezhi Wang and Brennan Saeta and Mark Diaz and Orhan Firat and Michele Catasta and Jason Wei and Kathy Meier-Hellstern and Douglas Eck and Jeff Dean and Slav Petrov and Noah Fiedel},
%  title   = {{PaLM: Scaling Language Modeling with Pathways}},
%  journal = {Journal of Machine Learning Research},
%  year    = {2023},
%  volume  = {24},
%  number  = {240},
%  pages   = {1--113},
%  url     = {http://jmlr.org/papers/v24/22-1144.html}
%}

@article{ling-etal-2017-program,
    title = "Program Induction by Rationale Generation: {L}earning to Solve and Explain Algebraic Word Problems",
    author = "Ling, Wang  and
      Yogatama, Dani  and
      Dyer, Chris  and
      Blunsom, Phil",
    journal = "ACL",
    year = "2017",
    url = "https://aclanthology.org/P17-1015",
}

@article{thoppilan2022lamda,
  title={La{MDA}: {L}anguage Models for Dialog Applications},
  author={Thoppilan, Romal and De Freitas, Daniel and Hall, Jamie and Shazeer, Noam and Kulshreshtha, Apoorv and Cheng, Heng-Tze and Jin, Alicia and Bos, Taylor and Baker, Leslie and Du, Yu and others},
  journal={arXiv preprint arXiv:2201.08239},
  year={2022},
  url={https://arxiv.org/abs/2201.08239},
}

@article{zhao2021calibrate,
  title={Calibrate before use: {I}mproving few-shot performance of language models},
  author={Zhao, Tony Z. and Wallace, Eric and Feng, Shi and Klein, Dan and Singh, Sameer},
  journal={ICML},
  year={2021},
  url={https://arxiv.org/abs/2102.09690}
}

@article{lan2021mwptoolkit,
  title={{MWPT}oolkit: {A}n Open-Source Framework for Deep Learning-Based Math Word Problem Solvers},
  author={Lan, Yihuai and Wang, Lei and Zhang, Qiyuan and Lan, Yunshi and Dai, Bing Tian and Wang, Yan and Zhang, Dongxiang and Lim, Ee-Peng},
  journal={arXiv preprint arXiv:2109.00799},
  year={2021},
  url={https://arxiv.org/abs/2109.00799}
}

@article{ran-etal-2019-numnet,
    title = "{N}um{N}et: {M}achine Reading Comprehension with Numerical Reasoning",
    author = "Ran, Qiu  and
      Lin, Yankai  and
      Li, Peng  and
      Zhou, Jie  and
      Liu, Zhiyuan",
    journal = "EMNLP",
    year = "2019",
    url = "https://aclanthology.org/D19-1251",
    doi = "10.18653/v1/D19-1251",
}

@article{gu2021dream,
  title={{DREAM}: {U}ncovering Mental Models behind Language Models},
  author={Gu, Yuling and Mishra, Bhavana Dalvi and Clark, Peter},
  journal={NAACL},
  year={2022},
  url={https://arxiv.org/pdf/2112.08656.pdf}
}

@article{liang-etal-2021-explainable,
    title = "Explainable Multi-hop Verbal Reasoning Through Internal Monologue",
    author = "Liang, Zhengzhong  and
      Bethard, Steven  and
      Surdeanu, Mihai",
    journal = "NAACL",
    year = "2021",
    url = "https://aclanthology.org/2021.naacl-main.97",
    doi = "10.18653/v1/2021.naacl-main.97",
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020},
  url={https://arxiv.org/abs/2001.08361},
}

@book{cuddon2012dictionary,
  title={A dictionary of literary terms and literary theory},
  author={Cuddon, John Anthony},
  year={2012},
  publisher={John Wiley \& Sons}
}

@article{mao2021grammar,
  title={Grammar-Based Grounded Lexicon Learning},
  author={Mao, Jiayuan and Shi, Freda and Wu, Jiajun and Levy, Roger and Tenenbaum, Josh},
  journal={NeurIPS},
  year={2021},
  url={https://proceedings.neurips.cc/paper/2021/hash/4158f6d19559955bae372bb00f6204e4-Abstract.html},
}

@article{dong2019neural,
  title={Neural logic machines},
  author={Dong, Honghua and Mao, Jiayuan and Lin, Tian and Wang, Chong and Li, Lihong and Zhou, Denny},
  journal={ICLR},
  year={2019},
  url={https://arxiv.org/abs/1904.11694}
}

@article{chen2019neural,
  title={Neural symbolic reader: {S}calable integration of distributed and symbolic representations for reading comprehension},
  author={Chen, Xinyun and Liang, Chen and Yu, Adams Wei and Zhou, Denny and Song, Dawn and Le, Quoc V.},
  journal={ICLR},
  year={2019},
  url={https://openreview.net/forum?id=ryxjnREFwH}
}

@article{stanovich2000individual,
  title={Individual differences in reasoning: {I}mplications for the rationality debate?},
  author={Stanovich, Keith E and West, Richard F},
  journal={Behavioral and brain sciences},
  volume={23},
  number={5},
  pages={645--665},
  year={2000},
  publisher={Cambridge University Press},
  url={https://pubmed.ncbi.nlm.nih.gov/11301544/}
}

@article{devlin-etal-2019-bert,
    title = "{BERT}: {P}re-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    journal = "NAACL",
    year = "2019",
    url = "https://aclanthology.org/N19-1423",
}

@article{miao-etal-2020-diverse,
    title = "A Diverse Corpus for Evaluating and Developing {E}nglish Math Word Problem Solvers",
    author = "Miao, Shen Yun  and
      Liang, Chao Chun  and
      Su, Keh Yih",
    journal = "ACL",
    year = "2020",
    url = "https://aclanthology.org/2020.acl-main.92",
    doi = "10.18653/v1/2020.acl-main.92",
}

@article{koncel-2015-parsing,
    author = {Koncel-Kedziorski, Rik and Hajishirzi, Hannaneh and Sabharwal, Ashish and Etzioni, Oren and Ang, Siena
                            Dumas},
    title = "{Parsing Algebraic Word Problems into Equations}",
    journal = {TACL},
    year = {2015},
    doi = {10.1162/tacl_a_00160},
    url = {https://doi.org/10.1162/tacl\_a\_00160},
    eprint = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl\_a\_00160/1566814/tacl\_a\_00160.pdf},
}

@article{roy-roth-2015-solving,
    title = "Solving General Arithmetic Word Problems",
    author = "Roy, Subhro  and
      Roth, Dan",
    journal = "EMNLP",
    year = "2015",
    url = "https://aclanthology.org/D15-1202",
    doi = "10.18653/v1/D15-1202",
    
}

@article{roy-2016-reasoning,
    author = {Roy, Subhro and Vieira, Tim and Roth, Dan},
    title = "{Reasoning about Quantities in Natural Language}",
    journal = {TACL},
    year = {2015},
    doi = {10.1162/tacl_a_00118},
    url = {https://doi.org/10.1162/tacl\_a\_00118},
    eprint = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl\_a\_00118/1566734/tacl\_a\_00118.pdf},
}



@article{hosseini-etal-2014-learning,
    title = "Learning to Solve Arithmetic Word Problems with Verb Categorization",
    author = "Hosseini, Mohammad Javad  and
      Hajishirzi, Hannaneh  and
      Etzioni, Oren  and
      Kushman, Nate",
    journal = "EMNLP",
    year = "2014",
    url = "https://aclanthology.org/D14-1058",
    doi = "10.3115/v1/D14-1058",
    
}

@article{koncel-kedziorski-etal-2016-mawps,
    title = "{MAWPS}: A Math Word Problem Repository",
    author = "Koncel-Kedziorski, Rik  and
      Roy, Subhro  and
      Amini, Aida  and
      Kushman, Nate  and
      Hajishirzi, Hannaneh",
    journal = "NAACL",
    year = "2016",
    url = "https://aclanthology.org/N16-1136",
    doi = "10.18653/v1/N16-1136",
}

@inproceedings{amini-etal-2019-mathqa,
    title = "{M}ath{QA}: Towards Interpretable Math Word Problem Solving with Operation-Based Formalisms",
    author = "Amini, Aida  and
      Gabriel, Saadia  and
      Lin, Shanchuan  and
      Koncel-Kedziorski, Rik  and
      Choi, Yejin  and
      Hajishirzi, Hannaneh",
    booktitle = "NAACL",
    year = "2019",
    url = "https://aclanthology.org/N19-1245",
    doi = "10.18653/v1/N19-1245",
}


@article{saeed-etal-2021-rulebert,
    title = "{R}ule{BERT}: Teaching Soft Rules to Pre-Trained Language Models",
    author = "Saeed, Mohammed  and
      Ahmadi, Naser  and
      Nakov, Preslav  and
      Papotti, Paolo",
    journal = "EMNLP",
    year = "2021",
    url = "https://aclanthology.org/2021.emnlp-main.110",
    doi = "10.18653/v1/2021.emnlp-main.110",
}

@article{recchia2021teaching,
  title={Teaching Autoregressive Language Models Complex Tasks By Demonstration},
  author={Recchia, Gabriel},
  journal={arXiv preprint arXiv:2109.02102},
  year={2021},
  url={https://arxiv.org/abs/2109.02102}
}

@article{clark2020transformers,
  title={Transformers as soft reasoners over language},
  author={Clark, Peter and Tafjord, Oyvind and Richardson, Kyle},
  journal={IJCAI},
  year={2020},
  url={https://www.ijcai.org/proceedings/2020/0537.pdf}
}

@article{talmor2020leap,
  title={Leap-of-thought: Teaching pre-trained models to systematically reason over implicit knowledge},
  author={Talmor, Alon and Tafjord, Oyvind and Clark, Peter and Goldberg, Yoav and Berant, Jonathan},
  journal={NeurIPS},
  year={2020},
  url={https://arxiv.org/abs/2006.06609}
}

@article{wiegreffe2021reframing,
  title={Reframing Human-{AI} Collaboration for Generating Free-Text Explanations},
  author={Wiegreffe, Sarah and Hessel, Jack and Swayamdipta, Swabha and Riedl, Mark and Choi, Yejin},
  journal={NAACL},
  year={2022},
  url={https://arxiv.org/abs/2112.08674},
}

@article{hu-etal-2019-multi,
    title = "A Multi-Type Multi-Span Network for Reading Comprehension that Requires Discrete Reasoning",
    author = "Hu, Minghao  and
      Peng, Yuxing  and
      Huang, Zhen  and
      Li, Dongsheng",
    journal = "EMNLP",
    year = "2019",
    url = "https://aclanthology.org/D19-1170",
    doi = "10.18653/v1/D19-1170",
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Hilton, Jacob and Nakano, Reiichiro and Hesse, Christopher and Schulman, John},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021},
  url={https://arxiv.org/abs/2110.14168}
}

@article{reif2021recipe,
  title={A recipe for arbitrary text style transfer with large language models},
  author={Reif, Emily and Ippolito, Daphne and Yuan, Ann and Coenen, Andy and Callison-Burch, Chris and Wei, Jason},
  journal={ACL},
  year={2022},
  url={https://arxiv.org/abs/2109.03910}
}

@article{nye2021show,
  title={Show Your Work: Scratchpads for Intermediate Computation with Language Models},
  author={Nye, Maxwell and Andreassen, Anders Johan and Gur-Ari, Guy and Michalewski, Henryk and Austin, Jacob and Bieber, David and Dohan, David and Lewkowycz, Aitor and Bosma, Maarten and Luan, David and others},
  journal={arXiv preprint arXiv:2112.00114},
  year={2021},
  url={http://arxiv.org/abs/2112.00114},
}

@article{perez2022announcing,
  title={Announcing the Inverse Scaling Prize (\$250k Prize Pool)},
  author={Ian McKenzie and Alexander Lyzhov and Alicia Parrish and Ameya Prabhu and Aaron Mueller and Najoung Kim and Sam Bowman and Ethan Perez},
  journal={Lesswrong},
  year={2022},
  url={https://www.lesswrong.com/posts/eqxqgFxymP8hXDTt5/announcing-the-inverse-scaling-prize-usd250k-prize-pool},
}

@article{perez2022roundonewinners,
  title={Inverse Scaling Prize: Round 1 Winners},
  author={Ian McKenzie and Alexander Lyzhov and Alicia Parrish and Ameya Prabhu and Aaron Mueller and Najoung Kim and Sam Bowman and Ethan Perez},
  journal={Lesswrong},
  year={2022},
  url={https://www.lesswrong.com/posts/iznohbCPFkeB9kAJL/inverse-scaling-prize-round-1-winners},
}

@article{steinhardt2022mmluforecast,
  title={Updates and Lessons from AI Forecasting},
  author={Jacob Steinhardt},
  journal={Blog post.},
  year={2021},
  url={https://bounded-regret.ghost.io/ai-forecasting/},
}

@article{wei2022emergent,
  title={Emergent abilities of large language models},
  author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
  journal={TMLR},
  year={2022},
  url={https://openreview.net/forum?id=yzkSU5zdwD},
}

@inproceedings{rajpurkar-etal-2016-squad,
    title = "{SQ}u{AD}: 100,000+ Questions for Machine Comprehension of Text",
    author = "Rajpurkar, Pranav  and
      Zhang, Jian  and
      Lopyrev, Konstantin  and
      Liang, Percy",
    booktitle = "EMNLP",
    month = nov,
    year = "2016",
    address = "Austin, Texas",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D16-1264",
    doi = "10.18653/v1/D16-1264",
    pages = "2383--2392",
}

@inproceedings{huang2023selfimprove,
    title={Large Language Models Can Self-improve},
    author={Jiaxin Huang and Shixiang Shane Gu and Le Hou and Yuexin Wu and Xuezhi Wang and Hongkun Yu and Jiawei Han},
    booktitle={arxiv},
    year={2022},
    url={https://openreview.net/forum?id=NiEtU7blzN},
}

@inproceedings{tay2022transcending,
    title={Transcending scaling laws with 0.1\% extra compute},
    author={Yi Tay and Jason Wei and Hyung Won Chung and David R. So and Siamak Shakeri and Xavier Garcia and Vinh Q. Tran and Hauixiu Steven Zheng and Jinfeng Rao and Denny Zhou and Donald Metzler and Neil Houlsby and Quoc V. Le and Mostafa Dehghani},
    booktitle={arxiv},
    year={2022},
}

@article{wang2022language,
  title={What Language Model Architecture and Pretraining Objective Work Best for Zero-Shot Generalization?},
  author={Wang, Thomas and Roberts, Adam and Hesslow, Daniel and Scao, Teven Le and Chung, Hyung Won and Beltagy, Iz and Launay, Julien and Raffel, Colin},
  journal={ICML},
  year={2022},
  url={https://arxiv.org/abs/2204.05832},
}

@article{lewkowycz2022solving,
  title={Solving quantitative reasoning problems with language models},
  author={Lewkowycz, Aitor and Andreassen, Anders and Dohan, David and Dyer, Ethan and Michalewski, Henryk and Ramasesh, Vinay and Slone, Ambrose and Anil, Cem and Schlag, Imanol and Gutman-Solo, Theo and others},
  journal={arXiv preprint arXiv:2206.14858},
  year={2022},
  url={https://arxiv.org/abs/2206.14858},
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019},
  url={https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf},
}

@article{scialom2022continual,
  title={Continual-{T0}: Progressively Instructing 50+ Tasks to Language Models Without Forgetting},
  author={Scialom, Thomas and Chakrabarty, Tuhin and Muresan, Smaranda},
  journal={arXiv preprint arXiv:2205.12393},
  year={2022},
  url={https://arxiv.org/abs/2205.12393},
}

@inproceedings{shazeer2018adafactor,
  title={Adafactor: Adaptive learning rates with sublinear memory cost},
  author={Shazeer, Noam and Stern, Mitchell},
  booktitle={ICML},
  year={2018},
  url={https://arxiv.org/abs/1804.04235},
}


@inproceedings{camburu-etal-2020-make,
    title = "Make Up Your Mind! {A}dversarial Generation of Inconsistent Natural Language Explanations",
    author = "Camburu, Oana-Maria  and
      Shillingford, Brendan  and
      Minervini, Pasquale  and
      Lukasiewicz, Thomas  and
      Blunsom, Phil",
    booktitle = "ACL",
    year = "2020",
    url = "https://aclanthology.org/2020.acl-main.382",
}


@article{rajani-etal-2019-explain,
    title = "Explain Yourself! {L}everaging Language Models for Commonsense Reasoning",
    author = "Rajani, Nazneen Fatema  and
      McCann, Bryan  and
      Xiong, Caiming  and
      Socher, Richard",
    journal = "ACL",
    year = "2019",
    url = "https://aclanthology.org/P19-1487",
    doi = "10.18653/v1/P19-1487",
}

@article{camburu2018snli,
  title={e-{SNLI}: Natural Language Inference with Natural Language Explanations},
  author={Camburu, Oana-Maria and Rockt{\"a}schel, Tim and Lukasiewicz, Thomas and Blunsom, Phil},
  journal={NeurIPS},
  year={2018},
  url={https://arxiv.org/pdf/1812.01193.pdf}
}

@article{zhong2021meta,
  title={Adapting Language Models for Zero-shot Learning by Meta-tuning on Dataset and Prompt Collections},
  author={Zhong, Ruiqi and Lee, Kristy and Zhang, Zheng and Klein, Dan},
  journal={EMNLP Findings},
  year={2021},
  url={https://aclanthology.org/2021.findings-emnlp.244/},
}

@inproceedings{ye2021crossfit,
  title={CrossFit: A Few-shot Learning Challenge for Cross-task Generalization in {NLP}},
  author={Ye, Qinyuan and Lin, Bill Yuchen and Ren, Xiang},
  booktitle = {EMNLP},
  year={2021},
  url={https://arxiv.org/abs/2104.08835},
}

@article{xue-etal-2022-byt5,
    title = "{B}y{T}5: Towards a Token-Free Future with Pre-trained Byte-to-Byte Models",
    author = "Xue, Linting  and
      Barua, Aditya  and
      Constant, Noah  and
      Al-Rfou, Rami  and
      Narang, Sharan  and
      Kale, Mihir  and
      Roberts, Adam  and
      Raffel, Colin",
    journal = "TACL",
    year = "2022",
    url = "https://aclanthology.org/2022.tacl-1.17",
}

@article{bigbench,
  title={Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models},
  author={Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R. and others},
  journal={arXiv preprint arXiv:2206.04615},
  year={2022},
  url={https://arxiv.org/abs/2206.04615},
}

@inproceedings{bach-etal-2022-promptsource,
    title = "{P}rompt{S}ource: An Integrated Development Environment and Repository for Natural Language Prompts",
    author = "Bach, Stephen  and
      Sanh, Victor  and
      Yong, Zheng Xin  and
      Webson, Albert  and
      Raffel, Colin  and
      Nayak, Nihal V.  and
      Sharma, Abheesht  and
      Kim, Taewoon  and
      Bari, M Saiful  and
      Fevry, Thibault  and
      Alyafeai, Zaid  and
      Dey, Manan  and
      Santilli, Andrea  and
      Sun, Zhiqing  and
      Ben-david, Srulik  and
      Xu, Canwen  and
      Chhablani, Gunjan  and
      Wang, Han  and
      Fries, Jason  and
      Al-shaibani, Maged  and
      Sharma, Shanya  and
      Thakker, Urmish  and
      Almubarak, Khalid  and
      Tang, Xiangru  and
      Radev, Dragomir  and
      Jiang, Mike Tian-jian  and
      Rush, Alexander",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-demo.9",
    doi = "10.18653/v1/2022.acl-demo.9",
    pages = "93--104",
    abstract = "PromptSource is a system for creating, sharing, and using natural language prompts. Prompts are functions that map an example from a dataset to a natural language input and target output. Using prompts to train and query language models is an emerging area in NLP that requires new tools that let users develop and refine these prompts collaboratively. PromptSource addresses the emergent challenges in this new setting with (1) a templating language for defining data-linked prompts, (2) an interface that lets users quickly iterate on prompt development by observing outputs of their prompts on many examples, and (3) a community-driven set of guidelines for contributing new prompts to a common pool. Over 2,000 prompts for roughly 170 datasets are already available in PromptSource. PromptSource is available at https://github.com/bigscience-workshop/promptsource.",
}

@article{wiegreffe2021teach,
  title={Teach me to explain: A review of datasets for explainable {NLP}},
  author={Wiegreffe, Sarah and Marasovi{\'c}, Ana},
  journal={NeurIPS},
  year={2021},
  url={https://arxiv.org/abs/2102.12060}
}


@article{talmor2022commonsenseqa,
  title={Commonsense{QA} 2.0: {E}xposing the limits of AI through gamification},
  author={Talmor, Alon and Yoran, Ori and Bras, Ronan Le and Bhagavatula, Chandra and Goldberg, Yoav and Choi, Yejin and Berant, Jonathan},
  journal={NeurIPS Track on Datasets and Benchmarks},
  year={2021},
  url={https://arxiv.org/abs/2201.05320}
}

@inproceedings{ganguli2022predictability,
  title={Predictability and surprise in large generative models},
  author={Ganguli, Deep and Hernandez, Danny and Lovitt, Liane and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and Dassarma, Nova and Drain, Dawn and Elhage, Nelson and others},
  booktitle={2022 ACM Conference on Fairness, Accountability, and Transparency},
  pages={1747--1764},
  year={2022},
  url={https://dl.acm.org/doi/abs/10.1145/3531146.3533229},
}

@article{zoph2022designing,
  title={Designing effective sparse expert models},
  author={Zoph, Barret and Bello, Irwan and Kumar, Sameer and Du, Nan and Huang, Yanping and Dean, Jeff and Shazeer, Noam and Fedus, William},
  journal={arXiv preprint arXiv:2202.08906},
  year={2022},
  url={https://arxiv.org/abs/2202.08906}
}

@article{liu2021pre,
  title={Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing},
  author={Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  journal={arXiv preprint arXiv:2107.13586},
  year={2021},
  url={https://arxiv.org/abs/2107.13586}
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
   author={Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William Saunders and Christopher Hesse and Andrew N. Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021},
  url={https://arxiv.org/abs/2107.03374}
}

@article{li2021eye,
  title={In the eye of the beholder: Gaze and actions in first person video},
  author={Li, Yin and Liu, Miao and Rehg, James M},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={45},
  number={6},
  pages={6731--6747},
  year={2021},
  publisher={IEEE}
}

@inproceedings{wang2023holoassist,
  title={Holoassist: an egocentric human interaction dataset for interactive {AI} assistants in the real world},
  author={Wang, Xin and Kwon, Taein and Rad, Mahdi and Pan, Bowen and Chakraborty, Ishani and Andrist, Sean and Bohus, Dan and Feniello, Ashley and Tekin, Bugra and Frujeri, Felipe Vieira and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={20270--20281},
  year={2023}
}

@misc{umi_data,
  author = {{UMI-Data}},
  title = {{UMI-Data}},
  url = {https://umi-data.github.io/},
  year={2024}
}

@inproceedings{grauman2022ego4d,
  title={Ego4d: Around the world in 3,000 hours of egocentric video},
  author={Grauman, Kristen and Westbury, Andrew and Byrne, Eugene and Chavis, Zachary and Furnari, Antonino and Girdhar, Rohit and Hamburger, Jackson and Jiang, Hao and Liu, Miao and Liu, Xingyu and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18995--19012},
  year={2022}
}


@inproceedings{10611477,
  author={O'Neill, Abby and Rehman, Abdul and Gupta, Abhinav and Maddukuri, Abhiram and Gupta, Abhishek and Padalkar, Abhishek and Lee, Abraham and Pooley, Acorn and Gupta, Agrim and Mandlekar, Ajay and others},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title="{Open X-Embodiment: Robotic Learning Datasets and RT-X Models : Open X-Embodiment Collaboration}", 
  year={2024},
  volume={},
  number={},
  pages={6892-6903},
  keywords={Learning systems;Adaptation models;Computer vision;Computational modeling;Collaboration;Data models;Task analysis},
  doi={10.1109/ICRA57147.2024.10611477}}


@article{li-liang-2021-prefix,
    title = "Prefix-Tuning: Optimizing Continuous Prompts for Generation",
    author = "Li, Xiang Lisa  and
      Liang, Percy",
    journal = "ACL",
    year = "2021",
    url = "https://aclanthology.org/2021.acl-long.353",
    doi = "10.18653/v1/2021.acl-long.353",
}

@article{gao-etal-2021-making,
    title = "Making Pre-trained Language Models Better Few-shot Learners",
    author = "Gao, Tianyu  and
      Fisch, Adam  and
      Chen, Danqi",
    journal = "ACL",
    year = "2021",
    url = "https://aclanthology.org/2021.acl-long.295",
    doi = "10.18653/v1/2021.acl-long.295",
}

@article{li2022advance,
  title={On the Advance of Making Language Models Better Reasoners},
  author={Li, Yifei and Lin, Zeqi and Zhang, Shizhuo and Fu, Qiang and Chen, Bei and Lou, Jian-Guang and Chen, Weizhu},
  journal={arXiv preprint arXiv:2206.02336},
  year={2022},
  url={https://arxiv.org/abs/2206.02336}
}

@inproceedings{xu-etal-2021-fusing,
    title = "Fusing Context Into Knowledge Graph for Commonsense Question Answering",
    author = "Xu, Yichong  and
      Zhu, Chenguang  and
      Xu, Ruochen  and
      Liu, Yang  and
      Zeng, Michael  and
      Huang, Xuedong",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-acl.102",
    doi = "10.18653/v1/2021.findings-acl.102",
    pages = "1201--1207",
}

@article{geva-etal-2021-aristotle,
    title = "Did Aristotle Use a Laptop? {A} Question Answering Benchmark with Implicit Reasoning Strategies",
    author = "Geva, Mor  and
      Khashabi, Daniel  and
      Segal, Elad  and
      Khot, Tushar  and
      Roth, Dan  and
      Berant, Jonathan",
    journal = "TACL",
    year = "2021",
    url = "https://aclanthology.org/2021.tacl-1.21",
    doi = "10.1162/tacl_a_00370",
}


@book{williamjames,
  title={The Principles of Psychology},
  author={James, William},
  volume={1},
  year={1890},
  publisher={Cosimo}
}

@article{narang2020wt5,
  title={{WT5}?! {T}raining text-to-text models to explain their predictions},
  author={Narang, Sharan and Raffel, Colin and Lee, Katherine and Roberts, Adam and Fiedel, Noah and Malkan, Karishma},
  journal={arXiv preprint arXiv:2004.14546},
  year={2020},
  url={https://arxiv.org/abs/2004.14546}
}

@book{joyce-1922-ulysses,
  title={Ulysses},
  author={James Joyce},
  year={1922},
  publisher={Shakespeare and Company},
}

@article{geva-etal-2020-injecting,
    title = "Injecting Numerical Reasoning Skills into Language Models",
    author = "Geva, Mor  and
      Gupta, Ankit  and
      Berant, Jonathan",
    journal = "ACL",
    year = "2020",
    url = "https://aclanthology.org/2020.acl-main.89",
    doi = "10.18653/v1/2020.acl-main.89",
}

@article{andor-etal-2019-giving,
    title = "Giving {BERT} a Calculator: Finding Operations and Arguments with Reading Comprehension",
    author = "Andor, Daniel  and
      He, Luheng  and
      Lee, Kenton  and
      Pitler, Emily",
    journal = "EMNLP",
    year = "2019",
    url = "https://aclanthology.org/D19-1609",
    doi = "10.18653/v1/D19-1609",
}

@article{piekos-etal-2021-measuring,
    title = "Measuring and Improving {BERT}{'}s Mathematical Abilities by Predicting the Order of Reasoning.",
    author = "Pi{\k{e}}kos, Piotr  and
      Malinowski, Mateusz  and
      Michalewski, Henryk",
    journal = "ACL",
    year = "2021",
    url = "https://aclanthology.org/2021.acl-short.49",
    doi = "10.18653/v1/2021.acl-short.49",
}

@article{drori2021neural,
  title={A Neural Network Solves and Generates Mathematics Problems by Program Synthesis: Calculus, Differential Equations, Linear Algebra, and More},
  author={Drori, Iddo and Tran, Sunny and Wang, Roman and Cheng, Newman and Liu, Kevin and Tang, Leonard and Ke, Elizabeth and Singh, Nikhil and Patti, Taylor L and Lynch, Jayson and others},
  journal={arXiv preprint arXiv:2112.15594},
  year={2021},
  url={https://arxiv.org/abs/2112.15594}
}

@article{hancock-etal-2018-training,
    title = "Training Classifiers with Natural Language Explanations",
    author = "Hancock, Braden  and
      Varma, Paroma  and
      Wang, Stephanie  and
      Bringmann, Martin  and
      Liang, Percy  and
      R{\'e}, Christopher",
    journal = "ACL",
    year = "2018",
    url = "https://aclanthology.org/P18-1175",
    doi = "10.18653/v1/P18-1175",
}

@article{rajagopal2021selfexplain,
    title = "{SelfExplain}: A Self-Explaining Architecture for Neural Text Classifiers",
    author = "Rajagopal, Dheeraj  and
      Balachandran, Vidhisha  and
      Hovy, Eduard H.  and
      Tsvetkov, Yulia",
    journal = "EMNLP",
    year = "2021",
    url = "https://aclanthology.org/2021.emnlp-main.64",
    doi = "10.18653/v1/2021.emnlp-main.64",
}

@article{marasovic-etal-2020-natural,
    title = "Natural Language Rationales with Full-Stack Visual Reasoning: From Pixels to Semantic Frames to Commonsense Graphs",
    author = "Marasovi{\'c}, Ana  and
      Bhagavatula, Chandra  and
      Park, Jae sung  and
      Le Bras, Ronan  and
      Smith, Noah A.  and
      Choi, Yejin",
    journal = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    year = "2020",
    url = "https://aclanthology.org/2020.findings-emnlp.253",
    doi = "10.18653/v1/2020.findings-emnlp.253",
}

@article{bostrom-etal-2021-flexible,
    title = "Flexible Generation of Natural Language Deductions",
    author = "Bostrom, Kaj  and
      Zhao, Xinyu  and
      Chaudhuri, Swarat  and
      Durrett, Greg",
    journal = "EMNLP",
    year = "2021",
    url = "https://aclanthology.org/2021.emnlp-main.506",
    doi = "10.18653/v1/2021.emnlp-main.506",
}

@article{majumder2021rationale,
  title={Rationale-inspired natural language explanations with commonsense},
  author={Majumder, Bodhisattwa Prasad and Camburu, Oana-Maria and Lukasiewicz, Thomas and McAuley, Julian},
  journal={arXiv preprint arXiv:2106.13876},
  year={2021},
  url={https://arxiv.org/abs/2106.13876}
}

@inproceedings{min-etal-2022-metaicl,
    title = "{M}eta{ICL}: Learning to Learn In Context",
    author = "Min, Sewon  and
      Lewis, Mike  and
      Zettlemoyer, Luke  and
      Hajishirzi, Hannaneh",
    booktitle = "NAACL",
    year = "2022",
    url = "https://aclanthology.org/2022.naacl-main.201",
}

@inproceedings{aghajanyan-etal-2021-muppet,
    title = "Muppet: Massive Multi-task Representations with Pre-Finetuning",
    author = "Aghajanyan, Armen  and
      Gupta, Anchit  and
      Shrivastava, Akshat  and
      Chen, Xilun  and
      Zettlemoyer, Luke  and
      Gupta, Sonal",
    booktitle = "EMNLP",
    year = "2021",
    url = "https://aclanthology.org/2021.emnlp-main.468",
}

@inproceedings{anantha-etal-2021-open,
    title = "Open-Domain Question Answering Goes Conversational via Question Rewriting",
    author = "Anantha, Raviteja  and
      Vakulenko, Svitlana  and
      Tu, Zhucheng  and
      Longpre, Shayne  and
      Pulman, Stephen  and
      Chappidi, Srinivas",
    booktitle = "NAACL",
    year = "2021",
    url = "https://aclanthology.org/2021.naacl-main.44/",
}

@inproceedings{yasunaga2020graph,
  title={Graph-based, self-supervised program repair from diagnostic feedback},
  author={Yasunaga, Michihiro and Liang, Percy},
  booktitle={ICML},
  year={2020},
  url={http://go/arxiv/2005.10636},
}

@article{li2022competition,
  title={Competition-level code generation with alphacode},
  author={Li, Yujia and Choi, David and Chung, Junyoung and Kushman, Nate and Schrittwieser, Julian and Leblond, R{\'e}mi and Eccles, Tom and Keeling, James and Gimeno, Felix and Lago, Agustin Dal and others},
  journal={arXiv preprint arXiv:2203.07814},
  year={2022},
  url={http://go/arxiv/2203.07814},
}

@inproceedings{byrne-etal-2019-taskmaster,
    title = "Taskmaster-1: {T}oward a Realistic and Diverse Dialog Dataset",
    author = "Byrne, Bill  and
      Krishnamoorthi, Karthik  and
      Sankar, Chinnadhurai  and
      Neelakantan, Arvind  and
      Goodrich, Ben  and
      Duckworth, Daniel  and
      Yavuz, Semih  and
      Dubey, Amit  and
      Kim, Kyu-Young  and
      Cedilnik, Andy",
    booktitle = "EMNLP",
    year = "2019",
    url = "https://aclanthology.org/D19-1459",
    doi = "10.18653/v1/D19-1459",
}

@InProceedings{pmlr-v162-dai22a,
  title = 	 {Dialog Inpainting: Turning Documents into Dialogs},
  author =       {Dai, Zhuyun and Chaganty, Arun Tejasvi and Zhao, Vincent Y and Amini, Aida and Rashid, Qazi Mamunur and Green, Mike and Guu, Kelvin},
  booktitle = 	 {ICML},
  year = 	 {2022},
  pdf = 	 {https://proceedings.mlr.press/v162/dai22a/dai22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/dai22a.html},
}


@article{hendricks2016generating,
  title={Generating visual explanations},
  author={Hendricks, Lisa Anne and Akata, Zeynep and Rohrbach, Marcus and Donahue, Jeff and Schiele, Bernt and Darrell, Trevor},
  journal={European conference on computer vision},
  pages={3--19},
  year={2016},
  organization={Springer}
}

@article{marasovic2021few,
  title={Few-Shot Self-Rationalization with Natural Language Prompts},
  author={Marasovi{\'c}, Ana and Beltagy, Iz and Downey, Doug and Peters, Matthew E},
  journal={NAACL Findings},
  year={2022},
  url={http://arxiv.org/abs/2111.08284},
}

@article{wang2019superglue,
  title={Super{G}lue: A stickier benchmark for general-purpose language understanding systems},
  author={Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel},
  journal={NeurIPS},
  year={2019},
  url={http://go/arxiv/1905.00537}
}

@article{yordanov2021few,
  title={Few-Shot Out-of-Domain Transfer Learning of Natural Language Explanations},
  author={Yordanov, Yordan and Kocijan, Vid and Lukasiewicz, Thomas and Camburu, Oana-Maria},
  journal={arXiv preprint arXiv:2112.06204},
  year={2021},
  url={http://arxiv.org/abs/2112.06204},
}

@article{chen2020compositional,
  title={Compositional Generalization via Neural-Symbolic Stack Machines},
  author={Chen, Xinyun and Liang, Chen and Yu, Adams Wei and Song, Dawn and Zhou, Denny},
  journal={NeurIPS},
  volume={33},
  year={2020}
}

@article{hase2021can,
  title={When can models learn from explanations? a formal framework for understanding the roles of explanation data},
  author={Hase, Peter and Bansal, Mohit},
  journal={ACL},
  year={2022},
  url={https://arxiv.org/abs/2102.02201},
}

@article{le-scao-rush-2021-many,
    title = "How many data points is a prompt worth?",
    author = "Le Scao, Teven  and
      Rush, Alexander",
    journal = "NAACL",
    year = "2021",
    url = "https://aclanthology.org/2021.naacl-main.208",
    doi = "10.18653/v1/2021.naacl-main.208",
}

@article{reynolds2021prompt,
  title={Prompt programming for large language models: Beyond the few-shot paradigm},
  author={Reynolds, Laria and McDonell, Kyle},
  journal={Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
  year={2021},
  url={https://arxiv.org/abs/2102.07350},
}

@article{lev-etal-2004-solving,
    title = "Solving logic puzzles: From robust processing to precise semantics",
    author = "Lev, Iddo  and
      MacCartney, Bill  and
      Manning, Christopher  and
      Levy, Roger",
    journal = "Proceedings of the 2nd Workshop on Text Meaning and Interpretation",
    year = "2004",
    url = "https://aclanthology.org/W04-0902",
}

@article{Lourie2021UNICORNOR,
  title={{UNICORN} on {RAINBOW}: A Universal Commonsense Reasoning Model on a New Multitask Benchmark},
  author={Nicholas Lourie and Ronan {Le Bras} and Chandra Bhagavatula and Yejin Choi},
  journal={AAAI},
  year={2021},
  url={https://arxiv.org/abs/2103.13009}
}

@article{aribandi2021ext5,
  title={Ext5: Towards extreme multi-task scaling for transfer learning},
  author={Aribandi, Vamsi and Tay, Yi and Schuster, Tal and Rao, Jinfeng and Zheng, Huaixiu Steven and Mehta, Sanket Vaibhav and Zhuang, Honglei and Tran, Vinh Q and Bahri, Dara and Ni, Jianmo and others},
  journal={arXiv preprint arXiv:2111.10952},
  year={2021},
  url={https://arxiv.org/abs/2111.10952}
}

@ARTICLE{du_glam_2021,
       author = {{Du}, Nan and {Huang}, Yanping and {Dai}, Andrew M. and {Tong}, Simon and {Lepikhin}, Dmitry and {Xu}, Yuanzhong and {Krikun}, Maxim and {Zhou}, Yanqi and {Yu}, Adams Wei and {Firat}, Orhan and {Zoph}, Barret and {Fedus}, Liam and {Bosma}, Maarten and {Zhou}, Zongwei and {Wang}, Tao and {Wang}, Yu Emma and {Webster}, Kellie and {Pellat}, Marie and {Robinson}, Kevin and {Meier-Hellstern}, Kathleen and {Duke}, Toju and {Dixon}, Lucas and {Zhang}, Kun and {Le}, Quoc V and {Wu}, Yonghui and {Chen}, Zhifeng and {Cui}, Claire},
        title = "{GLaM: Efficient Scaling of Language Models with Mixture-of-Experts}",
      journal = {ICML},
         year = 2022,
         url = {https://arxiv.org/abs/2112.06905},
}

@inproceedings{paperno-etal-2016-lambada,
    title = "The {LAMBADA} dataset: Word prediction requiring a broad discourse context",
    author = "Paperno, Denis  and
      Kruszewski, Germ{\'a}n  and
      Lazaridou, Angeliki  and
      Pham, Ngoc Quan  and
      Bernardi, Raffaella  and
      Pezzelle, Sandro  and
      Baroni, Marco  and
      Boleda, Gemma  and
      Fern{\'a}ndez, Raquel",
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P16-1144",
    doi = "10.18653/v1/P16-1144",
    pages = "1525--1534",
}

@inproceedings{khashabi-etal-2020-unifiedqa,
    title = "{UnifiedQA}: Crossing Format Boundaries with a Single {QA} System",
    author = "Khashabi, Daniel  and
      Min, Sewon  and
      Khot, Tushar  and
      Sabharwal, Ashish  and
      Tafjord, Oyvind  and
      Clark, Peter  and
      Hajishirzi, Hannaneh",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    year = "2020",
    url = "https://aclanthology.org/2020.findings-emnlp.171",
}

@inproceedings{vit,
title        = {An Image is Worth 16x16 Words: Transformers for Image Recognition
                  at Scale},
  author       = {Alexey Dosovitskiy and
                  Lucas Beyer and
                  Alexander Kolesnikov and
                  Dirk Weissenborn and
                  Xiaohua Zhai and
                  Thomas Unterthiner and
                  Mostafa Dehghani and
                  Matthias Minderer and
                  Georg Heigold and
                  Sylvain Gelly and
                  Jakob Uszkoreit and
                  Neil Houlsby},
  year         = {2020},
  booktitle   = {ICLR},
}

@misc{https://doi.org/10.48550/arxiv.2101.02235,
  doi = {10.48550/ARXIV.2101.02235},
  url = {https://arxiv.org/abs/2101.02235},
  author = {Geva, Mor and Khashabi, Daniel and Segal, Elad and Khot, Tushar and Roth, Dan and Berant, Jonathan},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Did Aristotle Use a Laptop? A Question Answering Benchmark with Implicit Reasoning Strategies}
},

@misc{openmathinstruct,
      title={OpenMathInstruct-1: A 1.8 Million Math Instruction Tuning Dataset}, 
      author={Shubham Toshniwal and Ivan Moshkov and Sean Narenthiran and Daria Gitman and Fei Jia and Igor Gitman},
      year={2024},
      eprint={2402.10176},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{orpo,
      title={Large Language Models as Optimizers}, 
      author={Chengrun Yang and Xuezhi Wang and Yifeng Lu and Hanxiao Liu and Quoc V. Le and Denny Zhou and Xinyun Chen},
      year={2023},
      eprint={2309.03409},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{promptbreeder,
      title={Promptbreeder: Self-Referential Self-Improvement Via Prompt Evolution}, 
      author={Chrisantha Fernando and Dylan Banarse and Henryk Michalewski and Simon Osindero and Tim Rocktäschel},
      year={2023},
      eprint={2309.16797},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{onoe2021creak,
  title={{CREAK}: A Dataset for Commonsense Reasoning over Entity Knowledge},
  author={Onoe, Yasumasa and Zhang, Michael JQ and Choi, Eunsol and Durrett, Greg},
  booktitle={NeurIPS Datasets and Benchmarks Track (Round 2)},
  year={2021},
  url={https://arxiv.org/abs/2109.01653},
}

@inproceedings{aggarwal-etal-2021-explanations,
    title = "{E}xplanations for {C}ommonsense{QA}: {N}ew {D}ataset and {M}odels",
    author = "Aggarwal, Shourya  and
      Mandowara, Divyanshu  and
      Agrawal, Vishwajeet  and
      Khandelwal, Dinesh  and
      Singla, Parag  and
      Garg, Dinesh",
    booktitle = "ACL",
    year = "2021",
    url = "https://aclanthology.org/2021.acl-long.238",
}

@inproceedings{khot2020qasc,
  title={{QASC}: A dataset for question answering via sentence composition},
  author={Khot, Tushar and Clark, Peter and Guerquin, Michal and Jansen, Peter and Sabharwal, Ashish},
  booktitle={AAAI},
  year={2020},
  url={https://arxiv.org/abs/1910.11473},
}

@article{lamm2021qed,
  title={{QED}: A framework and dataset for explanations in question answering},
  author={Lamm, Matthew and Palomaki, Jennimaria and Alberti, Chris and Andor, Daniel and Choi, Eunsol and Soares, Livio Baldini and Collins, Michael},
  journal={TACL},
  volume={9},
  pages={790--806},
  year={2021},
  publisher={MIT Press},
  url={https://arxiv.org/abs/2009.06354},
}

@inproceedings{wang2019does,
  title={Does it Make Sense? {A}nd Why? {A} Pilot Study for Sense Making and Explanation},
  author={Wang, Cunxiang and Liang, Shuailong and Zhang, Yue and Li, Xiaonan and Gao, Tian},
  booktitle={ACL},
  year={2019},
  url={https://arxiv.org/abs/1906.00363},
}


@ARTICLE{2022_palm_saycan,
       author = {{Ahn}, Michael and {Brohan}, Anthony and {Brown}, Noah and {Chebotar}, Yevgen and {Cortes}, Omar and {David}, Byron and {Finn}, Chelsea and {Fu}, Chuyuan and {Gopalakrishnan}, Keerthana and {Hausman}, Karol and {Herzog}, Alex and {Ho}, Daniel and {Hsu}, Jasmine and {Ibarz}, Julian and {Ichter}, Brian and {Irpan}, Alex and {Jang}, Eric and {Jauregui Ruano}, Rosario and {Jeffrey}, Kyle and {Jesmonth}, Sally and {Joshi}, Nikhil J and {Julian}, Ryan and {Kalashnikov}, Dmitry and {Kuang}, Yuheng and {Lee}, Kuang-Huei and {Levine}, Sergey and {Lu}, Yao and {Luu}, Linda and {Parada}, Carolina and {Pastor}, Peter and {Quiambao}, Jornell and {Rao}, Kanishka and {Rettinghouse}, Jarek and {Reyes}, Diego and {Sermanet}, Pierre and {Sievers}, Nicolas and {Tan}, Clayton and {Toshev}, Alexander and {Vanhoucke}, Vincent and {Xia}, Fei and {Xiao}, Ted and {Xu}, Peng and {Xu}, Sichun and {Yan}, Mengyuan and {Zeng}, Andy},
        title = "{Do As I Can, Not As I Say: Grounding Language in Robotic Affordances}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Robotics, Computer Science - Computation and Language, Computer Science - Machine Learning},
         year = 2022,
        month = apr,
          eid = {arXiv:2204.01691},
        pages = {arXiv:2204.01691},
archivePrefix = {arXiv},
       eprint = {2204.01691},
 primaryClass = {cs.RO},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220401691A},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@article{roberts2022t5x,
  url = {https://arxiv.org/abs/2203.17189},
  author = {Roberts, Adam and Chung, Hyung Won and Levskaya, Anselm and Mishra, Gaurav and Bradbury, James and Andor, Daniel and Narang, Sharan and Lester, Brian and Gaffney, Colin and Mohiuddin, Afroz and Hawthorne, Curtis and Lewkowycz, Aitor and Salcianu, Alex and van Zee, Marc and Austin, Jacob and Goodman, Sebastian and Soares, Livio Baldini and Hu, Haitang and Tsvyashchenko, Sasha and Chowdhery, Aakanksha and Bastings, Jasmijn and Bulian, Jannis and Garcia, Xavier and Ni, Jianmo and Chen, Andrew and Kenealy, Kathleen and Clark, Jonathan H. and Lee, Stephan and Garrette, Dan and Lee-Thorp, James and Raffel, Colin and Shazeer, Noam and Ritter, Marvin and Bosma, Maarten and Passos, Alexandre and Maitin-Shepard, Jeremy and Fiedel, Noah and Omernick, Mark and Saeta, Brennan and Sepassi, Ryan and Spiridonov, Alexander and Newlan, Joshua and Gesmundo, Andrea},
  title = {Scaling Up Models and Data with $\texttt{t5x}$ and $\texttt{seqio}$},
  journal={arXiv preprint arXiv:2203.17189},
  year = {2022},
  url={https://arxiv.org/abs/2203.17189}
}

@misc{jax2018github,
  author = {James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and George Necula and Adam Paszke and Jake Vander{P}las and Skye Wanderman-{M}ilne and Qiao Zhang},
  title = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
  url = {http://github.com/google/jax},
  version = {0.3.13},
  year = {2018},
}

@article{hoffmann2022training,
  title={Training Compute-Optimal Large Language Models},
  author={Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and others},
  journal={NeurIPS},
  year={2022},
  url={https://arxiv.org/abs/2203.15556},
}

@article{hao2022language,
  title={Language models are general-purpose interfaces},
  author={Hao, Yaru and Song, Haoyu and Dong, Li and Huang, Shaohan and Chi, Zewen and Wang, Wenhui and Ma, Shuming and Wei, Furu},
  journal={arXiv preprint arXiv:2206.06336},
  year={2022},
  url={https://arxiv.org/abs/2206.06336},
}

@article{puri2022many,
  title={How Many Data Samples is an Additional Instruction Worth?},
  author={Puri, Ravsehaj Singh and Mishra, Swaroop and Parmar, Mihir and Baral, Chitta},
  journal={arXiv preprint arXiv:2203.09161},
  year={2022},
  url={https://arxiv.org/abs/2203.09161},
}

@article{padmakumar2022exploring,
  title={Exploring the Role of Task Transferability in Large-Scale Multi-Task Learning},
  author={Padmakumar, Vishakh and Lausen, Leonard and Ballesteros, Miguel and Zha, Sheng and He, He and Karypis, George},
  journal={arXiv preprint arXiv:2204.11117},
  year={2022},
  url={https://aclanthology.org/2022.naacl-main.183/},
}

@inproceedings{rudinger2018gender,
    title = "Gender Bias in Coreference Resolution",
    author = "Rudinger, Rachel  and
      Naradowsky, Jason  and
      Leonard, Brian  and
      Van Durme, Benjamin",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-2002",
    doi = "10.18653/v1/N18-2002",
    pages = "8--14",
    abstract = "We present an empirical study of gender bias in coreference resolution systems. We first introduce a novel, Winograd schema-style set of minimal pair sentences that differ only by pronoun gender. With these {``}Winogender schemas,{''} we evaluate and confirm systematic gender bias in three publicly-available coreference resolution systems, and correlate this bias with real-world and textual gender statistics.",
}

@article{zhao2018gender,
  title={Gender bias in coreference resolution: Evaluation and debiasing methods},
  author={Zhao, Jieyu and Wang, Tianlu and Yatskar, Mark and Ordonez, Vicente and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:1804.06876},
  year={2018}
}
@article{he2023can,
  title={Can Large Language Models Understand Real-World Complex Instructions?},
  author={He, Qianyu and Zeng, Jie and Huang, Wenhao and Chen, Lina and Xiao, Jin and He, Qianxi and Zhou, Xunzhe and Chen, Lida and Wang, Xintao and Huang, Yuncheng and others},
  journal={arXiv preprint arXiv:2309.09150},
  year={2023}
}
@article{xu2023wizardlm,
  title={Wizardlm: Empowering large language models to follow complex instructions},
  author={Xu, Can and Sun, Qingfeng and Zheng, Kai and Geng, Xiubo and Zhao, Pu and Feng, Jiazhan and Tao, Chongyang and Jiang, Daxin},
  journal={arXiv preprint arXiv:2304.12244},
  year={2023}
}

% Mitchell_2019
@inproceedings{mitchell2019model,
  title={Model cards for model reporting},
  author={Mitchell, Margaret and Wu, Simone and Zaldivar, Andrew and Barnes, Parker and Vasserman, Lucy and Hutchinson, Ben and Spitzer, Elena and Raji, Inioluwa Deborah and Gebru, Timnit},
  booktitle={Proceedings of the conference on Fairness, Accountability, and Transparency},
  pages={220--229},
  year={2019}
}

@article{pratap2020mls,
  title={Mls: A large-scale multilingual dataset for speech research},
  author={Pratap, Vineel and Xu, Qiantong and Sriram, Anuroop and Synnaeve, Gabriel and Collobert, Ronan},
  journal={arXiv preprint arXiv:2012.03411},
  year={2020}
}

@inproceedings{pushkarna2021data,
  title={Data Cards: Purposeful and Transparent Dataset Documentation for Responsible AI},
  author={Pushkarna, Mahima and Zaldivar, Andrew and Kjartansson, Oddur},
  booktitle={Data-centric AI Workshop at NeurIPS},
  year={2021},
  url={https://arxiv.org/abs/2204.01075},
}

@article{jouppi2020domain,
  title={A domain-specific supercomputer for training deep neural networks},
  author={Jouppi, Norman P and Yoon, Doe Hyun and Kurian, George and Li, Sheng and Patil, Nishant and Laudon, James and Young, Cliff and Patterson, David},
  journal={Communications of the ACM},
  volume={63},
  number={7},
  pages={67--78},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{kwiatkowski-etal-2019-natural,
    title = "Natural Questions: A Benchmark for Question Answering Research",
    author = "Kwiatkowski, Tom  and
      Palomaki, Jennimaria  and
      Redfield, Olivia  and
      Collins, Michael  and
      Parikh, Ankur  and
      Alberti, Chris  and
      Epstein, Danielle  and
      Polosukhin, Illia  and
      Devlin, Jacob  and
      Lee, Kenton  and
      Toutanova, Kristina  and
      Jones, Llion  and
      Kelcey, Matthew  and
      Chang, Ming-Wei  and
      Dai, Andrew M.  and
      Uszkoreit, Jakob  and
      Le, Quoc  and
      Petrov, Slav",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "7",
    year = "2019",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/Q19-1026",
    doi = "10.1162/tacl_a_00276",
    pages = "452--466",
    abstract = "We present the Natural Questions corpus, a question answering data set. Questions consist of real anonymized, aggregated queries issued to the Google search engine. An annotator is presented with a question along with a Wikipedia page from the top 5 search results, and annotates a long answer (typically a paragraph) and a short answer (one or more entities) if present on the page, or marks null if no long/short answer is present. The public release consists of 307,373 training examples with single annotations; 7,830 examples with 5-way annotations for development data; and a further 7,842 examples with 5-way annotated sequestered as test data. We present experiments validating quality of the data. We also describe analysis of 25-way annotations on 302 examples, giving insights into human variability on the annotation task. We introduce robust metrics for the purposes of evaluating question answering systems; demonstrate high human upper bounds on these metrics; and establish baseline results using competitive methods drawn from related literature.",
}

@inproceedings{rajpurkar-etal-2018-know,
    title = "Know What You Don{'}t Know: Unanswerable Questions for {SQ}u{AD}",
    author = "Rajpurkar, Pranav  and
      Jia, Robin  and
      Liang, Percy",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-2124",
    doi = "10.18653/v1/P18-2124",
    pages = "784--789",
    abstract = "Extractive reading comprehension systems can often locate the correct answer to a question in a context document, but they also tend to make unreliable guesses on questions for which the correct answer is not stated in the context. Existing datasets either focus exclusively on answerable questions, or use automatically generated unanswerable questions that are easy to identify. To address these weaknesses, we present SQuADRUn, a new dataset that combines the existing Stanford Question Answering Dataset (SQuAD) with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQuADRUn, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering. SQuADRUn is a challenging natural language understanding task for existing models: a strong neural system that gets 86{\%} F1 on SQuAD achieves only 66{\%} F1 on SQuADRUn. We release SQuADRUn to the community as the successor to SQuAD.",
}

@inproceedings{joshi-etal-2017-triviaqa,
    title = "{T}rivia{QA}: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension",
    author = "Joshi, Mandar  and
      Choi, Eunsol  and
      Weld, Daniel  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-1147",
    doi = "10.18653/v1/P17-1147",
    pages = "1601--1611",
    abstract = "We present TriviaQA, a challenging reading comprehension dataset containing over 650K question-answer-evidence triples. TriviaQA includes 95K question-answer pairs authored by trivia enthusiasts and independently gathered evidence documents, six per question on average, that provide high quality distant supervision for answering the questions. We show that, in comparison to other recently introduced large-scale datasets, TriviaQA (1) has relatively complex, compositional questions, (2) has considerable syntactic and lexical variability between questions and corresponding answer-evidence sentences, and (3) requires more cross sentence reasoning to find answers. We also present two baseline algorithms: a feature-based classifier and a state-of-the-art neural network, that performs well on SQuAD reading comprehension. Neither approach comes close to human performance (23{\%} and 40{\%} vs. 80{\%}), suggesting that TriviaQA is a challenging testbed that is worth significant future study.",
}

@inproceedings{berant-etal-2013-semantic,
    title = "Semantic Parsing on {F}reebase from Question-Answer Pairs",
    author = "Berant, Jonathan  and
      Chou, Andrew  and
      Frostig, Roy  and
      Liang, Percy",
    booktitle = "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
    month = oct,
    year = "2013",
    address = "Seattle, Washington, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D13-1160",
    pages = "1533--1544",
}

@article{izacard2022atlas,
  title={Atlas: Few-shot learning with retrieval augmented language models},
  author={Izacard, Gautier and Lewis, Patrick and Lomeli, Maria and Hosseini, Lucas and Petroni, Fabio and Schick, Timo and Dwivedi-Yu, Jane and Joulin, Armand and Riedel, Sebastian and Grave, Edouard},
  journal={arXiv preprint arXiv},
  volume={2208},
  year={2022},
  url={https://arxiv.org/abs/2208.03299}
}

@inproceedings{zellers-etal-2019-hellaswag,
    title = "{H}ella{S}wag: Can a Machine Really Finish Your Sentence?",
    author = "Zellers, Rowan  and
      Holtzman, Ari  and
      Bisk, Yonatan  and
      Farhadi, Ali  and
      Choi, Yejin",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1472",
    doi = "10.18653/v1/P19-1472",
    pages = "4791--4800",
    abstract = "Recent work by Zellers et al. (2018) introduced a new task of commonsense natural language inference: given an event description such as {``}A woman sits at a piano,{''} a machine must select the most likely followup: {``}She sets her fingers on the keys.{''} With the introduction of BERT, near human-level performance was reached. Does this mean that machines can perform human level commonsense inference? In this paper, we show that commonsense inference still proves difficult for even state-of-the-art models, by presenting HellaSwag, a new challenge dataset. Though its questions are trivial for humans ({\textgreater}95{\%} accuracy), state-of-the-art models struggle ({\textless}48{\%}). We achieve this via Adversarial Filtering (AF), a data collection paradigm wherein a series of discriminators iteratively select an adversarial set of machine-generated wrong answers. AF proves to be surprisingly robust. The key insight is to scale up the length and complexity of the dataset examples towards a critical {`}Goldilocks{'} zone wherein generated text is ridiculous to humans, yet often misclassified by state-of-the-art models. Our construction of HellaSwag, and its resulting difficulty, sheds light on the inner workings of deep pretrained models. More broadly, it suggests a new path forward for NLP research, in which benchmarks co-evolve with the evolving state-of-the-art in an adversarial way, so as to present ever-harder challenges.",
}

@inproceedings{mostafazadeh-etal-2016-corpus,
    title = "A Corpus and Cloze Evaluation for Deeper Understanding of Commonsense Stories",
    author = "Mostafazadeh, Nasrin  and
      Chambers, Nathanael  and
      He, Xiaodong  and
      Parikh, Devi  and
      Batra, Dhruv  and
      Vanderwende, Lucy  and
      Kohli, Pushmeet  and
      Allen, James",
    booktitle = "Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2016",
    address = "San Diego, California",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N16-1098",
    doi = "10.18653/v1/N16-1098",
    pages = "839--849",
}

@inproceedings{levesque2012winograd,
  title={The winograd schema challenge},
  author={Levesque, Hector and Davis, Ernest and Morgenstern, Leora},
  booktitle={Thirteenth international conference on the principles of knowledge representation and reasoning},
  year={2012}
}

@article{sakaguchi2021winogrande,
  title={Winogrande: An adversarial winograd schema challenge at scale},
  author={Sakaguchi, Keisuke and Bras, Ronan Le and Bhagavatula, Chandra and Choi, Yejin},
  journal={Communications of the ACM},
  volume={64},
  number={9},
  pages={99--106},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@inproceedings{lai-etal-2017-race,
    title = "{RACE}: Large-scale {R}e{A}ding Comprehension Dataset From Examinations",
    author = "Lai, Guokun  and
      Xie, Qizhe  and
      Liu, Hanxiao  and
      Yang, Yiming  and
      Hovy, Eduard",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D17-1082",
    doi = "10.18653/v1/D17-1082",
    pages = "785--794",
    abstract = "We present RACE, a new dataset for benchmark evaluation of methods in the reading comprehension task. Collected from the English exams for middle and high school Chinese students in the age range between 12 to 18, RACE consists of near 28,000 passages and near 100,000 questions generated by human experts (English instructors), and covers a variety of topics which are carefully designed for evaluating the students{'} ability in understanding and reasoning. In particular, the proportion of questions that requires reasoning is much larger in RACE than that in other benchmark datasets for reading comprehension, and there is a significant gap between the performance of the state-of-the-art models (43{\%}) and the ceiling human performance (95{\%}). We hope this new dataset can serve as a valuable resource for research and evaluation in machine comprehension. The dataset is freely available at \url{http://www.cs.cmu.edu/~glai1/data/race/}and the code is available at \url{https://github.com/qizhex/RACE_AR_baselines}.",
}

@misc{openai2023gpt4,
      title={{GPT-4 Technical Report}}, 
      author={OpenAI},
      year={2023},
      month=mar,
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.08774},
}

@inproceedings{bisk2020piqa,
  title={Piqa: Reasoning about physical commonsense in natural language},
  author={Bisk, Yonatan and Zellers, Rowan and Gao, Jianfeng and Choi, Yejin and others},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={05},
  pages={7432--7439},
  year={2020}
}

@article{clark2018think,
  title={Think you have solved question answering? {T}ry arc, the {AI2} reasoning challenge},
  author={Clark, Peter and Cowhey, Isaac and Etzioni, Oren and Khot, Tushar and Sabharwal, Ashish and Schoenick, Carissa and Tafjord, Oyvind},
  journal={arXiv preprint arXiv:1803.05457},
  year={2018},
  url={https://arxiv.org/abs/1803.05457}
}

@inproceedings{mihaylov-etal-2018-suit,
    title = "Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering",
    author = "Mihaylov, Todor  and
      Clark, Peter  and
      Khot, Tushar  and
      Sabharwal, Ashish",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1260",
    doi = "10.18653/v1/D18-1260",
    pages = "2381--2391",
    abstract = "We present a new kind of question answering dataset, OpenBookQA, modeled after open book exams for assessing human understanding of a subject. The open book that comes with our questions is a set of 1326 elementary level science facts. Roughly 6000 questions probe an understanding of these facts and their application to novel situations. This requires combining an open book fact (e.g., metals conduct electricity) with broad common knowledge (e.g., a suit of armor is made of metal) obtained from other sources. While existing QA datasets over documents or knowledge bases, being generally self-contained, focus on linguistic understanding, OpenBookQA probes a deeper understanding of both the topic{---}in the context of common knowledge{---}and the language it is expressed in. Human performance on OpenBookQA is close to 92{\%}, but many state-of-the-art pre-trained QA methods perform surprisingly poorly, worse than several simple neural baselines we develop. Our oracle experiments designed to circumvent the knowledge retrieval bottleneck demonstrate the value of both the open book and additional facts. We leave it as a challenge to solve the retrieval problem in this multi-hop setting and to close the large gap to human performance.",
}


@inproceedings{nie-etal-2020-adversarial,
    title = "Adversarial {NLI}: A New Benchmark for Natural Language Understanding",
    author = "Nie, Yixin  and
      Williams, Adina  and
      Dinan, Emily  and
      Bansal, Mohit  and
      Weston, Jason  and
      Kiela, Douwe",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.441",
    doi = "10.18653/v1/2020.acl-main.441",
    pages = "4885--4901",
    abstract = "We introduce a new large-scale NLI benchmark dataset, collected via an iterative, adversarial human-and-model-in-the-loop procedure. We show that training models on this new dataset leads to state-of-the-art performance on a variety of popular NLI benchmarks, while posing a more difficult challenge with its new test set. Our analysis sheds light on the shortcomings of current state-of-the-art models, and shows that non-expert annotators are successful at finding their weaknesses. The data collection method can be applied in a never-ending learning scenario, becoming a moving target for NLU, rather than a static benchmark that will quickly saturate.",
}

@inproceedings{Hendrycks2021mmlu,
abstract = {We propose a new test to measure a text model's multitask accuracy. The test covers 57 tasks including elementary mathematics, US history, computer science, law, and more. To attain high accuracy on this test, models must possess extensive world knowledge and problem solving ability. We find that while most recent models have near random-chance accuracy, the very largest GPT-3 model improves over random chance by almost 20 percentage points on average. However, on every one of the 57 tasks, the best models still need substantial improvements before they can reach human-level accuracy. Models also have lopsided performance and frequently do not know when they are wrong. Worse, they still have near-random accuracy on some socially important subjects such as morality and law. By comprehensively evaluating the breadth and depth of a model's academic and professional understanding, our test can be used to analyze models across many tasks and to identify important shortcomings.},
annote = {- propose a test that covers elementary mathematics, US history, computer science, law and more topics based on undergraduate and graduate examinations in different fields
- find that most recent models perform on par with chance but GPT-3 performs better},
archivePrefix = {arXiv},
arxivId = {2009.03300},
author = {Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
booktitle = {Proceedings of ICLR 2021},
eprint = {2009.03300},
file = {:Users/ruder/Library/Application Support/Mendeley Desktop/Downloaded/Hendrycks et al. - 2020 - Measuring Massive Multitask Language Understanding.pdf:pdf},
mendeley-groups = {Adaptation/Common sense reasoning},
title = {{Measuring Massive Multitask Language Understanding}},
url = {http://arxiv.org/abs/2009.03300},
year = {2021}
}

@inproceedings{dua-etal-2019-drop,
    title = "{DROP}: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs",
    author = "Dua, Dheeru  and
      Wang, Yizhong  and
      Dasigi, Pradeep  and
      Stanovsky, Gabriel  and
      Singh, Sameer  and
      Gardner, Matt",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1246",
    doi = "10.18653/v1/N19-1246",
    pages = "2368--2378",
    abstract = "Reading comprehension has recently seen rapid progress, with systems matching humans on the most popular datasets for the task. However, a large body of work has highlighted the brittleness of these systems, showing that there is much work left to be done. We introduce a new reading comprehension benchmark, DROP, which requires Discrete Reasoning Over the content of Paragraphs. In this crowdsourced, adversarially-created, 55k-question benchmark, a system must resolve references in a question, perhaps to multiple input positions, and perform discrete operations over them (such as addition, counting, or sorting). These operations require a much more comprehensive understanding of the content of paragraphs, as they remove the paraphrase-and-entity-typing shortcuts available in prior datasets. We apply state-of-the-art methods from both the reading comprehension and semantic parsing literatures on this dataset and show that the best systems only achieve 38.4{\%} F1 on our generalized accuracy metric, while expert human performance is 96{\%}. We additionally present a new model that combines reading comprehension methods with simple numerical reasoning to achieve 51{\%} F1.",
}

@inproceedings{Wang2023,
abstract = {We explore a simple ensemble strategy, self-consistency, that significantly improves the reasoning accuracy of large language models. The idea is to sample a diverse set of outputs from a language model and return the most consistent answer in the set. Such ensembling method improves reasoning accuracy when combined with chain of thought prompting. For arithmetic and commonsense reasoning benchmarks we find that self-consistency yields significant accuracy improvements in a variety of datasets, such as GSM8K (+10%), SVAMP (+14%), MultiArith (+24%), CommonsenseQA (+5%) and ARC (easy +4%, challenge +5%).},
archivePrefix = {arXiv},
arxivId = {2201.11903},
author = {Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed H. and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
booktitle = {Proceedings of ICLR 2023},
eprint = {2201.11903},
file = {:Users/ruder/Library/Application Support/Mendeley Desktop/Downloaded/Wang, Wei, Schuurmans - 2022 - Self-Consistency Improves Chain of Thought Reasoning in Language Models.pdf:pdf},
title = {{Self-Consistency Improves Chain of Thought Reasoning in Language Models}},
year = {2023}
}

@inproceedings{
arenas2023how,
title={How to Prompt Your Robot: A PromptBook for Manipulation Skills with Code as Policies},
author={Montserrat Gonzalez Arenas and Ted Xiao and Sumeet Singh and Vidhi Jain and Allen Z. Ren and Quan Vuong and Jake Varley and Alexander Herzog and Isabel Leal and Sean Kirmani and Dorsa Sadigh and Vikas Sindhwani and Kanishka Rao and Jacky Liang and Andy Zeng},
booktitle={2nd Workshop on Language and Robot Learning: Language as Grounding},
year={2023},
url={https://openreview.net/forum?id=T8AiZj1QdN}
}

@article{Kwon_2024,
   title={Language Models as Zero-Shot Trajectory Generators},
   volume={9},
   ISSN={2377-3774},
   url={http://dx.doi.org/10.1109/LRA.2024.3410155},
   DOI={10.1109/lra.2024.3410155},
   number={7},
   journal={IEEE Robotics and Automation Letters},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Kwon, Teyun and Palo, Norman Di and Johns, Edward},
   year={2024},
   month=jul, pages={6728–6735} }

@inproceedings{ponti-etal-2020-xcopa,
    title = "{XCOPA}: A Multilingual Dataset for Causal Commonsense Reasoning",
    author = "Ponti, Edoardo Maria  and
      Glava{\v{s}}, Goran  and
      Majewska, Olga  and
      Liu, Qianchu  and
      Vuli{\'c}, Ivan  and
      Korhonen, Anna",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.185",
    doi = "10.18653/v1/2020.emnlp-main.185",
    pages = "2362--2376",
    abstract = "In order to simulate human language capacity, natural language processing systems must be able to reason about the dynamics of everyday situations, including their possible causes and effects. Moreover, they should be able to generalise the acquired world knowledge to new languages, modulo cultural differences. Advances in machine reasoning and cross-lingual transfer depend on the availability of challenging evaluation benchmarks. Motivated by both demands, we introduce Cross-lingual Choice of Plausible Alternatives (XCOPA), a typologically diverse multilingual dataset for causal commonsense reasoning in 11 languages, which includes resource-poor languages like Eastern Apur{\'\i}mac Quechua and Haitian Creole. We evaluate a range of state-of-the-art models on this novel dataset, revealing that the performance of current methods based on multilingual pretraining and zero-shot fine-tuning falls short compared to translation-based transfer. Finally, we propose strategies to adapt multilingual models to out-of-sample resource-lean languages where only a small corpus or a bilingual dictionary is available, and report substantial improvements over the random baseline. The XCOPA dataset is freely available at github.com/cambridgeltl/xcopa.",
}

@inproceedings{mgsm,
abstract = {We evaluate the reasoning abilities of large language models in multilingual settings. We introduce the Multilingual Grade School Math (MGSM) benchmark, by manually translating 250 grade-school math problems from the GSM8K dataset (Cobbe et al., 2021) into ten typologically diverse languages. We find that the ability to solve MGSM problems via chain-of-thought prompting emerges with increasing model scale, and that models have strikingly strong multilingual reasoning abilities, even in underrepresented languages such as Bengali and Swahili. Finally, we show that the multilingual reasoning abilities of language models extend to other tasks such as commonsense reasoning and word-in-context semantic judgment. The MGSM benchmark is publicly available at https://github.com/google-research/url-nlp.},
archivePrefix = {arXiv},
arxivId = {2210.03057},
author = {Shi, Freda and Suzgun, Mirac and Freitag, Markus and Wang, Xuezhi and Srivats, Suraj and Vosoughi, Soroush and Chung, Hyung Won and Tay, Yi and Ruder, Sebastian and Zhou, Denny and Das, Dipanjan and Wei, Jason},
booktitle = {Proceedings of ICLR 2023},
eprint = {2210.03057},
file = {:Users/ruder/Documents/Papers/2210.03057.pdf:pdf},
title = {{Language Models are Multilingual Chain-of-Thought Reasoners}},
url = {http://arxiv.org/abs/2210.03057},
year = {2023}
}


@article{vilar2022prompting,
  title={Prompting PaLM for Translation: Assessing Strategies and Performance},
  author={Vilar, David and Freitag, Markus and Cherry, Colin and Luo, Jiaming and Ratnakar, Viresh and Foster, George},
  journal={arXiv preprint arXiv:2211.09102},
  year={2022},
  url={https://arxiv.org/abs/2211.09102}
}

@proceedings{wmt-2022-machine,
    title = "Proceedings of the Seventh Conference on Machine Translation (WMT)",
    editor = {Koehn, Philipp  and
      Barrault, Lo{\"\i}c  and
      Bojar, Ond{\v{r}}ej  and
      Bougares, Fethi  and
      Chatterjee, Rajen  and
      Costa-juss{\`a}, Marta R.  and
      Federmann, Christian  and
      Fishel, Mark  and
      Fraser, Alexander  and
      Freitag, Markus  and
      Graham, Yvette  and
      Grundkiewicz, Roman  and
      Guzman, Paco  and
      Haddow, Barry  and
      Huck, Matthias  and
      Jimeno Yepes, Antonio  and
      Kocmi, Tom  and
      Martins, Andr{\'e}  and
      Morishita, Makoto  and
      Monz, Christof  and
      Nagata, Masaaki  and
      Nakazawa, Toshiaki  and
      Negri, Matteo  and
      N{\'e}v{\'e}ol, Aur{\'e}lie  and
      Neves, Mariana  and
      Popel, Martin  and
      Turchi, Marco  and
      Zampieri, Marcos},
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates (Hybrid)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.wmt-1.0",
}

@misc{coca,
      title={CoCa: Contrastive Captioners are Image-Text Foundation Models}, 
      author={Jiahui Yu and Zirui Wang and Vijay Vasudevan and Legg Yeung and Mojtaba Seyedhosseini and Yonghui Wu},
      year={2022},
      eprint={2205.01917},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{sellam-etal-2020-bleurt,
    title = "{BLEURT}: Learning Robust Metrics for Text Generation",
    author = "Sellam, Thibault  and
      Das, Dipanjan  and
      Parikh, Ankur",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.704",
    doi = "10.18653/v1/2020.acl-main.704",
    pages = "7881--7892",
    abstract = "Text generation has made significant advances in the last few years. Yet, evaluation metrics have lagged behind, as the most popular choices (e.g., BLEU and ROUGE) may correlate poorly with human judgment. We propose BLEURT, a learned evaluation metric for English based on BERT. BLEURT can model human judgment with a few thousand possibly biased training examples. A key aspect of our approach is a novel pre-training scheme that uses millions of synthetic examples to help the model generalize. BLEURT provides state-of-the-art results on the last three years of the WMT Metrics shared task and the WebNLG data set. In contrast to a vanilla BERT-based approach, it yields superior results even when the training data is scarce and out-of-distribution.",
}

@inproceedings{freitag-etal-2022-results,
    title = "Results of {WMT}22 Metrics Shared Task: Stop Using {BLEU} {--} Neural Metrics Are Better and More Robust",
    author = "Freitag, Markus  and
      Rei, Ricardo  and
      Mathur, Nitika  and
      Lo, Chi-kiu  and
      Stewart, Craig  and
      Avramidis, Eleftherios  and
      Kocmi, Tom  and
      Foster, George  and
      Lavie, Alon  and
      Martins, Andr{\'e} F. T.",
    booktitle = "Proceedings of the Seventh Conference on Machine Translation (WMT)",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates (Hybrid)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.wmt-1.2",
    pages = "46--68",
}

@inproceedings{papineni-etal-2002-bleu,
    title = "{B}leu: a Method for Automatic Evaluation of Machine Translation",
    author = "Papineni, Kishore  and
      Roukos, Salim  and
      Ward, Todd  and
      Zhu, Wei-Jing",
    booktitle = "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2002",
    address = "Philadelphia, Pennsylvania, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P02-1040",
    doi = "10.3115/1073083.1073135",
    pages = "311--318",
}

@article{freitag-etal-2021-experts,
    title = "Experts, Errors, and Context: A Large-Scale Study of Human Evaluation for Machine Translation",
    author = "Freitag, Markus  and
      Foster, George  and
      Grangier, David  and
      Ratnakar, Viresh  and
      Tan, Qijun  and
      Macherey, Wolfgang",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "9",
    year = "2021",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2021.tacl-1.87",
    doi = "10.1162/tacl_a_00437",
    pages = "1460--1474",
    abstract = "Abstract Human evaluation of modern high-quality machine translation systems is a difficult problem, and there is increasing evidence that inadequate evaluation procedures can lead to erroneous conclusions. While there has been considerable research on human evaluation, the field still lacks a commonly accepted standard procedure. As a step toward this goal, we propose an evaluation methodology grounded in explicit error analysis, based on the Multidimensional Quality Metrics (MQM) framework. We carry out the largest MQM research study to date, scoring the outputs of top systems from the WMT 2020 shared task in two language pairs using annotations provided by professional translators with access to full document context. We analyze the resulting data extensively, finding among other results a substantially different ranking of evaluated systems from the one established by the WMT crowd workers, exhibiting a clear preference for human over machine output. Surprisingly, we also find that automatic metrics based on pre-trained embeddings can outperform human crowd workers. We make our corpus publicly available for further research.",
}

@inproceedings{hasan-etal-2021-xl,
    title = "{XL}-Sum: Large-Scale Multilingual Abstractive Summarization for 44 Languages",
    author = "Hasan, Tahmid  and
      Bhattacharjee, Abhik  and
      Islam, Md. Saiful  and
      Mubasshir, Kazi  and
      Li, Yuan-Fang  and
      Kang, Yong-Bin  and
      Rahman, M. Sohel  and
      Shahriyar, Rifat",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-acl.413",
    doi = "10.18653/v1/2021.findings-acl.413",
    pages = "4693--4703",
}

@inproceedings{ladhak-etal-2020-wikilingua,
    title = "{W}iki{L}ingua: A New Benchmark Dataset for Cross-Lingual Abstractive Summarization",
    author = "Ladhak, Faisal  and
      Durmus, Esin  and
      Cardie, Claire  and
      McKeown, Kathleen",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.360",
    doi = "10.18653/v1/2020.findings-emnlp.360",
    pages = "4034--4048",
    abstract = "We introduce WikiLingua, a large-scale, multilingual dataset for the evaluation of cross-lingual abstractive summarization systems. We extract article and summary pairs in 18 languages from WikiHow, a high quality, collaborative resource of how-to guides on a diverse set of topics written by human authors. We create gold-standard article-summary alignments across languages by aligning the images that are used to describe each how-to step in an article. As a set of baselines for further studies, we evaluate the performance of existing cross-lingual abstractive summarization methods on our dataset. We further propose a method for direct cross-lingual summarization (i.e., without requiring translation at inference time) by leveraging synthetic data and Neural Machine Translation as a pre-training step. Our method significantly outperforms the baseline approaches, while being more cost efficient during inference.",
}

@inproceedings{narayan-etal-2018-dont,
    title = "Don{'}t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization",
    author = "Narayan, Shashi  and
      Cohen, Shay B.  and
      Lapata, Mirella",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1206",
    doi = "10.18653/v1/D18-1206",
    pages = "1797--1807",
    abstract = "We introduce {``}extreme summarization{''}, a new single-document summarization task which does not favor extractive strategies and calls for an abstractive modeling approach. The idea is to create a short, one-sentence news summary answering the question {``}What is the article about?{''}. We collect a real-world, large-scale dataset for this task by harvesting online articles from the British Broadcasting Corporation (BBC). We propose a novel abstractive model which is conditioned on the article{'}s topics and based entirely on convolutional neural networks. We demonstrate experimentally that this architecture captures long-range dependencies in a document and recognizes pertinent content, outperforming an oracle extractive system and state-of-the-art abstractive approaches when evaluated automatically and by humans.",
}

@inproceedings{xue-etal-2021-mt5,
    title = "m{T}5: A Massively Multilingual Pre-trained Text-to-Text Transformer",
    author = "Xue, Linting  and
      Constant, Noah  and
      Roberts, Adam  and
      Kale, Mihir  and
      Al-Rfou, Rami  and
      Siddhant, Aditya  and
      Barua, Aditya  and
      Raffel, Colin",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.41",
    doi = "10.18653/v1/2021.naacl-main.41",
    pages = "483--498",
    abstract = "The recent {``}Text-to-Text Transfer Transformer{''} (T5) leveraged a unified text-to-text format and scale to attain state-of-the-art results on a wide variety of English-language NLP tasks. In this paper, we introduce mT5, a multilingual variant of T5 that was pre-trained on a new Common Crawl-based dataset covering 101 languages. We detail the design and modified training of mT5 and demonstrate its state-of-the-art performance on many multilingual benchmarks. We also describe a simple technique to prevent {``}accidental translation{''} in the zero-shot setting, where a generative model chooses to (partially) translate its prediction into the wrong language. All of the code and model checkpoints used in this work are publicly available.",
}

@inproceedings{athiwaratkun2023multi,
  title={Multi-lingual Evaluation of Code Generation Models},
  author={Athiwaratkun, Ben and Gouda, Sanjay Krishna and Wang, Zijian and Li, Xiaopeng and Tian, Yuchen and Tan, Ming and Ahmad, Wasi Uddin and Wang, Shiqi and Sun, Qing and Shang, Mingyue and others},
  booktitle = "Proceedings of ICLR 2023",
  year={2023}
}

@book{daniels1996world,
  title={The world's writing systems},
  author={Daniels, Peter T and Bright, William},
  year={1996},
  publisher={Oxford University Press on Demand}
}

@inproceedings{van-esch-etal-2022-writing,
    title = "Writing System and Speaker Metadata for 2,800+ Language Varieties",
    author = "van Esch, Daan  and
      Lucassen, Tamar  and
      Ruder, Sebastian  and
      Caswell, Isaac  and
      Rivera, Clara",
    booktitle = "Proceedings of the Thirteenth Language Resources and Evaluation Conference",
    month = jun,
    year = "2022",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2022.lrec-1.538",
    pages = "5035--5046",
    abstract = "We describe an open-source dataset providing metadata for about 2,800 language varieties used in the world today. Specifically, the dataset provides the attested writing system(s) for each of these 2,800+ varieties, as well as an estimated speaker count for each variety. This dataset was developed through internal research and has been used for analyses around language technologies. This is the largest publicly-available, machine-readable resource with writing system and speaker information for the world{'}s languages. We analyze the distribution of languages and writing systems in our data and compare it to their representation in current NLP. We hope the availability of this data will catalyze research in under-represented languages.",
}

@article{roziere2020unsupervised,
  title={Unsupervised translation of programming languages},
  author={Roziere, Baptiste and Lachaux, Marie-Anne and Chanussot, Lowik and Lample, Guillaume},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={20601--20611},
  year={2020}
}

@article{meurer2017sympy,
  title={SymPy: symbolic computing in Python},
  author={Meurer, Aaron and Smith, Christopher P and Paprocki, Mateusz and {\v{C}}ert{\'\i}k, Ond{\v{r}}ej and Kirpichev, Sergey B and Rocklin, Matthew and Kumar, AMiT and Ivanov, Sergiu and Moore, Jason K and Singh, Sartaj and others},
  journal={PeerJ Computer Science},
  volume={3},
  pages={e103},
  year={2017},
  publisher={PeerJ Inc.}
}

@inproceedings{popovic-2015-chrf,
    title = "chr{F}: character n-gram {F}-score for automatic {MT} evaluation",
    author = "Popovi{\'c}, Maja",
    editor = "Bojar, Ond{\v{r}}ej  and
      Chatterjee, Rajan  and
      Federmann, Christian  and
      Haddow, Barry  and
      Hokamp, Chris  and
      Huck, Matthias  and
      Logacheva, Varvara  and
      Pecina, Pavel",
    booktitle = "Proceedings of the Tenth Workshop on Statistical Machine Translation",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W15-3049",
    doi = "10.18653/v1/W15-3049",
    pages = "392--395",
}

@inproceedings{chen-etal-2020-question,
    title = "Question Directed Graph Attention Network for Numerical Reasoning over Text",
    author = "Chen, Kunlong  and
      Xu, Weidi  and
      Cheng, Xingyi  and
      Xiaochuan, Zou  and
      Zhang, Yuyu  and
      Song, Le  and
      Wang, Taifeng  and
      Qi, Yuan  and
      Chu, Wei",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.549",
    doi = "10.18653/v1/2020.emnlp-main.549",
    pages = "6759--6768",
    abstract = "Numerical reasoning over texts, such as addition, subtraction, sorting and counting, is a challenging machine reading comprehension task, since it requires both natural language understanding and arithmetic computation. To address this challenge, we propose a heterogeneous graph representation for the context of the passage and question needed for such reasoning, and design a question directed graph attention network to drive multi-step numerical reasoning over this context graph. Our model, which combines deep learning and graph reasoning, achieves remarkable results in benchmark datasets such as DROP.",
}

@article{chung2022scaling,
  title="Scaling instruction-finetuned language models",
  author="Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph,
                   Barret and Tay, Yi and Fedus, William and Li, Yunxuan and
                   Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha
                   and Webson, Albert and Gu, Shixiang Shane and Dai, Zhuyun
                   and Suzgun, Mirac and Chen, Xinyun and Chowdhery, Aakanksha
                   and Castro-Ros, Alex and Pellat, Marie and Robinson, Kevin
                   and Valter, Dasha and Narang, Sharan and Mishra, Gaurav and
                   Yu, Adams and Zhao, Vincent and Huang, Yanping and Dai,
                   Andrew and Yu, Hongkun and Petrov, Slav and Chi, Ed H and
                   Dean, Jeff and Devlin, Jacob and Roberts, Adam and Zhou,
                   Denny and Le, Quoc V and Wei, Jason",
  journal="arXiv preprint arXiv:2210.11416",
  year="2022",
  url="https://arxiv.org/abs/2210.11416"
}

@inproceedings{talmor-etal-2019-commonsenseqa,
    title = "{C}ommonsense{QA}: A Question Answering Challenge Targeting Commonsense Knowledge",
    author = "Talmor, Alon  and
      Herzig, Jonathan  and
      Lourie, Nicholas  and
      Berant, Jonathan",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1421",
    doi = "10.18653/v1/N19-1421",
    pages = "4149--4158",
    abstract = "When answering a question, people often draw upon their rich world knowledge in addition to the particular context. Recent work has focused primarily on answering questions given some relevant document or context, and required very little general background. To investigate question answering with prior knowledge, we present CommonsenseQA: a challenging new dataset for commonsense question answering. To capture common sense beyond associations, we extract from ConceptNet (Speer et al., 2017) multiple target concepts that have the same semantic relation to a single source concept. Crowd-workers are asked to author multiple-choice questions that mention the source concept and discriminate in turn between each of the target concepts. This encourages workers to create questions with complex semantics that often require prior knowledge. We create 12,247 questions through this procedure and demonstrate the difficulty of our task with a large number of strong baselines. Our best baseline is based on BERT-large (Devlin et al., 2018) and obtains 56{\%} accuracy, well below human performance, which is 89{\%}.",
}

@inproceedings{xu2022human,
  title={Human parity on {CommonsenseQA}: Augmenting self-attention with external attention},
  author={Xu, Yichong and Zhu, Chenguang and Wang, Shuohang and Sun, Siqi and Cheng, Hao and Liu, Xiaodong and Gao, Jianfeng and He, Pengcheng and Zeng, Michael and Huang, Xuedong},
  booktitle = "Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence (IJCAI-22)",
  year={2022}
}


@article{sdcs,
  title={Silent data corruptions at scale},
  author={Dixit, Harish Dattatraya and Pendharkar, Sneha and Beadon, Matt and Mason, Chris and Chakravarthy, Tejasvi and Muthiah, Bharath and Sankar, Sriram},
  journal={arXiv preprint arXiv:2102.11245},
  year={2021}
}

@article{flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Jean-Baptiste Alayrac and Jeff Donahue and Pauline Luc and Antoine Miech and Iain Barr and Yana Hasson and Karel Lenc and Arthur Mensch and Katie Millican and Malcolm Reynolds and Roman Ring and Eliza Rutherford and Serkan Cabi and Tengda Han and Zhitao Gong and Sina Samangooei and Marianne Monteiro and Jacob Menick and Sebastian Borgeaud and Andrew Brock and Aida Nematzadeh and Sahand Sharifzadeh and Mikolaj Binkowski and Ricardo Barreira and Oriol Vinyals and Andrew Zisserman and Karen Simonyan},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group UK London}
}

@article{mathvista,
  title={Mathvista: Evaluating mathematical reasoning of foundation models in visual contexts},
  author={Lu, Pan and Bansal, Hritik and Xia, Tony and Liu, Jiacheng and Li, Chunyuan and Hajishirzi, Hannaneh and Cheng, Hao and Chang, Kai-Wei and Galley, Michel and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2310.02255},
  year={2023}
}

@article{wortsman2023small,
  title={Small-scale proxies for large-scale Transformer training instabilities},
  author={Wortsman, Mitchell and Liu, Peter J and Xiao, Lechao and Everett, Katie and Alemi, Alex and Adlam, Ben and Co-Reyes, John D and Gur, Izzeddin and Kumar, Abhishek and Novak, Roman and others},
  journal={arXiv preprint arXiv:2309.14322},
  year={2023}
}

@article{alphacode,
  title={Competition-level code generation with alphacode},
  author={Li, Yujia and Choi, David and Chung, Junyoung and Kushman, Nate and Schrittwieser, Julian and Leblond, R{\'e}mi and Eccles, Tom and Keeling, James and Gimeno, Felix and Dal Lago, Agustin and others},
  journal={Science},
  volume={378},
  number={6624},
  pages={1092--1097},
  year={2022},
  publisher={American Association for the Advancement of Science}
}

@article{pali3,
  title={{PaLI-3 Vision Language Models: Smaller, Faster, Stronger}},
  author={Xi Chen and Xiao Wang and Lucas Beyer and Alexander Kolesnikov and Jialin Wu and Paul Voigtlaender and Basil Mustafa and Sebastian Goodman and Ibrahim Alabdulmohsin and Piotr Padlewski and Daniel Salz and Xi Xiong and Daniel Vlasic and Filip Pavetic and Keran Rong and Tianli Yu and Daniel Keysers and Xiaohua Zhai and Radu Soricut},
  journal={arXiv preprint arXiv:2310.09199},
  year={2023}
}

@article{gdm2023alphacode2,
      title={{AlphaCode 2 Technical Report}}, 
      author={{Leblond et al}},
      year={2023},
      url={https://storage.googleapis.com/deepmind-media/AlphaCode2/AlphaCode2_Tech_Report.pdf},
}


@article{jobs-white-paper,
      title={{Jobs of Tomorrow: Large Language Models and Jobs}}, 
      author={{World Economic Forum}},
      year={2023},
      url={https://www3.weforum.org/docs/WEF_Jobs_of_Tomorrow_Generative_AI_2023.pdf},
}

@article{palix,
  title={{PaLI-X: On Scaling up a Multilingual Vision and Language Model}},
  author={Xi Chen and Josip Djolonga and Piotr Padlewski and Basil Mustafa and Soravit Changpinyo and Jialin Wu and Carlos Riquelme Ruiz and Sebastian Goodman and Xiao Wang and Yi Tay and Siamak Shakeri and Mostafa Dehghani and Daniel Salz and Mario Lucic and Michael Tschannen and Arsha Nagrani and Hexiang Hu and Mandar Joshi and Bo Pang and Ceslee Montgomery and Paulina Pietrzyk and Marvin Ritter and AJ Piergiovanni and Matthias Minderer and Filip Pavetic and Austin Waters and Gang Li and Ibrahim Alabdulmohsin and Lucas Beyer and Julien Amelot and Kenton Lee and Andreas Peter Steiner and Yang Li and Daniel Keysers and Anurag Arnab and Yuanzhong Xu and Keran Rong and Alexander Kolesnikov and Mojtaba Seyedhosseini and Anelia Angelova and Xiaohua Zhai and Neil Houlsby and Radu Soricut},
  journal={arXiv preprint arXiv:2305.18565},
  year={2023}
}

@article{pali,
  title={{PaLI}: A jointly-scaled multilingual language-image model},
  author={Chen, Xi and Wang, Xiao and Changpinyo, Soravit and
                   Piergiovanni, A J and Padlewski, Piotr and Salz, Daniel and
                   Goodman, Sebastian and Grycner, Adam and Mustafa, Basil and
                   Beyer, Lucas and Kolesnikov, Alexander and Puigcerver, Joan
                   and Ding, Nan and Rong, Keran and Akbari, Hassan and Mishra,
                   Gaurav and Xue, Linting and Thapliyal, Ashish and Bradbury,
                   James and Kuo, Weicheng and Seyedhosseini, Mojtaba and Jia,
                   Chao and Ayan, Burcu Karagol and Riquelme, Carlos and
                   Steiner, Andreas and Angelova, Anelia and Zhai, Xiaohua and
                   Houlsby, Neil and Soricut, Radu},
  journal={arXiv preprint arXiv:2209.06794},
  year={2022},
  url={https://arxiv.org/abs/2209.06794}
}

@article{yu2022coca,
  title={{CoCa}: Contrastive captioners are image-text foundation models},
  author={Yu, Jiahui and Wang, Zirui and Vasudevan, Vijay and Yeung, Legg and Seyedhosseini, Mojtaba and Wu, Yonghui},
  journal={arXiv preprint arXiv:2205.01917},
  year={2022},
  url={https://arxiv.org/abs/2205.01917}
}

@inproceedings{goyal2017making,
  title={Making the {V} in {VQA} matter: Elevating the role of image understanding in visual question answering},
  author={Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6904--6913},
  year={2017}
}

@article{chen2015microsoft,
  title={Microsoft {COCO} captions: Data collection and evaluation server},
  author={Chen, Xinlei and Fang, Hao and Lin, Tsung-Yi and Vedantam, Ramakrishna and Gupta, Saurabh and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  journal={arXiv preprint arXiv:1504.00325},
  year={2015},
  url={https://arxiv.org/abs/1504.00325}
}

@inproceedings{singh2019towards,
  title={Towards vqa models that can read},
  author={Singh, Amanpreet and Natarajan, Vivek and Shah, Meet and Jiang, Yu and Chen, Xinlei and Batra, Dhruv and Parikh, Devi and Rohrbach, Marcus},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8317--8326},
  year={2019}
}

@inproceedings{marino2019ok,
  title={Ok-vqa: A visual question answering benchmark requiring external knowledge},
  author={Marino, Kenneth and Rastegari, Mohammad and Farhadi, Ali and Mottaghi, Roozbeh},
  booktitle={Proceedings of the IEEE/cvf conference on computer vision and pattern recognition},
  pages={3195--3204},
  year={2019}
}

@article{schick2021selfdebias,
  author    = {Timo Schick and
               Sahana Udupa and
               Hinrich Sch{\"{u}}tze},
  title     = {Self-Diagnosis and Self-Debiasing: A Proposal for Reducing Corpus-Based
               Bias in {NLP}},
  journal   = {CoRR},
  volume    = {abs/2103.00453},
  year      = {2021},
  url       = {https://arxiv.org/abs/2103.00453},
  eprinttype = {arXiv},
  eprint    = {2103.00453},
  timestamp = {Thu, 04 Mar 2021 17:00:40 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2103-00453.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{civilcomments,
  doi = {10.48550/ARXIV.1903.04561},
  url = {https://arxiv.org/abs/1903.04561},
  author = {Borkan, Daniel and Dixon, Lucas and Sorensen, Jeffrey and Thain, Nithum and Vasserman, Lucy},
  keywords = {Machine Learning (cs.LG), Computation and Language (cs.CL), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Nuanced Metrics for Measuring Unintended Bias with Real Data for Text Classification},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{jigsawmultilingual,
  url = {https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification},
  author = {Jigsaw},
  title = {Jigsaw Multilingual Toxic Comment Classification},
  year = {2019},
}

@misc{civil-comments-kaggle-competition,
  url = {https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge},
  author = {Jigsaw},
  title = {Toxic Comment Classification Challenge},
  year = {2018},
}

@inproceedings{tay2023ul,
    title={{UL}2: Unifying Language Learning Paradigms},
    author={Yi Tay and Mostafa Dehghani and Vinh Q. Tran and Xavier Garcia and Jason Wei and Xuezhi Wang and Hyung Won Chung and Dara Bahri and Tal Schuster and Steven Zheng and Denny Zhou and Neil Houlsby and Donald Metzler},
    booktitle={The Eleventh International Conference on Learning Representations },
    year={2023},
    url={https://openreview.net/forum?id=6ruVLB727MC}
}

@inproceedings{jacobs_wallach,
author = {Jacobs, Abigail Z. and Wallach, Hanna},
title = {Measurement and Fairness},
year = {2021},
isbn = {9781450383097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442188.3445901},
doi = {10.1145/3442188.3445901},
abstract = {We propose measurement modeling from the quantitative social sciences as a framework for understanding fairness in computational systems. Computational systems often involve unobservable theoretical constructs, such as socioeconomic status, teacher effectiveness, and risk of recidivism. Such constructs cannot be measured directly and must instead be inferred from measurements of observable properties (and other unobservable theoretical constructs) thought to be related to them---i.e., operationalized via a measurement model. This process, which necessarily involves making assumptions, introduces the potential for mismatches between the theoretical understanding of the construct purported to be measured and its operationalization. We argue that many of the harms discussed in the literature on fairness in computational systems are direct results of such mismatches. We show how some of these harms could have been anticipated and, in some cases, mitigated if viewed through the lens of measurement modeling. To do this, we contribute fairness-oriented conceptualizations of construct reliability and construct validity that unite traditions from political science, education, and psychology and provide a set of tools for making explicit and testing assumptions about constructs and their operationalizations. We then turn to fairness itself, an essentially contested construct that has different theoretical understandings in different contexts. We argue that this contestedness underlies recent debates about fairness definitions: although these debates appear to be about different operationalizations, they are, in fact, debates about different theoretical understandings of fairness. We show how measurement modeling can provide a framework for getting to the core of these debates.},
booktitle = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
pages = {375–385},
numpages = {11},
keywords = {construct validity, measurement, construct reliability, fairness},
location = {Virtual Event, Canada},
series = {FAccT '21}
}

@misc{shelby2023identifying,
      title={Identifying Sociotechnical Harms of Algorithmic Systems: Scoping a Taxonomy for Harm Reduction}, 
      author={Renee Shelby and Shalaleh Rismani and Kathryn Henne and AJung Moon and Negar Rostamzadeh and Paul Nicholas and N'Mah Yilla and Jess Gallegos and Andrew Smart and Emilio Garcia and Gurleen Virk},
      year={2023},
      eprint={2210.05791},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2210.05791},
}

@article{Shelby2022-sk,
  title         = "Identifying sociotechnical harms of algorithmic systems:
                   Scoping a taxonomy for harm reduction",
  author        = "Shelby, Renee and Rismani, Shalaleh and Henne, Kathryn and
                   Moon, Ajung and Rostamzadeh, Negar and Nicholas, Paul and
                   Yilla, N'mah and Gallegos, Jess and Smart, Andrew and
                   Garcia, Emilio and Virk, Gurleen",
  abstract      = "Understanding the landscape of potential harms from
                   algorithmic systems enables practitioners to better
                   anticipate consequences of the systems they build. It also
                   supports the prospect of incorporating controls to help
                   minimize harms that emerge from the interplay of
                   technologies and social and cultural dynamics. A growing
                   body of scholarship has identified a wide range of harms
                   across different algorithmic technologies. However,
                   computing research and practitioners lack a high level and
                   synthesized overview of harms from algorithmic systems
                   arising at the micro, meso-, and macro-levels of society. We
                   present an applied taxonomy of sociotechnical harms to
                   support more systematic surfacing of potential harms in
                   algorithmic systems. Based on a scoping review of computing
                   research $(n=172)$, we identified five major themes related
                   to sociotechnical harms - representational, allocative,
                   quality-of-service, interpersonal harms, and social
                   system/societal harms - and sub-themes. We describe these
                   categories and conclude with a discussion of challenges and
                   opportunities for future research.",
  month         =  oct,
  year          =  2022,
  copyright     = "http://creativecommons.org/licenses/by/4.0/",
  archivePrefix = "arXiv",
  primaryClass  = "cs.HC",
  eprint        = "2210.05791",
  url           = "https://arxiv.org/abs/2210.05791",
}

@inproceedings{ruder-etal-2022-square,
    title = "Square One Bias in {NLP}: Towards a Multi-Dimensional Exploration of the Research Manifold",
    author = "Ruder, Sebastian  and
      Vuli{\'c}, Ivan  and
      S{\o}gaard, Anders",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2022",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-acl.184",
    doi = "10.18653/v1/2022.findings-acl.184",
    pages = "2340--2354",
    abstract = "The prototypical NLP experiment trains a standard architecture on labeled English data and optimizes for accuracy, without accounting for other dimensions such as fairness, interpretability, or computational efficiency. We show through a manual classification of recent NLP research papers that this is indeed the case and refer to it as the square one experimental setup. We observe that NLP research often goes beyond the square one setup, e.g, focusing not only on accuracy, but also on fairness or interpretability, but typically only along a single dimension. Most work targeting multilinguality, for example, considers only accuracy; most work on fairness or interpretability considers only English; and so on. Such one-dimensionality of most research means we are only exploring a fraction of the NLP research search space. We provide historical and recent examples of how the square one bias has led researchers to draw false conclusions or make unwise choices, point to promising yet unexplored directions on the research manifold, and make practical recommendations to enable more multi-dimensional research. We open-source the results of our annotations to enable further analysis.",
}

@inproceedings{gpt3,
	author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
	pages = {1877--1901},
	publisher = {Curran Associates, Inc.},
	title = {Language Models are Few-Shot Learners},
	url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
	volume = {33},
	year = {2020},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf}
}

@article{rae2021scaling,
  title={Scaling Language Models: Methods, Analysis \& Insights from Training {G}opher},
  author={Rae, Jack W and Borgeaud, Sebastian and Cai, Trevor and
                   Millican, Katie and Hoffmann, Jordan and Song, Francis and
                   Aslanides, John and Henderson, Sarah and Ring, Roman and
                   Young, Susannah and Rutherford, Eliza and Hennigan, Tom and
                   Menick, Jacob and Cassirer, Albin and Powell, Richard and
                   van den Driessche, George and Hendricks, Lisa Anne and Rauh,
                   Maribeth and Huang, Po-Sen and Glaese, Amelia and Welbl,
                   Johannes and Dathathri, Sumanth and Huang, Saffron and
                   Uesato, Jonathan and Mellor, John and Higgins, Irina and
                   Creswell, Antonia and McAleese, Nat and Wu, Amy and Elsen,
                   Erich and Jayakumar, Siddhant and Buchatskaya, Elena and
                   Budden, David and Sutherland, Esme and Simonyan, Karen and
                   Paganini, Michela and Sifre, Laurent and Martens, Lena and
                   Li, Xiang Lorraine and Kuncoro, Adhiguna and Nematzadeh,
                   Aida and Gribovskaya, Elena and Donato, Domenic and
                   Lazaridou, Angeliki and Mensch, Arthur and Lespiau,
                   Jean-Baptiste and Tsimpoukelli, Maria and Grigorev, Nikolai
                   and Fritz, Doug and Sottiaux, Thibault and Pajarskas, Mantas
                   and Pohlen, Toby and Gong, Zhitao and Toyama, Daniel and
                   d'Autume, Cyprien de Masson and Li, Yujia and Terzi, Tayfun
                   and Mikulik, Vladimir and Babuschkin, Igor and Clark, Aidan
                   and Casas, Diego de Las and Guy, Aurelia and Jones, Chris
                   and Bradbury, James and Johnson, Matthew and Hechtman, Blake
                   and Weidinger, Laura and Gabriel, Iason and Isaac, William
                   and Lockhart, Ed and Osindero, Simon and Rimell, Laura and
                   Dyer, Chris and Vinyals, Oriol and Ayoub, Kareem and
                   Stanway, Jeff and Bennett, Lorrayne and Hassabis, Demis and
                   Kavukcuoglu, Koray and Irving, Geoffrey},
  journal={arXiv preprint arXiv:2112.11446},
  year={2021},
  url={https://arxiv.org/abs/2112.11446},
}

@article{shannon_lm,
	abstract = {A new method of estimating the entropy and redundancy of a language is described. This method exploits the knowledge of the language statistics possessed by those who speak the language, and depends on experimental results in prediction of the next letter when the preceding text is known. Results of experiments in prediction are given, and some properties of an ideal predictor are developed.},
	author = {Shannon, C. E.},
	doi = {https://doi.org/10.1002/j.1538-7305.1951.tb01366.x},
	eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/j.1538-7305.1951.tb01366.x},
	journal = {Bell System Technical Journal},
	number = {1},
	pages = {50-64},
	title = {Prediction and Entropy of Printed English},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/j.1538-7305.1951.tb01366.x},
	volume = {30},
	year = {1951},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/j.1538-7305.1951.tb01366.x},
	bdsk-url-2 = {https://doi.org/10.1002/j.1538-7305.1951.tb01366.x}
}

@misc{jozefowicz2016exploring,
      title={Exploring the Limits of Language Modeling}, 
      author={Rafal Jozefowicz and Oriol Vinyals and Mike Schuster and Noam Shazeer and Yonghui Wu},
      year={2016},
      eprint={1602.02410},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1602.02410}
}

@inproceedings{howard-ruder-2018-universal,
    title = "Universal Language Model Fine-tuning for Text Classification",
    author = "Howard, Jeremy  and
      Ruder, Sebastian",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1031",
    doi = "10.18653/v1/P18-1031",
    pages = "328--339",
    abstract = "Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24{\%} on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100 times more data. We open-source our pretrained models and code.",
}


@inproceedings{NIPS2015_dai_le,
	author = {Dai, Andrew M and Le, Quoc V},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {Semi-supervised Sequence Learning},
	url = {https://proceedings.neurips.cc/paper_files/paper/2015/file/7137debd45ae4d0ab9aa953017286b20-Paper.pdf},
	volume = {28},
	year = {2015},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2015/file/7137debd45ae4d0ab9aa953017286b20-Paper.pdf}}

@inproceedings{transformer_paper,
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {Attention is All you Need},
	url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
	volume = {30},
	year = {2017},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf}}

@inproceedings{akhbardeh-etal-2021-findings,
    title = "Findings of the 2021 Conference on Machine Translation ({WMT}21)",
    author = "Akhbardeh, Farhad  and
      Arkhangorodsky, Arkady  and
      Biesialska, Magdalena  and
      Bojar, Ond{\v{r}}ej  and
      Chatterjee, Rajen  and
      Chaudhary, Vishrav  and
      Costa-jussa, Marta R.  and
      Espa{\~n}a-Bonet, Cristina  and
      Fan, Angela  and
      Federmann, Christian  and
      Freitag, Markus  and
      Graham, Yvette  and
      Grundkiewicz, Roman  and
      Haddow, Barry  and
      Harter, Leonie  and
      Heafield, Kenneth  and
      Homan, Christopher  and
      Huck, Matthias  and
      Amponsah-Kaakyire, Kwabena  and
      Kasai, Jungo  and
      Khashabi, Daniel  and
      Knight, Kevin  and
      Kocmi, Tom  and
      Koehn, Philipp  and
      Lourie, Nicholas  and
      Monz, Christof  and
      Morishita, Makoto  and
      Nagata, Masaaki  and
      Nagesh, Ajay  and
      Nakazawa, Toshiaki  and
      Negri, Matteo  and
      Pal, Santanu  and
      Tapo, Allahsera Auguste  and
      Turchi, Marco  and
      Vydrin, Valentin  and
      Zampieri, Marcos",
    booktitle = "Proceedings of the Sixth Conference on Machine Translation",
    month = nov,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.wmt-1.1",
    pages = "1--88",
    abstract = "This paper presents the results of the newstranslation task, the multilingual low-resourcetranslation for Indo-European languages, thetriangular translation task, and the automaticpost-editing task organised as part of the Con-ference on Machine Translation (WMT) 2021.In the news task, participants were asked tobuild machine translation systems for any of10 language pairs, to be evaluated on test setsconsisting mainly of news stories. The taskwas also opened up to additional test suites toprobe specific aspects of translation.",
}

@article{riley2023frmt,
  title={FRMT: A Benchmark for Few-Shot Region-Aware Machine Translation},
  author={Riley, Parker and Dozat, Timothy and Botha, Jan A and Garcia, Xavier and Garrette, Dan and Riesa, Jason and Firat, Orhan and Constant, Noah},
  journal = "Transactions of the Association for Computational Linguistics",
  year={2023}
}

@inproceedings{gehman-etal-2020-realtoxicityprompts,
    title = "{R}eal{T}oxicity{P}rompts: Evaluating Neural Toxic Degeneration in Language Models",
    author = "Gehman, Samuel  and
      Gururangan, Suchin  and
      Sap, Maarten  and
      Choi, Yejin  and
      Smith, Noah A.",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.301",
    doi = "10.18653/v1/2020.findings-emnlp.301",
    pages = "3356--3369",
    abstract = "Pretrained neural language models (LMs) are prone to generating racist, sexist, or otherwise toxic language which hinders their safe deployment. We investigate the extent to which pretrained LMs can be prompted to generate toxic language, and the effectiveness of controllable text generation algorithms at preventing such toxic degeneration. We create and release RealToxicityPrompts, a dataset of 100K naturally occurring, sentence-level prompts derived from a large corpus of English web text, paired with toxicity scores from a widely-used toxicity classifier. Using RealToxicityPrompts, we find that pretrained LMs can degenerate into toxic text even from seemingly innocuous prompts. We empirically assess several controllable generation methods, and find that while data- or compute-intensive methods (e.g., adaptive pretraining on non-toxic data) are more effective at steering away from toxicity than simpler solutions (e.g., banning {``}bad{''} words), no current method is failsafe against neural toxic degeneration. To pinpoint the potential cause of such persistent toxic degeneration, we analyze two web text corpora used to pretrain several LMs (including GPT-2; Radford et. al, 2019), and find a significant amount of offensive, factually unreliable, and otherwise toxic content. Our work provides a test bed for evaluating toxic generations by LMs and stresses the need for better data selection processes for pretraining.",
}

@inproceedings{deplot,
    title = "{D}e{P}lot: One-shot visual language reasoning by plot-to-table translation",
    author = "Liu, Fangyu  and
      Eisenschlos, Julian  and
      Piccinno, Francesco  and
      Krichene, Syrine  and
      Pang, Chenxi  and
      Lee, Kenton  and
      Joshi, Mandar  and
      Chen, Wenhu  and
      Collier, Nigel  and
      Altun, Yasemin",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.660",
    doi = "10.18653/v1/2023.findings-acl.660",
    pages = "10381--10399",
}


@inproceedings{dinan-etal-2019-build,
    title = "Build it Break it Fix it for Dialogue Safety: Robustness from Adversarial Human Attack",
    author = "Dinan, Emily  and
      Humeau, Samuel  and
      Chintagunta, Bharath  and
      Weston, Jason",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1461",
    doi = "10.18653/v1/D19-1461",
    pages = "4537--4546",
    abstract = "The detection of offensive language in the context of a dialogue has become an increasingly important application of natural language processing. The detection of trolls in public forums (Gal{\'a}n-Garc{\'\i}a et al., 2016), and the deployment of chatbots in the public domain (Wolf et al., 2017) are two examples that show the necessity of guarding against adversarially offensive behavior on the part of humans. In this work, we develop a training scheme for a model to become robust to such human attacks by an iterative build it, break it, fix it scheme with humans and models in the loop. In detailed experiments we show this approach is considerably more robust than previous systems. Further, we show that offensive language used within a conversation critically depends on the dialogue context, and cannot be viewed as a single sentence offensive detection task as in most previous work. Our newly collected tasks and methods are all made open source and publicly available.",
}

@article{parrish-2021-bbq,
  author       = {Alicia Parrish and
                  Angelica Chen and
                  Nikita Nangia and
                  Vishakh Padmakumar and
                  Jason Phang and
                  Jana Thompson and
                  Phu Mon Htut and
                  Samuel R. Bowman},
  title        = {{BBQ:} {A} Hand-Built Bias Benchmark for Question Answering},
  journal      = {CoRR},
  volume       = {abs/2110.08193},
  year         = {2021},
  url          = {https://arxiv.org/abs/2110.08193},
  eprinttype    = {arXiv},
  eprint       = {2110.08193},
  timestamp    = {Fri, 22 Oct 2021 13:33:09 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2110-08193.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Blodgett2020-lt,
  title         = "Language (technology) is power: A critical survey of
                   ``bias'' in {NLP}",
  author        = "Blodgett, Su Lin and Barocas, Solon and Daum{\'e}, III, Hal
                   and Wallach, Hanna",
  abstract      = "We survey 146 papers analyzing ``bias'' in NLP systems,
                   finding that their motivations are often vague,
                   inconsistent, and lacking in normative reasoning, despite
                   the fact that analyzing ``bias'' is an inherently normative
                   process. We further find that these papers' proposed
                   quantitative techniques for measuring or mitigating ``bias''
                   are poorly matched to their motivations and do not engage
                   with the relevant literature outside of NLP. Based on these
                   findings, we describe the beginnings of a path forward by
                   proposing three recommendations that should guide work
                   analyzing ``bias'' in NLP systems. These recommendations
                   rest on a greater recognition of the relationships between
                   language and social hierarchies, encouraging researchers and
                   practitioners to articulate their conceptualizations of
                   ``bias''---i.e., what kinds of system behaviors are harmful,
                   in what ways, to whom, and why, as well as the normative
                   reasoning underlying these statements---and to center work
                   around the lived experiences of members of communities
                   affected by NLP systems, while interrogating and reimagining
                   the power relations between technologists and such
                   communities.",
  month         =  may,
  year          =  2020,
  copyright     = "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2005.14050",
  url           = "https://arxiv.org/abs/2005.14050",
}

% dev2022measures
@ARTICLE{Dev2021-pm,
  title         = "On measures of biases and harms in {NLP}",
  author        = "Dev, Sunipa and Sheng, Emily and Zhao, Jieyu and Amstutz,
                   Aubrie and Sun, Jiao and Hou, Yu and Sanseverino, Mattie and
                   Kim, Jiin and Nishi, Akihiro and Peng, Nanyun and Chang,
                   Kai-Wei",
  abstract      = "Recent studies show that Natural Language Processing (NLP)
                   technologies propagate societal biases about demographic
                   groups associated with attributes such as gender, race, and
                   nationality. To create interventions and mitigate these
                   biases and associated harms, it is vital to be able to
                   detect and measure such biases. While existing works propose
                   bias evaluation and mitigation methods for various tasks,
                   there remains a need to cohesively understand the biases and
                   the specific harms they measure, and how different measures
                   compare with each other. To address this gap, this work
                   presents a practical framework of harms and a series of
                   questions that practitioners can answer to guide the
                   development of bias measures. As a validation of our
                   framework and documentation questions, we also present
                   several case studies of how existing bias measures in NLP --
                   both intrinsic measures of bias in representations and
                   extrinsic measures of bias of downstream applications -- can
                   be aligned with different harms and how our proposed
                   documentation questions facilitates more holistic
                   understanding of what bias measures are measuring.",
  month         =  aug,
  year          =  2021,
  copyright     = "http://creativecommons.org/licenses/by/4.0/",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2108.03362",
  url           = "https://arxiv.org/abs/2108.03362",
}

@article{Weidinger2021-bk,
  title         = "Ethical and social risks of harm from Language Models",
  author        = "Weidinger, Laura and Mellor, John and Rauh, Maribeth and
                   Griffin, Conor and Uesato, Jonathan and Huang, Po-Sen and
                   Cheng, Myra and Glaese, Mia and Balle, Borja and Kasirzadeh,
                   Atoosa and Kenton, Zac and Brown, Sasha and Hawkins, Will
                   and Stepleton, Tom and Biles, Courtney and Birhane, Abeba
                   and Haas, Julia and Rimell, Laura and Hendricks, Lisa Anne
                   and Isaac, William and Legassick, Sean and Irving, Geoffrey
                   and Gabriel, Iason",
  abstract      = "This paper aims to help structure the risk landscape
                   associated with large-scale Language Models (LMs). In order
                   to foster advances in responsible innovation, an in-depth
                   understanding of the potential risks posed by these models
                   is needed. A wide range of established and anticipated risks
                   are analysed in detail, drawing on multidisciplinary
                   expertise and literature from computer science, linguistics,
                   and social sciences. We outline six specific risk areas: I.
                   Discrimination, Exclusion and Toxicity, II. Information
                   Hazards, III. Misinformation Harms, V. Malicious Uses, V.
                   Human-Computer Interaction Harms, VI. Automation, Access,
                   and Environmental Harms. The first area concerns the
                   perpetuation of stereotypes, unfair discrimination,
                   exclusionary norms, toxic language, and lower performance by
                   social group for LMs. The second focuses on risks from
                   private data leaks or LMs correctly inferring sensitive
                   information. The third addresses risks arising from poor,
                   false or misleading information including in sensitive
                   domains, and knock-on risks such as the erosion of trust in
                   shared information. The fourth considers risks from actors
                   who try to use LMs to cause harm. The fifth focuses on risks
                   specific to LLMs used to underpin conversational agents that
                   interact with human users, including unsafe use,
                   manipulation or deception. The sixth discusses the risk of
                   environmental harm, job automation, and other challenges
                   that may have a disparate effect on different social groups
                   or communities. In total, we review 21 risks in-depth. We
                   discuss the points of origin of different risks and point to
                   potential mitigation approaches. Lastly, we discuss
                   organisational responsibilities in implementing mitigations,
                   and the role of collaboration and participation. We
                   highlight directions for further research, particularly on
                   expanding the toolkit for assessing and evaluating the
                   outlined risks in LMs.",
  month         =  dec,
  year          =  2021,
  copyright     = "http://creativecommons.org/licenses/by/4.0/",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2112.04359",
  url           = "https://arxiv.org/abs/2112.04359",
}

@inproceedings{Sambasivan2021,
  title={Re-imagining Algorithmic Fairness in India and Beyond},
  author={Sambasivan, Nithya and Arnesen, Erin and Hutchinson, Ben and Doshi, Tulsee and Prabhakaran, Vinodkumar},
  booktitle={FAccT '21: Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
  month={March},
  year={2021},
  pages={315-328}
}

@inproceedings{Ramesh2022,
  title={How Platform-User Power Relations Shape Algorithmic Accountability: A Case Study of Instant Loan Platforms and Financially Stressed Users in India},
  author={Ramesh, Divya and Kameswaran, Vaishnav and Wang Ding and Sambasivan, Nithya},
  booktitle={FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency},
  month={June},
  year={2022},
  pages={1917-1928}
}

@article{ji-2023-survey-of-hallucination,
	doi = {10.1145/3571730},
	url = {https://doi.org/10.1145%2F3571730},
	year = 2023,
	month = {mar},
	publisher = {Association for Computing Machinery ({ACM})},
	volume = {55},
	number = {12},
	pages = {1--38},
	author = {Ziwei Ji and Nayeon Lee and Rita Frieske and Tiezheng Yu and Dan Su and Yan Xu and Etsuko Ishii and Ye Jin Bang and Andrea Madotto and Pascale Fung},
	title = {Survey of Hallucination in Natural Language Generation},
	journal = {{ACM} Computing Surveys}
}

@misc{glaese2022improving,
      title={Improving alignment of dialogue agents via targeted human judgements}, 
      author={Amelia Glaese and Nat McAleese and Maja Trębacz and John Aslanides and Vlad Firoiu and Timo Ewalds and Maribeth Rauh and Laura Weidinger and Martin Chadwick and Phoebe Thacker and Lucy Campbell-Gillingham and Jonathan Uesato and Po-Sen Huang and Ramona Comanescu and Fan Yang and Abigail See and Sumanth Dathathri and Rory Greig and Charlie Chen and Doug Fritz and Jaume Sanchez Elias and Richard Green and Soňa Mokrá and Nicholas Fernando and Boxi Wu and Rachel Foley and Susannah Young and Iason Gabriel and William Isaac and John Mellor and Demis Hassabis and Koray Kavukcuoglu and Lisa Anne Hendricks and Geoffrey Irving},
      year={2022},
      eprint={2209.14375},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2209.14375}
}

@ARTICLE{Raji2021-rr,
  title         = "{AI} and the everything in the whole wide world benchmark",
  author        = "Raji, Inioluwa Deborah and Bender, Emily M and Paullada,
                   Amandalynne and Denton, Emily and Hanna, Alex",
  abstract      = "There is a tendency across different subfields in AI to
                   valorize a small collection of influential benchmarks. These
                   benchmarks operate as stand-ins for a range of anointed
                   common problems that are frequently framed as foundational
                   milestones on the path towards flexible and generalizable AI
                   systems. State-of-the-art performance on these benchmarks is
                   widely understood as indicative of progress towards these
                   long-term goals. In this position paper, we explore the
                   limits of such benchmarks in order to reveal the construct
                   validity issues in their framing as the functionally
                   ``general'' broad measures of progress they are set up to
                   be.",
  month         =  nov,
  year          =  2021,
  copyright     = "http://creativecommons.org/licenses/by/4.0/",
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG",
  eprint        = "2111.15366",
  url           = "https://arxiv.org/abs/2111.15366",
}

@inproceedings{Selbst2019,
  title={Fairness and Abstraction in Sociotechnical Systems},
  author={Selbst, Andrew D. and Boyd, Danah and Friedler, Sorelle A.},
  booktitle={FFAT* '19: Proceedings of the Conference on Fairness, Accountability, and Transparency},
  month={January},
  year={2019},
  pages={59-68}
}

@ARTICLE{Bai2022-us,
  title         = "Training a helpful and harmless assistant with reinforcement
                   learning from human feedback",
  author        = "Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell,
                   Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and
                   Fort, Stanislav and Ganguli, Deep and Henighan, Tom and
                   Joseph, Nicholas and Kadavath, Saurav and Kernion, Jackson
                   and Conerly, Tom and El-Showk, Sheer and Elhage, Nelson and
                   Hatfield-Dodds, Zac and Hernandez, Danny and Hume, Tristan
                   and Johnston, Scott and Kravec, Shauna and Lovitt, Liane and
                   Nanda, Neel and Olsson, Catherine and Amodei, Dario and
                   Brown, Tom and Clark, Jack and McCandlish, Sam and Olah,
                   Chris and Mann, Ben and Kaplan, Jared",
  month         =  apr,
  year          =  2022,
  copyright     = "http://creativecommons.org/licenses/by/4.0/",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2204.05862",
  url           = "https://arxiv.org/abs/2204.05862",
}

@inproceedings{lester-etal-2021-power,
    title = "The Power of Scale for Parameter-Efficient Prompt Tuning",
    author = "Lester, Brian  and
      Al-Rfou, Rami  and
      Constant, Noah",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.243",
    doi = "10.18653/v1/2021.emnlp-main.243",
    pages = "3045--3059",
    abstract = "In this work, we explore {``}prompt tuning,{''} a simple yet effective mechanism for learning {``}soft prompts{''} to condition frozen language models to perform specific downstream tasks. Unlike the discrete text prompts used by GPT-3, soft prompts are learned through backpropagation and can be tuned to incorporate signals from any number of labeled examples. Our end-to-end learned approach outperforms GPT-3{'}s few-shot learning by a large margin. More remarkably, through ablations on model size using T5, we show that prompt tuning becomes more competitive with scale: as models exceed billions of parameters, our method {``}closes the gap{''} and matches the strong performance of model tuning (where all model weights are tuned). This finding is especially relevant because large models are costly to share and serve and the ability to reuse one frozen model for multiple downstream tasks can ease this burden. Our method can be seen as a simplification of the recently proposed {``}prefix tuning{''} of Li and Liang (2021) and we provide a comparison to this and other similar approaches. Finally, we show that conditioning a frozen model with soft prompts confers benefits in robustness to domain transfer and enables efficient {``}prompt ensembling.{''} We release code and model checkpoints to reproduce our experiments.",
}

@misc{Casad2017,
      title={Stereotype Threat Among Girls: Differences by Gender Identity and Math Education Context},
      author={Casad, Bettina J. and Hale, Patricia and Wachs, Faye L.},
      journal={Psychology of Women Quarterly},
      volume={41},
      number={4},
      year={2017}
}

@misc{Crenshaw1989,
      title={Demarginalizing the Intersection of Race and Sex: A Black Feminist Critique of Antidiscrimination Doctrine, Feminist Theory and Antiracist Politics},
      author={Kimberle Crenshaw},
      journal={University of Chicago Legal Forum},
      volume={1989},
      number={1},
      year={1989}
}



@ARTICLE{Garg2022-zi,
  title         = "Handling bias in toxic speech detection: A survey",
  author        = "Garg, Tanmay and Masud, Sarah and Suresh, Tharun and
                   Chakraborty, Tanmoy",
  abstract      = "Detecting online toxicity has always been a challenge due to
                   its inherent subjectivity. Factors such as the context,
                   geography, socio-political climate, and background of the
                   producers and consumers of the posts play a crucial role in
                   determining if the content can be flagged as toxic. Adoption
                   of automated toxicity detection models in production can
                   thus lead to a sidelining of the various groups they aim to
                   help in the first place. It has piqued researchers' interest
                   in examining unintended biases and their mitigation. Due to
                   the nascent and multi-faceted nature of the work, complete
                   literature is chaotic in its terminologies, techniques, and
                   findings. In this paper, we put together a systematic study
                   of the limitations and challenges of existing methods for
                   mitigating bias in toxicity detection. We look closely at
                   proposed methods for evaluating and mitigating bias in toxic
                   speech detection. To examine the limitations of existing
                   methods, we also conduct a case study to introduce the
                   concept of bias shift due to knowledge-based bias
                   mitigation. The survey concludes with an overview of the
                   critical challenges, research gaps, and future directions.
                   While reducing toxicity on online platforms continues to be
                   an active area of research, a systematic study of various
                   biases and their mitigation strategies will help the
                   research community produce robust and fair models.",
  month         =  jan,
  year          =  2022,
  copyright     = "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
  archivePrefix = "arXiv",
  primaryClass  = "cs.SI",
  eprint        = "2202.00126",
  url="https://arxiv.org/abs/2202.00126",
}

@ARTICLE{Goyal2022-wh,
  title         = "Is your toxicity my toxicity? {E}xploring the impact of rater
                   identity on toxicity annotation",
  author        = "Goyal, Nitesh and Kivlichan, Ian and Rosen, Rachel and
                   Vasserman, Lucy",
  abstract      = "Machine learning models are commonly used to detect toxicity
                   in online conversations. These models are trained on
                   datasets annotated by human raters. We explore how raters'
                   self-described identities impact how they annotate toxicity
                   in online comments. We first define the concept of
                   specialized rater pools: rater pools formed based on raters'
                   self-described identities, rather than at random. We formed
                   three such rater pools for this study--specialized rater
                   pools of raters from the U.S. who identify as African
                   American, LGBTQ, and those who identify as neither. Each of
                   these rater pools annotated the same set of comments, which
                   contains many references to these identity groups. We found
                   that rater identity is a statistically significant factor in
                   how raters will annotate toxicity for identity-related
                   annotations. Using preliminary content analysis, we examined
                   the comments with the most disagreement between rater pools
                   and found nuanced differences in the toxicity annotations.
                   Next, we trained models on the annotations from each of the
                   different rater pools, and compared the scores of these
                   models on comments from several test sets. Finally, we
                   discuss how using raters that self-identify with the
                   subjects of comments can create more inclusive machine
                   learning models, and provide more nuanced ratings than those
                   by random raters.",
  month         =  may,
  year          =  2022,
  copyright     = "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
  archivePrefix = "arXiv",
  primaryClass  = "cs.HC",
  eprint        = "2205.00501",
  url="https://arxiv.org/abs/2205.00501",
}

@ARTICLE{Sap2021-zg,
  title         = "Annotators with attitudes: How annotator beliefs and
                   identities bias toxic language detection",
  author        = "Sap, Maarten and Swayamdipta, Swabha and Vianna, Laura and
                   Zhou, Xuhui and Choi, Yejin and Smith, Noah A",
  abstract      = "The perceived toxicity of language can vary based on
                   someone's identity and beliefs, but this variation is often
                   ignored when collecting toxic language datasets, resulting
                   in dataset and model biases. We seek to understand the who,
                   why, and what behind biases in toxicity annotations. In two
                   online studies with demographically and politically diverse
                   participants, we investigate the effect of annotator
                   identities (who) and beliefs (why), drawing from social
                   psychology research about hate speech, free speech, racist
                   beliefs, political leaning, and more. We disentangle what is
                   annotated as toxic by considering posts with three
                   characteristics: anti-Black language, African American
                   English (AAE) dialect, and vulgarity. Our results show
                   strong associations between annotator identity and beliefs
                   and their ratings of toxicity. Notably, more conservative
                   annotators and those who scored highly on our scale for
                   racist beliefs were less likely to rate anti-Black language
                   as toxic, but more likely to rate AAE as toxic. We
                   additionally present a case study illustrating how a popular
                   toxicity detection system's ratings inherently reflect only
                   specific beliefs and perspectives. Our findings call for
                   contextualizing toxicity labels in social variables, which
                   raises immense implications for toxic language annotation
                   and detection.",
  month         =  nov,
  year          =  2021,
  copyright     = "http://creativecommons.org/licenses/by/4.0/",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2111.07997",
  url="https://arxiv.org/abs/2111.07997",
}

% prabhakaran2022cultural
@ARTICLE{Prabhakaran2022-bc,
  title         = "Cultural Incongruencies in Artificial Intelligence",
  author        = "Prabhakaran, Vinodkumar and Qadri, Rida and Hutchinson, Ben",
  abstract      = "Artificial intelligence (AI) systems attempt to imitate
                   human behavior. How well they do this imitation is often
                   used to assess their utility and to attribute human-like (or
                   artificial) intelligence to them. However, most work on AI
                   refers to and relies on human intelligence without
                   accounting for the fact that human behavior is inherently
                   shaped by the cultural contexts they are embedded in, the
                   values and beliefs they hold, and the social practices they
                   follow. Additionally, since AI technologies are mostly
                   conceived and developed in just a handful of countries, they
                   embed the cultural values and practices of these countries.
                   Similarly, the data that is used to train the models also
                   fails to equitably represent global cultural diversity.
                   Problems therefore arise when these technologies interact
                   with globally diverse societies and cultures, with different
                   values and interpretive practices. In this position paper,
                   we describe a set of cultural dependencies and
                   incongruencies in the context of AI-based language and
                   vision technologies, and reflect on the possibilities of and
                   potential strategies towards addressing these
                   incongruencies.",
  month         =  nov,
  year          =  2022,
  copyright     = "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CY",
  eprint        = "2211.13069",
  url="https://arxiv.org/abs/2211.13069",
}

@ARTICLE{Diaz2022-mz,
  title         = "{CrowdWorkSheets}: Accounting for individual and collective
                   identities underlying crowdsourced dataset annotation",
  author        = "Diaz, Mark and Kivlichan, Ian D and Rosen, Rachel and Baker,
                   Dylan K and Amironesei, Razvan and Prabhakaran, Vinodkumar
                   and Denton, Emily",
  abstract      = "Human annotated data plays a crucial role in machine
                   learning (ML) research and development. However, the ethical
                   considerations around the processes and decisions that go
                   into dataset annotation have not received nearly enough
                   attention. In this paper, we survey an array of literature
                   that provides insights into ethical considerations around
                   crowdsourced dataset annotation. We synthesize these
                   insights, and lay out the challenges in this space along two
                   layers: (1) who the annotator is, and how the annotators'
                   lived experiences can impact their annotations, and (2) the
                   relationship between the annotators and the crowdsourcing
                   platforms, and what that relationship affords them. Finally,
                   we introduce a novel framework, CrowdWorkSheets, for dataset
                   developers to facilitate transparent documentation of key
                   decisions points at various stages of the data annotation
                   pipeline: task formulation, selection of annotators,
                   platform and infrastructure choices, dataset analysis and
                   evaluation, and dataset release and maintenance.",
  month         =  jun,
  year          =  2022,
  copyright     = "http://creativecommons.org/licenses/by/4.0/",
  archivePrefix = "arXiv",
  primaryClass  = "cs.HC",
  eprint        = "2206.08931",
  url           = "https://arxiv.org/abs/2206.08931",
}

@ARTICLE{Xu2021-xw,
  title         = "Detoxifying language models risks marginalizing minority
                   voices",
  author        = "Xu, Albert and Pathak, Eshaan and Wallace, Eric and
                   Gururangan, Suchin and Sap, Maarten and Klein, Dan",
  abstract      = "Language models (LMs) must be both safe and equitable to be
                   responsibly deployed in practice. With safety in mind,
                   numerous detoxification techniques (e.g., Dathathri et al.
                   2020; Krause et al. 2020) have been proposed to mitigate
                   toxic LM generations. In this work, we show that current
                   detoxification techniques hurt equity: they decrease the
                   utility of LMs on language used by marginalized groups
                   (e.g., African-American English and minority identity
                   mentions). In particular, we perform automatic and human
                   evaluations of text generation quality when LMs are
                   conditioned on inputs with different dialects and group
                   identifiers. We find that detoxification makes LMs more
                   brittle to distribution shift, especially on language used
                   by marginalized groups. We identify that these failures stem
                   from detoxification methods exploiting spurious correlations
                   in toxicity datasets. Overall, our results highlight the
                   tension between the controllability and distributional
                   robustness of LMs.",
  month         =  apr,
  year          =  2021,
  copyright     = "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2104.06390",
  url="https://arxiv.org/abs/2104.06390",
}

@ARTICLE{Smith2022-du,
  title         = "``I'm sorry to hear that'': {F}inding New Biases in Language
                   Models with a Holistic Descriptor Dataset",
  author        = "Smith, Eric Michael and Hall, Melissa and Kambadur, Melanie
                   and Presani, Eleonora and Williams, Adina",
  abstract      = "As language models grow in popularity, it becomes
                   increasingly important to clearly measure all possible
                   markers of demographic identity in order to avoid
                   perpetuating existing societal harms. Many datasets for
                   measuring bias currently exist, but they are restricted in
                   their coverage of demographic axes and are commonly used
                   with preset bias tests that presuppose which types of biases
                   models can exhibit. In this work, we present a new, more
                   inclusive bias measurement dataset, HolisticBias, which
                   includes nearly 600 descriptor terms across 13 different
                   demographic axes. HolisticBias was assembled in a
                   participatory process including experts and community
                   members with lived experience of these terms. These
                   descriptors combine with a set of bias measurement templates
                   to produce over 450,000 unique sentence prompts, which we
                   use to explore, identify, and reduce novel forms of bias in
                   several generative models. We demonstrate that HolisticBias
                   is effective at measuring previously undetectable biases in
                   token likelihoods from language models, as well as in an
                   offensiveness classifier. We will invite additions and
                   amendments to the dataset, which we hope will serve as a
                   basis for more easy-to-use and standardized methods for
                   evaluating bias in NLP models.",
  month         =  may,
  year          =  2022,
  copyright     = "http://creativecommons.org/licenses/by-sa/4.0/",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2205.09209",
  url           = "https://arxiv.org/abs/2205.09209",
}

@ARTICLE{Bhatt2022-sp,
  title         = "Re-contextualizing fairness in {NLP}: The case of India",
  author        = "Bhatt, Shaily and Dev, Sunipa and Talukdar, Partha and Dave,
                   Shachi and Prabhakaran, Vinodkumar",
  abstract      = "Recent research has revealed undesirable biases in NLP data
                   and models. However, these efforts focus on social
                   disparities in West, and are not directly portable to other
                   geo-cultural contexts. In this paper, we focus on NLP
                   fair-ness in the context of India. We start with a brief
                   account of the prominent axes of social disparities in
                   India. We build resources for fairness evaluation in the
                   Indian context and use them to demonstrate prediction biases
                   along some of the axes. We then delve deeper into social
                   stereotypes for Region andReligion, demonstrating its
                   prevalence in corpora and models. Finally, we outline a
                   holistic research agenda to re-contextualize NLP fairness
                   research for the Indian context, ac-counting for Indian
                   societal context, bridging technological gaps in NLP
                   capabilities and re-sources, and adapting to Indian cultural
                   values. While we focus on India, this framework can be
                   generalized to other geo-cultural contexts.",
  month         =  sep,
  year          =  2022,
  copyright     = "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2209.12226",
  url           = "https://arxiv.org/abs/2209.12226",
}

@ARTICLE{Hu2021-qk,
  title         = "{LoRA}: {Low-Rank} Adaptation of large language models",
  author        = "Hu, Edward J and Shen, Yelong and Wallis, Phillip and
                   Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang,
                   Lu and Chen, Weizhu",
  abstract      = "An important paradigm of natural language processing
                   consists of large-scale pre-training on general domain data
                   and adaptation to particular tasks or domains. As we
                   pre-train larger models, full fine-tuning, which retrains
                   all model parameters, becomes less feasible. Using GPT-3
                   175B as an example -- deploying independent instances of
                   fine-tuned models, each with 175B parameters, is
                   prohibitively expensive. We propose Low-Rank Adaptation, or
                   LoRA, which freezes the pre-trained model weights and
                   injects trainable rank decomposition matrices into each
                   layer of the Transformer architecture, greatly reducing the
                   number of trainable parameters for downstream tasks.
                   Compared to GPT-3 175B fine-tuned with Adam, LoRA can reduce
                   the number of trainable parameters by 10,000 times and the
                   GPU memory requirement by 3 times. LoRA performs on-par or
                   better than fine-tuning in model quality on RoBERTa,
                   DeBERTa, GPT-2, and GPT-3, despite having fewer trainable
                   parameters, a higher training throughput, and, unlike
                   adapters, no additional inference latency. We also provide
                   an empirical investigation into rank-deficiency in language
                   model adaptation, which sheds light on the efficacy of LoRA.
                   We release a package that facilitates the integration of
                   LoRA with PyTorch models and provide our implementations and
                   model checkpoints for RoBERTa, DeBERTa, and GPT-2 at
                   https://github.com/microsoft/LoRA.",
  month         =  jun,
  year          =  2021,
  copyright     = "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2106.09685",
  url           = "https://arxiv.org/abs/2106.09685",
}

@ARTICLE{Bapna2022-mp,
  title         = "Building machine translation systems for the next thousand
                   languages",
  author        = "Bapna, Ankur and Caswell, Isaac and Kreutzer, Julia and
                   Firat, Orhan and van Esch, Daan and Siddhant, Aditya and
                   Niu, Mengmeng and Baljekar, Pallavi and Garcia, Xavier and
                   Macherey, Wolfgang and Breiner, Theresa and Axelrod, Vera
                   and Riesa, Jason and Cao, Yuan and Chen, Mia Xu and
                   Macherey, Klaus and Krikun, Maxim and Wang, Pidong and
                   Gutkin, Alexander and Shah, Apurva and Huang, Yanping and
                   Chen, Zhifeng and Wu, Yonghui and Hughes, Macduff",
  abstract      = "In this paper we share findings from our effort to build
                   practical machine translation (MT) systems capable of
                   translating across over one thousand languages. We describe
                   results in three research domains: (i) Building clean,
                   web-mined datasets for 1500+ languages by leveraging
                   semi-supervised pre-training for language identification and
                   developing data-driven filtering techniques; (ii) Developing
                   practical MT models for under-served languages by leveraging
                   massively multilingual models trained with supervised
                   parallel data for over 100 high-resource languages and
                   monolingual datasets for an additional 1000+ languages; and
                   (iii) Studying the limitations of evaluation metrics for
                   these languages and conducting qualitative analysis of the
                   outputs from our MT models, highlighting several frequent
                   error modes of these types of models. We hope that our work
                   provides useful insights to practitioners working towards
                   building MT systems for currently understudied languages,
                   and highlights research directions that can complement the
                   weaknesses of massively multilingual models in data-sparse
                   settings.",
  month         =  may,
  year          =  2022,
  copyright     = "http://creativecommons.org/licenses/by/4.0/",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2205.03983",
  url           = "https://arxiv.org/abs/2205.03983",
}

@ARTICLE{Liang2022-ls,
  title         = "Holistic Evaluation of Language Models",
  author        = "Liang, Percy and Bommasani, Rishi and Lee, Tony and Tsipras,
                   Dimitris and Soylu, Dilara and Yasunaga, Michihiro and
                   Zhang, Yian and Narayanan, Deepak and Wu, Yuhuai and Kumar,
                   Ananya and Newman, Benjamin and Yuan, Binhang and Yan, Bobby
                   and Zhang, Ce and Cosgrove, Christian and Manning,
                   Christopher D and R{\'e}, Christopher and Acosta-Navas,
                   Diana and Hudson, Drew A and Zelikman, Eric and Durmus, Esin
                   and Ladhak, Faisal and Rong, Frieda and Ren, Hongyu and Yao,
                   Huaxiu and Wang, Jue and Santhanam, Keshav and Orr, Laurel
                   and Zheng, Lucia and Yuksekgonul, Mert and Suzgun, Mirac and
                   Kim, Nathan and Guha, Neel and Chatterji, Niladri and
                   Khattab, Omar and Henderson, Peter and Huang, Qian and Chi,
                   Ryan and Xie, Sang Michael and Santurkar, Shibani and
                   Ganguli, Surya and Hashimoto, Tatsunori and Icard, Thomas
                   and Zhang, Tianyi and Chaudhary, Vishrav and Wang, William
                   and Li, Xuechen and Mai, Yifan and Zhang, Yuhui and Koreeda,
                   Yuta",
  abstract      = "Language models (LMs) are becoming the foundation for almost
                   all major language technologies, but their capabilities,
                   limitations, and risks are not well understood. We present
                   Holistic Evaluation of Language Models (HELM) to improve the
                   transparency of language models. First, we taxonomize the
                   vast space of potential scenarios (i.e. use cases) and
                   metrics (i.e. desiderata) that are of interest for LMs. Then
                   we select a broad subset based on coverage and feasibility,
                   noting what's missing or underrepresented (e.g. question
                   answering for neglected English dialects, metrics for
                   trustworthiness). Second, we adopt a multi-metric approach:
                   We measure 7 metrics (accuracy, calibration, robustness,
                   fairness, bias, toxicity, and efficiency) for each of 16
                   core scenarios when possible (87.5\% of the time). This
                   ensures metrics beyond accuracy don't fall to the wayside,
                   and that trade-offs are clearly exposed. We also perform 7
                   targeted evaluations, based on 26 targeted scenarios, to
                   analyze specific aspects (e.g. reasoning, disinformation).
                   Third, we conduct a large-scale evaluation of 30 prominent
                   language models (spanning open, limited-access, and closed
                   models) on all 42 scenarios, 21 of which were not previously
                   used in mainstream LM evaluation. Prior to HELM, models on
                   average were evaluated on just 17.9\% of the core HELM
                   scenarios, with some prominent models not sharing a single
                   scenario in common. We improve this to 96.0\%: now all 30
                   models have been densely benchmarked on the same core
                   scenarios and metrics under standardized conditions. Our
                   evaluation surfaces 25 top-level findings. For full
                   transparency, we release all raw model prompts and
                   completions publicly for further analysis, as well as a
                   general modular toolkit. We intend for HELM to be a living
                   benchmark for the community, continuously updated with new
                   scenarios, metrics, and models.",
  month         =  nov,
  year          =  2022,
  copyright     = "http://creativecommons.org/licenses/by/4.0/",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2211.09110",
  url           = "https://arxiv.org/abs/2211.09110",
}

@misc{korbak2023pretraining,
      title={Pretraining Language Models with Human Preferences}, 
      author={Tomasz Korbak and Kejian Shi and Angelica Chen and Rasika Bhalerao and Christopher L. Buckley and Jason Phang and Samuel R. Bowman and Ethan Perez},
      year={2023},
      eprint={2302.08582},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2302.08582},
}

@misc{mozes2023agile,
      title={Towards Agile Text Classifiers for Everyone}, 
      author={Maximilian Mozes and Jessica Hoffmann and Katrin Tomanek and Muhamed Kouate and Nithum Thain and Ann Yuan and Tolga Bolukbasi and Lucas Dixon},
      year={2023},
      eprint={2302.06541},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2302.06541},
}

@article{googlecloudclassifyingcontent,
  title={Google Cloud Classifying Content},
  author={Google},
  year={2022},
  url={https://cloud.google.com/natural-language/docs/classifying-text},
}

@misc{dev2021harms,
      title={Harms of Gender Exclusivity and Challenges in Non-Binary Representation in Language Technologies}, 
      author={Sunipa Dev and Masoud Monajatipoor and Anaelia Ovalle and Arjun Subramonian and Jeff M Phillips and Kai-Wei Chang},
      year={2021},
      eprint={2108.12084},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2108.12084},
}

@misc{ganguli2022red,
      title={Red Teaming Language Models to Reduce Harms: {M}ethods, Scaling Behaviors, and Lessons Learned}, 
      author={Deep Ganguli and Liane Lovitt and Jackson Kernion and Amanda Askell and Yuntao Bai and Saurav Kadavath and Ben Mann and Ethan Perez and Nicholas Schiefer and Kamal Ndousse and Andy Jones and Sam Bowman and Anna Chen and Tom Conerly and Nova DasSarma and Dawn Drain and Nelson Elhage and Sheer El-Showk and Stanislav Fort and Zac Hatfield-Dodds and Tom Henighan and Danny Hernandez and Tristan Hume and Josh Jacobson and Scott Johnston and Shauna Kravec and Catherine Olsson and Sam Ringer and Eli Tran-Johnson and Dario Amodei and Tom Brown and Nicholas Joseph and Sam McCandlish and Chris Olah and Jared Kaplan and Jack Clark},
      year={2022},
      eprint={2209.07858},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2209.07858},
}


@misc{pronouns-lee,
  title = {Welcome, singular "they"},
  howpublished = {\url{https://apastyle.apa.org/blog/singular-they}},
  year = {2019},
  author = {Chelsea Lee},
  note = {Accessed: 2022-11-18}
}

@article{wang2021simvlm,
  title={Sim{VLM}: Simple visual language model pretraining with weak supervision},
  author={Wang, Zirui and Yu, Jiahui and Yu, Adams Wei and Dai, Zihang and Tsvetkov, Yulia and Cao, Yuan},
  journal={arXiv preprint arXiv:2108.10904},
  year={2021},
  url={https://arxiv.org/abs/2108.10904}
}

@inproceedings{roberts-etal-2020-much,
    title = "How Much Knowledge Can You Pack Into the Parameters of a Language Model?",
    author = "Roberts, Adam  and
      Raffel, Colin  and
      Shazeer, Noam",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.437",
    doi = "10.18653/v1/2020.emnlp-main.437",
    pages = "5418--5426",
    abstract = "It has recently been observed that neural language models trained on unstructured text can implicitly store and retrieve knowledge using natural language queries. In this short paper, we measure the practical utility of this approach by fine-tuning pre-trained models to answer questions without access to any external context or knowledge. We show that this approach scales with model size and performs competitively with open-domain systems that explicitly retrieve answers from an external knowledge source when answering questions. To facilitate reproducibility and future work, we release our code and trained models.",
}


@inproceedings{sap-etal-2020-social,
    title = "Social Bias Frames: Reasoning about Social and Power Implications of Language",
    author = "Sap, Maarten  and
      Gabriel, Saadia  and
      Qin, Lianhui  and
      Jurafsky, Dan  and
      Smith, Noah A.  and
      Choi, Yejin",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.486",
    doi = "10.18653/v1/2020.acl-main.486",
    pages = "5477--5490",
    abstract = "Warning: this paper contains content that may be offensive or upsetting. Language has the power to reinforce stereotypes and project social biases onto others. At the core of the challenge is that it is rarely what is stated explicitly, but rather the implied meanings, that frame people{'}s judgments about others. For example, given a statement that {``}we shouldn{'}t lower our standards to hire more women,{''} most listeners will infer the implicature intended by the speaker - that {``}women (candidates) are less qualified.{''} Most semantic formalisms, to date, do not capture such pragmatic implications in which people express social biases and power differentials in language. We introduce Social Bias Frames, a new conceptual formalism that aims to model the pragmatic frames in which people project social biases and stereotypes onto others. In addition, we introduce the Social Bias Inference Corpus to support large-scale modelling and evaluation with 150k structured annotations of social media posts, covering over 34k implications about a thousand demographic groups. We then establish baseline approaches that learn to recover Social Bias Frames from unstructured text. We find that while state-of-the-art neural models are effective at high-level categorization of whether a given statement projects unwanted social bias (80{\%} F1), they are not effective at spelling out more detailed explanations in terms of Social Bias Frames. Our study motivates future work that combines structured pragmatic inference with commonsense reasoning on social implications.",
}

@inproceedings{Barocas2017FairnessAM,
  title={Fairness and Machine Learning Limitations and Opportunities},
  author={Solon Barocas and Moritz Hardt and Arvind Narayanan},
  year={2017}
}
@misc{pozzobon2023challenges,
      title={On the Challenges of Using Black-Box APIs for Toxicity Evaluation in Research}, 
      author={Luiza Pozzobon and Beyza Ermis and Patrick Lewis and Sara Hooker},
      year={2023},
      eprint={2304.12397},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{Paullada_2021,
	doi = {10.1016/j.patter.2021.100336},
  
	url = {https://doi.org/10.1016%2Fj.patter.2021.100336},
  
	year = 2021,
	month = {nov},
  
	publisher = {Elsevier {BV}
},
  
	volume = {2},
  
	number = {11},
  
	pages = {100336},
  
	author = {Amandalynne Paullada and Inioluwa Deborah Raji and Emily M. Bender and Emily Denton and Alex Hanna},
  
	title = {Data and its (dis)contents: A survey of dataset development and use in machine learning research},
  
	journal = {Patterns}
}

@misc{dodge2021documenting,
      title={Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus}, 
      author={Jesse Dodge and Maarten Sap and Ana Marasović and William Agnew and Gabriel Ilharco and Dirk Groeneveld and Margaret Mitchell and Matt Gardner},
      year={2021},
      eprint={2104.08758},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{luccioni2021whats,
      title={What's in the Box? A Preliminary Analysis of Undesirable Content in the Common Crawl Corpus}, 
      author={Alexandra Sasha Luccioni and Joseph D. Viviano},
      year={2021},
      eprint={2105.02732},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{garg2018,
author = {Nikhil Garg  and Londa Schiebinger  and Dan Jurafsky  and James Zou },
title = {Word embeddings quantify 100 years of gender and ethnic stereotypes},
journal = {Proceedings of the National Academy of Sciences},
volume = {115},
number = {16},
pages = {E3635-E3644},
year = {2018},
doi = {10.1073/pnas.1720347115},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.1720347115},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.1720347115},
abstract = {Word embeddings are a powerful machine-learning framework that represents each English word by a vector. The geometric relationship between these vectors captures meaningful semantic relationships between the corresponding words. In this paper, we develop a framework to demonstrate how the temporal dynamics of the embedding helps to quantify changes in stereotypes and attitudes toward women and ethnic minorities in the 20th and 21st centuries in the United States. We integrate word embeddings trained on 100 y of text data with the US Census to show that changes in the embedding track closely with demographic and occupation shifts over time. The embedding captures societal shifts—e.g., the women’s movement in the 1960s and Asian immigration into the United States—and also illuminates how specific adjectives and occupations became more closely associated with certain populations over time. Our framework for temporal analysis of word embedding opens up a fruitful intersection between machine learning and quantitative social science.}}

@misc{hendricks2018women,
      title={Women also Snowboard: Overcoming Bias in Captioning Models (Extended Abstract)}, 
      author={Lisa Anne Hendricks and Kaylee Burns and Kate Saenko and Trevor Darrell and Anna Rohrbach},
      year={2018},
      eprint={1807.00517},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{prabhu2020large,
      title={Large image datasets: A pyrrhic win for computer vision?}, 
      author={Vinay Uday Prabhu and Abeba Birhane},
      year={2020},
      eprint={2006.16923},
      archivePrefix={arXiv},
      primaryClass={cs.CY}
}


@inproceedings{goldfarb-tarrant-etal-2021-intrinsic,
    title = "Intrinsic Bias Metrics Do Not Correlate with Application Bias",
    author = "Goldfarb-Tarrant, Seraphina  and
      Marchant, Rebecca  and
      Mu{\~n}oz S{\'a}nchez, Ricardo  and
      Pandya, Mugdha  and
      Lopez, Adam",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.150",
    doi = "10.18653/v1/2021.acl-long.150",
    pages = "1926--1940",
    abstract = "Natural Language Processing (NLP) systems learn harmful societal biases that cause them to amplify inequality as they are deployed in more and more situations. To guide efforts at debiasing these systems, the NLP community relies on a variety of metrics that quantify bias in models. Some of these metrics are intrinsic, measuring bias in word embedding spaces, and some are extrinsic, measuring bias in downstream tasks that the word embeddings enable. Do these intrinsic and extrinsic metrics correlate with each other? We compare intrinsic and extrinsic metrics across hundreds of trained models covering different tasks and experimental conditions. Our results show no reliable correlation between these metrics that holds in all scenarios across tasks and languages. We urge researchers working on debiasing to focus on extrinsic measures of bias, and to make using these measures more feasible via creation of new challenge sets and annotated test data. To aid this effort, we release code, a new intrinsic metric, and an annotated test set focused on gender bias in hate speech.",
}
@inproceedings{rojas2022dollar,
  title={The dollar street dataset: Images representing the geographic and socioeconomic diversity of the world},
  author={Rojas, William A Gaviria and Diamos, Sudnya and Kini, Keertan Ranjan and Kanter, David and Reddi, Vijay Janapa and Coleman, Cody},
  booktitle={Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year={2022}
}
@article{kinniment2023evaluating,
  title={Evaluating language-model agents on realistic autonomous tasks},
  author={Kinniment, Megan and Sato, Lucas Jun Koba and Du, Haoxing and Goodrich, Brian and Hasin, Max and Chan, Lawrence and Miles, Luke Harold and Lin, Tao R and Wijk, Hjalmar and Burget, Joel and others},
  journal={arXiv preprint arXiv:2312.11671},
  year={2023}
}
@inproceedings{schumann2021step,
  title={A step toward more inclusive people annotations for fairness},
  author={Schumann, Candice and Ricco, Susanna and Prabhu, Utsav and Ferrari, Vittorio and Pantofaru, Caroline},
  booktitle={Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
  pages={916--925},
  year={2021}
}
@inproceedings{zhao2021understanding,
  title={Understanding and evaluating racial biases in image captioning},
  author={Zhao, Dora and Wang, Angelina and Russakovsky, Olga},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={14830--14840},
  year={2021}
}
@inproceedings{blodgett-etal-2021-stereotyping,
    title = "Stereotyping {N}orwegian Salmon: An Inventory of Pitfalls in Fairness Benchmark Datasets",
    author = "Blodgett, Su Lin  and
      Lopez, Gilsinia  and
      Olteanu, Alexandra  and
      Sim, Robert  and
      Wallach, Hanna",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.81",
    doi = "10.18653/v1/2021.acl-long.81",
    pages = "1004--1015",
    abstract = "Auditing NLP systems for computational harms like surfacing stereotypes is an elusive goal. Several recent efforts have focused on benchmark datasets consisting of pairs of contrastive sentences, which are often accompanied by metrics that aggregate an NLP system{'}s behavior on these pairs into measurements of harms. We examine four such benchmarks constructed for two NLP tasks: language modeling and coreference resolution. We apply a measurement modeling lens{---}originating from the social sciences{---}to inventory a range of pitfalls that threaten these benchmarks{'} validity as measurement models for stereotyping. We find that these benchmarks frequently lack clear articulations of what is being measured, and we highlight a range of ambiguities and unstated assumptions that affect how these benchmarks conceptualize and operationalize stereotyping.",
}

@inproceedings{hannaetal2020,
author = {Hanna, Alex and Denton, Emily and Smart, Andrew and Smith-Loud, Jamila},
title = {Towards a Critical Race Methodology in Algorithmic Fairness},
year = {2020},
isbn = {9781450369367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3351095.3372826},
doi = {10.1145/3351095.3372826},
abstract = {We examine the way race and racial categories are adopted in algorithmic fairness frameworks. Current methodologies fail to adequately account for the socially constructed nature of race, instead adopting a conceptualization of race as a fixed attribute. Treating race as an attribute, rather than a structural, institutional, and relational phenomenon, can serve to minimize the structural aspects of algorithmic unfairness. In this work, we focus on the history of racial categories and turn to critical race theory and sociological work on race and ethnicity to ground conceptualizations of race for fairness research, drawing on lessons from public health, biomedical research, and social survey research. We argue that algorithmic fairness researchers need to take into account the multidimensionality of race, take seriously the processes of conceptualizing and operationalizing race, focus on social processes which produce racial inequality, and consider perspectives of those most affected by sociotechnical systems.},
booktitle = {Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
pages = {501–512},
numpages = {12},
keywords = {algorithmic fairness, critical race theory, race and ethnicity},
location = {Barcelona, Spain},
series = {FAT* '20}
}

@inproceedings{barocas-disaggregated-2021,
author = {Barocas, Solon and Guo, Anhong and Kamar, Ece and Krones, Jacquelyn and Morris, Meredith Ringel and Vaughan, Jennifer Wortman and Wadsworth, W. Duncan and Wallach, Hanna},
title = {Designing Disaggregated Evaluations of AI Systems: Choices, Considerations, and Tradeoffs},
year = {2021},
isbn = {9781450384735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461702.3462610},
doi = {10.1145/3461702.3462610},
abstract = {Disaggregated evaluations of AI systems, in which system performance is assessed and reported separately for different groups of people, are conceptually simple. However, their design involves a variety of choices. Some of these choices influence the results that will be obtained, and thus the conclusions that can be drawn; others influence the impacts---both beneficial and harmful---that a disaggregated evaluation will have on people, including the people whose data is used to conduct the evaluation. We argue that a deeper understanding of these choices will enable researchers and practitioners to design careful and conclusive disaggregated evaluations. We also argue that better documentation of these choices, along with the underlying considerations and tradeoffs that have been made, will help others when interpreting an evaluation's results and conclusions.},
booktitle = {Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {368–378},
numpages = {11},
keywords = {fairness, machine learning, artificial intelligence, disaggregated evaluations, evaluations},
location = {Virtual Event, USA},
series = {AIES '21}
}

@misc{movva2023coarse,
      title={Coarse race data conceals disparities in clinical risk score performance}, 
      author={Rajiv Movva and Divya Shanmugam and Kaihua Hou and Priya Pathak and John Guttag and Nikhil Garg and Emma Pierson},
      year={2023},
      eprint={2304.09270},
      archivePrefix={arXiv},
      primaryClass={cs.CY}
}

@misc{gebru2021datasheets,
      title={Datasheets for Datasets}, 
      author={Timnit Gebru and Jamie Morgenstern and Briana Vecchione and Jennifer Wortman Vaughan and Hanna Wallach and Hal Daumé III au2 and Kate Crawford},
      year={2021},
      eprint={1803.09010},
      archivePrefix={arXiv},
      primaryClass={cs.DB}
}

@article{bender-friedman-2018-data,
    title = "Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science",
    author = "Bender, Emily M.  and
      Friedman, Batya",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "6",
    year = "2018",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/Q18-1041",
    doi = "10.1162/tacl_a_00041",
    pages = "587--604",
    abstract = "In this paper, we propose data statements as a design solution and professional practice for natural language processing technologists, in both research and development. Through the adoption and widespread use of data statements, the field can begin to address critical scientific and ethical issues that result from the use of data from certain populations in the development of technology for other populations. We present a form that data statements can take and explore the implications of adopting them as part of regular practice. We argue that data statements will help alleviate issues related to exclusion and bias in language technology, lead to better precision in claims about how natural language processing research can generalize and thus better engineering results, protect companies from public embarrassment, and ultimately lead to language technology that meets its users in their own preferred linguistic style and furthermore does not misrepresent them to others.",
}

@article{keyes2018,
author = {Keyes, Os},
title = {The Misgendering Machines: Trans/HCI Implications of Automatic Gender Recognition},
year = {2018},
issue_date = {November 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {CSCW},
url = {https://doi.org/10.1145/3274357},
doi = {10.1145/3274357},
abstract = {Automatic Gender Recognition (AGR) is a subfield of facial recognition that aims to algorithmically identify the gender of individuals from photographs or videos. In wider society the technology has proposed applications in physical access control, data analytics and advertising. Within academia, it is already used in the field of Human-Computer Interaction (HCI) to analyse social media usage. Given the long-running critiques of HCI for failing to consider and include transgender (trans) perspectives in research, and the potential implications of AGR for trans people if deployed, I sought to understand how AGR and HCI understand the term "gender", and how HCI describes and deploys gender recognition technology. Using a content analysis of papers from both fields, I show that AGR consistently operationalises gender in a trans-exclusive way, and consequently carries disproportionate risk for trans people subject to it. In addition, I use the dearth of discussion of this in HCI papers that apply AGR to discuss how HCI operationalises gender, and the implications that this has for the field's research. I conclude with recommendations for alternatives to AGR, and some ideas for how HCI can work towards a more effective and trans-inclusive treatment of gender.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {nov},
articleno = {88},
numpages = {22},
keywords = {machine learning, automatic gender recognition, transgender, gender}
}

@misc{pushkarna2022data,
      title={Data Cards: Purposeful and Transparent Dataset Documentation for Responsible AI}, 
      author={Mahima Pushkarna and Andrew Zaldivar and Oddur Kjartansson},
      year={2022},
      eprint={2204.01075},
      archivePrefix={arXiv},
      primaryClass={cs.HC}
}

@article{gspmd,
  title={GSPMD: general and scalable parallelization for ML computation graphs},
  author={Xu, Yuanzhong and Lee, HyoukJoong and Chen, Dehao and Hechtman, Blake and Huang, Yanping and Joshi, Rahul and Krikun, Maxim and Lepikhin, Dmitry and Ly, Andy and Maggioni, Marcello and others},
  journal={arXiv preprint arXiv:2105.04663},
  year={2021}
}

@misc{pax2022pax,
  author={Pax},
  title={Pax},
  year={2022},
  url={https://github.com/google/paxml},
}

@misc{sax2022sax,
  author={Sax},
  title={Sax},
  year={2022},
  url={https://github.com/google/saxml},
}

@article{barham2022pathways,
  title={Pathways: Asynchronous distributed dataflow for ml},
  author={Barham, Paul and Chowdhery, Aakanksha and Dean, Jeff and Ghemawat, Sanjay and Hand, Steven and Hurt, Daniel and Isard, Michael and Lim, Hyeontaek and Pang, Ruoming and Roy, Sudip and others},
  journal={Proceedings of Machine Learning and Systems},
  volume={4},
  pages={430--449},
  year={2022}
}

@article{masry2022chartqa,
  title={Chartqa: A benchmark for question answering about charts with visual and logical reasoning},
  author={Masry, Ahmed and Long, Do Xuan and Tan, Jia Qing and Joty, Shafiq and Hoque, Enamul},
  journal={arXiv preprint arXiv:2203.10244},
  year={2022}
}

@misc{reddit-memes,
  author={Goswami, Sayan},
  title={Reddit Memes Dataset},
  year={2018},
  url={https://www.kaggle.com/datasets/sayangoswami/reddit-memes-dataset},
}

@misc{rauh2022characteristics,
      title={Characteristics of Harmful Text: Towards Rigorous Benchmarking of Language Models}, 
      author={Maribeth Rauh and John Mellor and Jonathan Uesato and Po-Sen Huang and Johannes Welbl and Laura Weidinger and Sumanth Dathathri and Amelia Glaese and Geoffrey Irving and Iason Gabriel and William Isaac and Lisa Anne Hendricks},
      year={2022},
      eprint={2206.08325},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{welty2019metrology,
      title={Metrology for AI: From Benchmarks to Instruments}, 
      author={Chris Welty and Praveen Paritosh and Lora Aroyo},
      year={2019},
      eprint={1911.01875},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@article{dwork-fairness-under-composition2018,
  doi = {10.4230/LIPICS.ITCS.2019.33},
  
  url = {http://drops.dagstuhl.de/opus/volltexte/2018/10126/},
  
  author = {Dwork, Cynthia and Ilvento, Christina},
  
  keywords = {Computer Science, 000 Computer science, knowledge, general works},
  
  language = {en},
  
  title = {Fairness Under Composition},
  
  publisher = {Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik GmbH, Wadern/Saarbruecken, Germany},
  
  year = {2018},
  
  copyright = {Creative Commons Attribution 3.0 Unported license (CC-BY 3.0)}
}

@misc{dipalo2024keypointactiontokensenable,
      title={Keypoint Action Tokens Enable In-Context Imitation Learning in Robotics}, 
      author={Di Palo, Norman and Johns, Edward},
      year={2024},
      eprint={2403.19578},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2403.19578}, 
}

@inproceedings{Tomasev_2021,
	doi = {10.1145/3461702.3462540},
  
	url = {https://doi.org/10.1145%2F3461702.3462540},
  
	year = 2021,
	month = {jul},
  
	publisher = {{ACM}
},
  
	author = {Nenad Tomasev and Kevin R. McKee and Jackie Kay and Shakir Mohamed},
  
	title = {Fairness for Unobserved Characteristics: Insights from Technological Impacts on Queer Communities},
  
	booktitle = {Proceedings of the 2021 {AAAI}/{ACM} Conference on {AI},
   Ethics, and Society}
}

@article{olteanu-socialdata-2016,
author = {Olteanu, Alexandra and Castillo, Carlos and Diaz, Fernando and Kiciman, Emre},
year = {2016},
month = {01},
pages = {},
title = {Social Data: Biases, Methodological Pitfalls, and Ethical Boundaries},
journal = {SSRN Electronic Journal},
doi = {10.2139/ssrn.2886526}
}

@misc{denton2020bringing,
      title={Bringing the People Back In: Contesting Benchmark Machine Learning Datasets}, 
      author={Emily Denton and Alex Hanna and Razvan Amironesei and Andrew Smart and Hilary Nicole and Morgan Klaus Scheuerman},
      year={2020},
      eprint={2007.07399},
      archivePrefix={arXiv},
      primaryClass={cs.CY}
}
@misc{bowman2021fix,
      title={What Will it Take to Fix Benchmarking in Natural Language Understanding?}, 
      author={Samuel R. Bowman and George E. Dahl},
      year={2021},
      eprint={2104.02145},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{schlangen2020targeting,
      title={Targeting the Benchmark: On Methodology in Current Natural Language Processing Research}, 
      author={David Schlangen},
      year={2020},
      eprint={2007.04792},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{rodriguez-etal-2021-evaluation,
    title = "Evaluation Examples are not Equally Informative: How should that change {NLP} Leaderboards?",
    author = "Rodriguez, Pedro  and
      Barrow, Joe  and
      Hoyle, Alexander Miserlis  and
      Lalor, John P.  and
      Jia, Robin  and
      Boyd-Graber, Jordan",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.346",
    doi = "10.18653/v1/2021.acl-long.346",
    pages = "4486--4503",
    abstract = "Leaderboards are widely used in NLP and push the field forward. While leaderboards are a straightforward ranking of NLP models, this simplicity can mask nuances in evaluation items (examples) and subjects (NLP models). Rather than replace leaderboards, we advocate a re-imagining so that they better highlight if and where progress is made. Building on educational testing, we create a Bayesian leaderboard model where latent subject skill and latent item difficulty predict correct responses. Using this model, we analyze the ranking reliability of leaderboards. Afterwards, we show the model can guide what to annotate, identify annotation errors, detect overfitting, and identify informative examples. We conclude with recommendations for future benchmark tasks.",
}

@misc{wiki:Shanghai_World_Financial_Center,
   author = "Wikipedia",
   title = "{Shanghai World Financial Center} --- {W}ikipedia{,} The Free Encyclopedia",
   year = "2023",
   howpublished = {\url{http://en.wikipedia.org/w/index.php?title=Shanghai\%20World\%20Financial\%20Center}},
  note = "[Online; accessed 03-May-2023]"
 }
 
 @article{kiela2020hateful,
  title={The hateful memes challenge: Detecting hate speech in multimodal memes},
  author={Kiela, Douwe and Firooz, Hamed and Mohan, Aravind and Goswami, Vedanuj and Singh, Amanpreet and Ringshia, Pratik and Testuggine, Davide},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={2611--2624},
  year={2020}
}


@ARTICLE{google_code_completion,
  title        = "\{ML-Enhanced\} Code Completion Improves Developer Productivity",
  author       = "Tabachnyk, Maxim and Nikolov, Stoyan",
  howpublished = "\url{https://ai.googleblog.com/2022/07/ml-enhanced-code-completion-improves.html}",
  month        = jul,
  year         = 2022
}


@ARTICLE{arcade,
  title         = "Natural Language to Code Generation in Interactive Data
                   Science Notebooks",
  author        = "Yin, Pengcheng and Li, Wen-Ding and Xiao, Kefan and Rao,
                   Abhishek and Wen, Yeming and Shi, Kensen and Howland, Joshua
                   and Bailey, Paige and Catasta, Michele and Michalewski,
                   Henryk and Polozov, Alex and Sutton, Charles",
  month         =  dec,
  year          =  2022,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2212.09248"
}

@MISC{copilot,
  title       = "Your {AI} pair programmer",
  author      = "Github",
  institution = "Github",
  language    = "en",
  month        = oct,
  year         = 2021
}


@MISC{ghostwriter,
  title        = "Meet Replit Ghostwriter, your partner in code",
  author       = "Replit",
  booktitle    = "Replit Blog",
  howpublished = "\url{https://blog.replit.com/ghostwriter}",
  note         = "Accessed: 2023-5-5",
  month        = oct,
  year         = 2022
}


@MISC{chatgpt,
  title        = "Introducing {ChatGPT}",
  author       = "OpenAI",
  howpublished = "\url{https://openai.com/blog/chatgpt}",
  note         = "Accessed: 2023-5-5",
  language     = "en",
  year         = 2022,
  month        = nov,
}


@MISC{bard,
  title        = "Try Bard and share your feedback",
  booktitle    = "Google",
  author       = "Hsiao, Sissie and Collins, Eli",
  month        =  mar,
  year         =  2023,
  howpublished = "\url{https://blog.google/technology/ai/try-bard/}",
  note         = "Accessed: 2023-5-5",
  language     = "en",
  year         = 2023,
}


@MISC{chatgpt_plugins,
  title        = "{ChatGPT} plugins",
  author       = "OpenAI",
  howpublished = "\url{https://openai.com/blog/chatgpt-plugins}",
  note         = "Accessed: 2023-5-5",
  language     = "en",
  year         = 2023,
  month        = mar,
}


@ARTICLE{babelcode,
  title         = "Measuring The Impact Of Programming Language Distribution",
  author        = "Orlanski, Gabriel and Xiao, Kefan and Garcia, Xavier and
                   Hui, Jeffrey and Howland, Joshua and Malmaud, Jonathan and
                   Austin, Jacob and Singh, Rishah and Catasta, Michele",
  month         =  feb,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG",
  eprint        = "2302.01973"
}
@INPROCEEDINGS{kneser_ney,
  author={Kneser, R. and Ney, H.},
  booktitle={1995 International Conference on Acoustics, Speech, and Signal Processing}, 
  title={Improved backing-off for M-gram language modeling}, 
  year={1995},
  volume={1},
  number={},
  pages={181-184 vol.1},
  doi={10.1109/ICASSP.1995.479394}}
@misc{graves2014generating,
      title={Generating Sequences With Recurrent Neural Networks}, 
      author={Alex Graves},
      year={2014},
      eprint={1308.0850},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}
@article{Hochreiter,
    author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
    title = "{Long Short-Term Memory}",
    journal = {Neural Computation},
    volume = {9},
    number = {8},
    pages = {1735-1780},
    year = {1997},
    month = {11},
    abstract = "{Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.}",
    issn = {0899-7667},
    doi = {10.1162/neco.1997.9.8.1735},
    url = {https://doi.org/10.1162/neco.1997.9.8.1735},
    eprint = {https://direct.mit.edu/neco/article-pdf/9/8/1735/813796/neco.1997.9.8.1735.pdf},
}

@article{longpre2023flan,
  title={The flan collection: Designing data and methods for effective instruction tuning},
  author={Longpre, Shayne and Hou, Le and Vu, Tu and Webson, Albert and Chung, Hyung Won and Tay, Yi and Zhou, Denny and Le, Quoc V and Zoph, Barret and Wei, Jason and Roberts, Adam},
  journal={arXiv preprint arXiv:2301.13688},
  year={2023}
}

@article{abid2021persistent,
      title={Persistent Anti-Muslim Bias in Large Language Models}, 
      author={Abubakar Abid and Maheen Farooqi and James Zou},
      year={2021},
      eprint={2101.05783},
      journal={arXiv preprint arXiv:2101.05783},
      url={https://arxiv.org/abs/2101.05783},
      primaryClass={cs.CL}
}

@misc{guide-to-fair-pay,
  url = {https://success.appen.com/hc/en-us/articles/9557008940941-Guide-to-Fair-Pay},
  author = {Appen},
  title = {Guide to Fair Pay},
  year = {2023},
}


@misc{jigsaw-exploring-role-2019,
  url = {https://medium.com/jigsaw/creating-labeled-datasets-and-exploring-the-role-of-human-raters-56367b6db298},
  author = {Jigsaw},
  title = {Exploring the Role of Human Raters in Creating NLP Datasets},
  year = {2019},
}

@misc{ai-principles,
  url = {https://ai.google/responsibility/principles/},
  author = {Google},
  title = {Our Principles},
  note = {Accessed May 16, 2023},
  year = {2018},
}

@misc{generative-ai-use-policy,
  url = {https://policies.google.com/terms/generative-ai/use-policy},
  author = {Google},
  title = {Generative AI Prohibited Use Policy},
  note = {Accessed May 16, 2023},
  year = {2023},
}

@misc{palm-api-makersuite-terms,
  url = {https://developers.generativeai.google/terms},
  author = {Google},
  title = {PaLM API and MakerSuite Additional Terms of Service},
  note = {Accessed May 16, 2023},
  year = {2023},
}

@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@article{shazeer2019fast,
  title={Fast transformer decoding: One write-head is all you need},
  author={Shazeer, Noam},
  journal={arXiv preprint arXiv:1911.02150},
  year={2019}
}

@article{rostamzadeh2021thinking,
  title={Thinking Beyond Distributions in Testing Machine Learned Models},
  author={Rostamzadeh, Negar and Hutchinson, Ben and Greer, Christina and Prabhakaran, Vinodkumar},
  journal={NeurIPS Workshop on Distributional Shifts},
  year={2021}
}

@inproceedings{sap2019risk,
  title={The Risk of Racial Bias in Hate Speech Detection},
  author={Sap, Maarten and Card, Dallas and Gabriel, Saadia and Choi, Yejin and Smith, Noah A},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={1668--1678},
  year={2019}
}

@article{raji2021ai,
  author    = {Inioluwa Deborah Raji and
               Emily M. Bender and
               Amandalynne Paullada and
               Emily Denton and
               Alex Hanna},
  title     = {{AI} and the Everything in the Whole Wide World Benchmark},
  journal   = {CoRR},
  volume    = {abs/2111.15366},
  year      = {2021},
  url       = {https://arxiv.org/abs/2111.15366},
  eprinttype = {arXiv},
  eprint    = {2111.15366},
  timestamp = {Thu, 02 Dec 2021 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2111-15366.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{gpt-j,
  author = {Wang, Ben and Komatsuzaki, Aran},
  title = {{GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model}},
  howpublished = {\url{https://github.com/kingoflolz/mesh-transformer-jax}},
  year = 2021,
  month = May
}

@article{mccandlish2018empirical,
  title={An empirical model of large-batch training},
  author={McCandlish, Sam and Kaplan, Jared and Amodei, Dario and Team, OpenAI Dota},
  journal={arXiv preprint arXiv:1812.06162},
  year={2018}
}

@article{zeng2021pangu,
  title={PanGu-$\alpha$: Large-scale Autoregressive Pretrained Chinese Language Models with Auto-parallel Computation},
  author={Zeng, Wei and Ren, Xiaozhe and Su, Teng and Wang, Hui and Liao, Yi and Wang, Zhiwei and Jiang, Xin and Yang, ZhenZhang and Wang, Kaisheng and Zhang, Xiaoda and others},
  journal={arXiv preprint arXiv:2104.12369},
  year={2021}
}

@article{roberts2022t5x,
  url = {https://arxiv.org/abs/2203.17189},
  author = {Roberts, Adam and Chung, Hyung Won and Levskaya, Anselm and Mishra, Gaurav and Bradbury, James and Andor, Daniel and Narang, Sharan and Lester, Brian and Gaffney, Colin and Mohiuddin, Afroz and Hawthorne, Curtis and Lewkowycz, Aitor and Salcianu, Alex and van Zee, Marc and Austin, Jacob and Goodman, Sebastian and Soares, Livio Baldini and Hu, Haitang and Tsvyashchenko, Sasha and Chowdhery, Aakanksha and Bastings, Jasmijn and Bulian, Jannis and Garcia, Xavier and Ni, Jianmo and Chen, Andrew and Kenealy, Kathleen and Clark, Jonathan H. and Lee, Stephan and Garrette, Dan and Lee-Thorp, James and Raffel, Colin and Shazeer, Noam and Ritter, Marvin and Bosma, Maarten and Passos, Alexandre and Maitin-Shepard, Jeremy and Fiedel, Noah and Omernick, Mark and Saeta, Brennan and Sepassi, Ryan and Spiridonov, Alexander and Newlan, Joshua and Gesmundo, Andrea},
 
  title = {Scaling Up Models and Data with $\texttt{t5x}$ and $\texttt{seqio}$},
 
  journal={arXiv preprint arXiv:2203.17189},

  year = {2022},
}

@inproceedings{dodge2021documenting,
  title={Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus},
  author={Dodge, Jesse and Sap, Maarten and Marasovi{\'c}, Ana and Agnew, William and Ilharco, Gabriel and Groeneveld, Dirk and Mitchell, Margaret and Gardner, Matt},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={1286--1305},
  year={2021}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@inproceedings{hutchinson2020social,
  title={Social Biases in NLP Models as Barriers for Persons with Disabilities},
  author={Hutchinson, Ben and Prabhakaran, Vinodkumar and Denton, Emily and Webster, Kellie and Zhong, Yu and Denuyl, Stephen},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={5491--5501},
  year={2020}
}

@article{borgeaud2021improving,
  title={Improving language models by retrieving from trillions of tokens},
  author={Borgeaud, Sebastian and Mensch, Arthur and Hoffmann, Jordan and Cai, Trevor and Rutherford, Eliza and Millican, Katie and Driessche, George van den and Lespiau, Jean-Baptiste and Damoc, Bogdan and Clark, Aidan and others},
  journal={arXiv preprint arXiv:2112.04426},
  year={2021}
}

@inproceedings{gardent-etal-2017-webnlg,
    title = "The {W}eb{NLG} Challenge: Generating Text from {RDF} Data",
    author = "Gardent, Claire  and
      Shimorina, Anastasia  and
      Narayan, Shashi  and
      Perez-Beltrachini, Laura",
    booktitle = "Proceedings of the 10th International Conference on Natural Language Generation",
    
    year = "2017",
    
    
    url = "https://aclanthology.org/W17-3518",
    
    pages = "124--133",
    abstract = "The WebNLG challenge consists in mapping sets of RDF triples to text. It provides a common benchmark on which to train, evaluate and compare {``}microplanners{''}, i.e. generation systems that verbalise a given content by making a range of complex interacting choices including referring expression generation, aggregation, lexicalisation, surface realisation and sentence segmentation. In this paper, we introduce the microplanning task, describe data preparation, introduce our evaluation methodology, analyse participant results and provide a brief description of the participating systems.",
}

@article{dai2020funnel,
  title={Funnel-transformer: Filtering out sequential redundancy for efficient language processing},
  author={Dai, Zihang and Lai, Guokun and Yang, Yiming and Le, Quoc},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={4271--4282},
  year={2020}
}

@inproceedings{katharopoulos2020transformers,
  title={Transformers are rnns: Fast autoregressive transformers with linear attention},
  author={Katharopoulos, Angelos and Vyas, Apoorv and Pappas, Nikolaos and Fleuret, Fran{\c{c}}ois},
  booktitle={International Conference on Machine Learning},
  pages={5156--5165},
  year={2020},
  organization={PMLR}
}

@inproceedings{dusek-etal-2019-semantic,
    title = "Semantic Noise Matters for Neural Natural Language Generation",
    author = "Du{\v{s}}ek, Ond{\v{r}}ej  and
      Howcroft, David M.  and
      Rieser, Verena",
    booktitle = "Proceedings of the 12th International Conference on Natural Language Generation",
    
    year = "2019",
    
    
    url = "https://aclanthology.org/W19-8652",
    
    pages = "421--426",
    abstract = "Neural natural language generation (NNLG) systems are known for their pathological outputs, i.e. generating text which is unrelated to the input specification. In this paper, we show the impact of semantic noise on state-of-the-art NNLG models which implement different semantic control mechanisms. We find that cleaned data can improve semantic correctness by up to 97{\%}, while maintaining fluency. We also find that the most common error is omitting information, rather than hallucination.",
}

@inproceedings{nan-etal-2021-dart,
    title = "{DART}: Open-Domain Structured Data Record to Text Generation",
    author = "Nan, Linyong  and
      Radev, Dragomir  and
      Zhang, Rui  and
      Rau, Amrit  and
      Sivaprasad, Abhinand  and
      Hsieh, Chiachun  and
      Tang, Xiangru  and
      Vyas, Aadit  and
      Verma, Neha  and
      Krishna, Pranav  and
      Liu, Yangxiaokang  and
      Irwanto, Nadia  and
      Pan, Jessica  and
      Rahman, Faiaz  and
      Zaidi, Ahmad  and
      Mutuma, Mutethia  and
      Tarabar, Yasin  and
      Gupta, Ankit  and
      Yu, Tao  and
      Tan, Yi Chern  and
      Lin, Xi Victoria  and
      Xiong, Caiming  and
      Socher, Richard  and
      Rajani, Nazneen Fatema",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    
    year = "2021",
    
    
    url = "https://aclanthology.org/2021.naacl-main.37",
    
    pages = "432--447",
    abstract = "We present DART, an open domain structured DAta Record to Text generation dataset with over 82k instances (DARTs). Data-to-text annotations can be a costly process, especially when dealing with tables which are the major source of structured data and contain nontrivial structures. To this end, we propose a procedure of extracting semantic triples from tables that encodes their structures by exploiting the semantic dependencies among table headers and the table title. Our dataset construction framework effectively merged heterogeneous sources from open domain semantic parsing and spoken dialogue systems by utilizing techniques including tree ontology annotation, question-answer pair to declarative sentence conversion, and predicate unification, all with minimum post-editing. We present systematic evaluation on DART as well as new state-of-the-art results on WebNLG 2017 to show that DART (1) poses new challenges to existing data-to-text datasets and (2) facilitates out-of-domain generalization. Our data and code can be found at https://github.com/Yale-LILY/dart.",
}

@inproceedings{lin-etal-2020-commongen,
    title = "{C}ommon{G}en: A Constrained Text Generation Challenge for Generative Commonsense Reasoning",
    author = "Lin, Bill Yuchen  and
      Zhou, Wangchunshu  and
      Shen, Ming  and
      Zhou, Pei  and
      Bhagavatula, Chandra  and
      Choi, Yejin  and
      Ren, Xiang",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    
    year = "2020",
    
    
    url = "https://aclanthology.org/2020.findings-emnlp.165",
    
    pages = "1823--1840",
    abstract = "Recently, large-scale pre-trained language models have demonstrated impressive performance on several commonsense-reasoning benchmark datasets. However, building machines with commonsense to compose realistically plausible sentences remains challenging. In this paper, we present a constrained text generation task, CommonGen associated with a benchmark dataset, to explicitly test machines for the ability of generative commonsense reasoning. Given a set of common concepts (e.g., dog, frisbee, catch, throw); the task is to generate a coherent sentence describing an everyday scenario using these concepts (e.g., {``}a man throws a frisbee and his dog catches it{''}). The CommonGen task is challenging because it inherently requires 1) relational reasoning with background commonsense knowledge and 2) compositional generalization ability to work on unseen concept combinations. Our dataset, constructed through a combination of crowdsourced and existing caption corpora, consists of 77k commonsense descriptions over 35k unique concept-sets. Experiments show that there is a large gap between state-of-the-art text generation models (e.g., T5) and human performance (31.6{\%} v.s. 63.5{\%} in SPICE metric). Furthermore, we demonstrate that the learned generative commonsense reasoning capability can be transferred to improve downstream tasks such as CommonsenseQA (76.9{\%} to 78.4 in dev accuracy) by generating additional context.",
}

@book{mccarthy1960programs,
  title={Programs with common sense},
  author={McCarthy, John},
  year={1960},
  publisher={RLE and MIT computation center},
  url={http://jmc.stanford.edu/articles/mcc59/mcc59.pdf}
}

@article{goldwasser2014learning,
  title={Learning from natural instructions},
  author={Goldwasser, Dan and Roth, Dan},
  journal={Machine learning},
  volume={94},
  number={2},
  pages={205--232},
  year={2014},
  publisher={Springer},
  url={https://link.springer.com/article/10.1007/s10994-013-5407-y}
}

@inproceedings{peters-etal-2018-deep,
    title = "Deep Contextualized Word Representations",
    author = "Peters, Matthew E.  and
      Neumann, Mark  and
      Iyyer, Mohit  and
      Gardner, Matt  and
      Clark, Christopher  and
      Lee, Kenton  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    
    year = "2018",
    
    
    url = "https://aclanthology.org/N18-1202",
    
    pages = "2227--2237",
    abstract = "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
}

@article{su2021,
  author    = {Jianlin Su and
               Yu Lu and
               Shengfeng Pan and
               Bo Wen and
               Yunfeng Liu},
  title     = {RoFormer: Enhanced Transformer with Rotary Position Embedding},
  journal   = {CoRR},
  volume    = {abs/2104.09864},
  year      = {2021},
  url       = {https://arxiv.org/abs/2104.09864},
  eprinttype = {arXiv},
  eprint    = {2104.09864},
  timestamp = {Mon, 26 Apr 2021 17:25:10 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2104-09864.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{chen2023longlora,
  title={Longlora: Efficient fine-tuning of long-context large language models},
  author={Chen, Yukang and Qian, Shengju and Tang, Haotian and Lai, Xin and Liu, Zhijian and Han, Song and Jia, Jiaya},
  journal={arXiv preprint arXiv:2309.12307},
  URL="https://arxiv.org/abs/2309.12307",
  year={2023}
}

@article{li2023functional,
  title={Functional interpolation for relative positions improves long context transformers},
  author={Li, Shanda and You, Chong and Guruganesh, Guru and Ainslie, Joshua and Ontanon, Santiago and Zaheer, Manzil and Sanghai, Sumit and Yang, Yiming and Kumar, Sanjiv and Bhojanapalli, Srinadh},
  journal={arXiv preprint arXiv:2310.04418},
  year={2023}
}

@article{chen2023extending,
  title={Extending context window of large language models via positional interpolation},
  author={Chen, Shouyuan and Wong, Sherman and Chen, Liangjian and Tian, Yuandong},
  journal={arXiv preprint arXiv:2306.15595},
  URL="https://arxiv.org/abs/2306.15595",
  year={2023}
}

@article{press2021train,
  title={Train short, test long: Attention with linear biases enables input length extrapolation},
  author={Press, Ofir and Smith, Noah A and Lewis, Mike},
  journal={arXiv preprint arXiv:2108.12409},
  year={2021}
}

@article{peng2023yarn,
  title={Yarn: Efficient context window extension of large language models},
  author={Peng, Bowen and Quesnelle, Jeffrey and Fan, Honglu and Shippole, Enrico},
  journal={arXiv preprint arXiv:2309.00071},
  year={2023}
}

@article{kazemnejad2023impact,
  title={The Impact of Positional Encoding on Length Generalization in Transformers},
  author={Kazemnejad, Amirhossein and Padhi, Inkit and Ramamurthy, Karthikeyan Natesan and Das, Payel and Reddy, Siva},
  journal={arXiv preprint arXiv:2305.19466},
  year={2023}
}

@article{xiong2023effective,
  title={Effective long-context scaling of foundation models},
  author={Xiong, Wenhan and Liu, Jingyu and Molybog, Igor and Zhang, Hejia and Bhargava, Prajjwal and Hou, Rui and Martin, Louis and Rungta, Rashi and Sankararaman, Karthik Abinav and Oguz, Barlas and others},
  journal={arXiv preprint arXiv:2309.16039},
  year={2023}
}

@article{jin2024llm,
  title={LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning},
  author={Jin, Hongye and Han, Xiaotian and Yang, Jingfeng and Jiang, Zhimeng and Liu, Zirui and Chang, Chia-Yuan and Chen, Huiyuan and Hu, Xia},
  journal={arXiv preprint arXiv:2401.01325},
  year={2024}
}

@article{bertsch2023unlimiformer,
  title={Unlimiformer: Long-range transformers with unlimited length input},
  author={Bertsch, Amanda and Alon, Uri and Neubig, Graham and Gormley, Matthew R},
  journal={arXiv preprint arXiv:2305.01625},
  year={2023}
}

@article{gu2023mamba,
  title={Mamba: Linear-time sequence modeling with selective state spaces},
  author={Gu, Albert and Dao, Tri},
  journal={arXiv preprint arXiv:2312.00752},
  URL="https://arxiv.org/abs/2312.00752",
  year={2023}
}

@article{orvieto2023resurrecting,
  title={Resurrecting recurrent neural networks for long sequences},
  author={Orvieto, Antonio and Smith, Samuel L and Gu, Albert and Fernando, Anushan and Gulcehre, Caglar and Pascanu, Razvan and De, Soham},
  journal={arXiv preprint arXiv:2303.06349},
  year={2023}
}

@article{guo2021longt5,
  title={LongT5: Efficient text-to-text transformer for long sequences},
  author={Guo, Mandy and Ainslie, Joshua and Uthus, David and Ontanon, Santiago and Ni, Jianmo and Sung, Yun-Hsuan and Yang, Yinfei},
  journal={arXiv preprint arXiv:2112.07916},
  URL="https://arxiv.org/abs/2112.07916",
  year={2021}
}

@article{ainslie2023colt5,
  title={Colt5: Faster long-range transformers with conditional computation},
  author={Ainslie, Joshua and Lei, Tao and de Jong, Michiel and Onta{\~n}{\'o}n, Santiago and Brahma, Siddhartha and Zemlyanskiy, Yury and Uthus, David and Guo, Mandy and Lee-Thorp, James and Tay, Yi and others},
  journal={arXiv preprint arXiv:2303.09752},
  year={2023}
}

@inproceedings{karpukhin2020dense,
    title = "Dense Passage Retrieval for Open-Domain Question Answering",
    author = "Karpukhin, Vladimir  and
      Oguz, Barlas  and
      Min, Sewon  and
      Lewis, Patrick  and
      Wu, Ledell  and
      Edunov, Sergey  and
      Chen, Danqi  and
      Yih, Wen-tau",
    editor = "Webber, Bonnie  and
      Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.550",
    doi = "10.18653/v1/2020.emnlp-main.550",
    pages = "6769--6781",
    abstract = "Open-domain question answering relies on efficient passage retrieval to select candidate contexts, where traditional sparse vector space models, such as TF-IDF or BM25, are the de facto method. In this work, we show that retrieval can be practically implemented using dense representations alone, where embeddings are learned from a small number of questions and passages by a simple dual-encoder framework. When evaluated on a wide range of open-domain QA datasets, our dense retriever outperforms a strong Lucene-BM25 system greatly by 9{\%}-19{\%} absolute in terms of top-20 passage retrieval accuracy, and helps our end-to-end QA system establish new state-of-the-art on multiple open-domain QA benchmarks.",
}


@article{izacard2022few,
  title={Few-shot learning with retrieval augmented language models},
  author={Izacard, Gautier and Lewis, Patrick and Lomeli, Maria and Hosseini, Lucas and Petroni, Fabio and Schick, Timo and Dwivedi-Yu, Jane and Joulin, Armand and Riedel, Sebastian and Grave, Edouard},
  journal={arXiv preprint arXiv:2208.03299},
  year={2022},
  url="https://arxiv.org/abs/2208.03299"
}

@inproceedings{jiang-etal-2022-retrieval,
    title = "Retrieval as Attention: End-to-end Learning of Retrieval and Reading within a Single Transformer",
    author = "Jiang, Zhengbao  and
      Gao, Luyu  and
      Wang, Zhiruo  and
      Araki, Jun  and
      Ding, Haibo  and
      Callan, Jamie  and
      Neubig, Graham",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.149",
    doi = "10.18653/v1/2022.emnlp-main.149",
    pages = "2336--2349",
    abstract = "Systems for knowledge-intensive tasks such as open-domain question answering (QA) usually consist of two stages: efficient retrieval of relevant documents from a large corpus and detailed reading of the selected documents. This is usually done through two separate models, a retriever that encodes the query and finds nearest neighbors, and a reader based on Transformers. These two components are usually modeled separately, which necessitates a cumbersome implementation and is awkward to optimize in an end-to-end fashion. In this paper, we revisit this design and eschew the separate architecture and training in favor of a single Transformer that performs retrieval as attention (RAA), and end-to-end training solely based on supervision from the end QA task. We demonstrate for the first time that an end-to-end trained single Transformer can achieve both competitive retrieval and QA performance on in-domain datasets, matching or even slightly outperforming state-of-the-art dense retrievers and readers. Moreover, end-to-end adaptation of our model significantly boosts its performance on out-of-domain datasets in both supervised and unsupervised settings, making our model a simple and adaptable end-to-end solution for knowledge-intensive tasks.",
}


@article{santhanam2021colbertv2,
  title={Colbertv2: Effective and efficient retrieval via lightweight late interaction},
  author={Santhanam, Keshav and Khattab, Omar and Saad-Falcon, Jon and Potts, Christopher and Zaharia, Matei},
  journal={arXiv preprint arXiv:2112.01488},
  year={2021}
}

@article{wu2022memorizing,
  title={Memorizing transformers},
  author={Wu, Yuhuai and Rabe, Markus N and Hutchins, DeLesley and Szegedy, Christian},
  journal={arXiv preprint arXiv:2203.08913},
  year={2022}
}

@inproceedings{zhong-etal-2022-training,
    title = "Training Language Models with Memory Augmentation",
    author = "Zhong, Zexuan  and
      Lei, Tao  and
      Chen, Danqi",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.382",
    doi = "10.18653/v1/2022.emnlp-main.382",
    pages = "5657--5673",
    abstract = "Recent work has improved language models (LMs) remarkably by equipping them with a non-parametric memory component. However, most existing approaches only introduce mem-ories at testing time or represent them using a separately trained encoder, resulting in suboptimal training of the language model. In this work, we present TRIME, a novel yet simple training approach designed for training LMs with memory augmentation. Our approach uses a training objective that directly takes in-batch examples as accessible memory. We also present new methods for memory construction and data batching, which are used for adapting to different sets of memories{---}local, long-term, and external memory{---}at testing time. We evaluate TRIME on multiple language modeling and machine translation benchmarks and show that it is able to achieve significant improvements across all the settings. Concretely, TRIME reduces the perplexity from 18.70 to 15.37 on WIKITEXT-103, by effectively leveraging a large memory set from the training corpus. Compared to standard LM training, TRIME adds negligible computational overhead and is compatible with different neural architectures, making it a versatile solution for training memory-augmented LMs.",
}

@inproceedings{bulatov2022recurrent,
 author = {Bulatov, Aydar and Kuratov, Yury and Burtsev, Mikhail},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {11079--11091},
 publisher = {Curran Associates, Inc.},
 title = {Recurrent Memory Transformer},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/47e288629a6996a17ce50b90a056a0e1-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}

@article{bulatov2023scaling,
  title={Scaling Transformer to 1M tokens and beyond with RMT},
  author={Bulatov, Aydar and Kuratov, Yuri and Burtsev, Mikhail S},
  journal={arXiv preprint arXiv:2304.11062},
  year={2023}
}

@inproceedings{wu-etal-2022-memformer,
    title = "Memformer: A Memory-Augmented Transformer for Sequence Modeling",
    author = "Wu, Qingyang  and
      Lan, Zhenzhong  and
      Qian, Kun  and
      Gu, Jing  and
      Geramifard, Alborz  and
      Yu, Zhou",
    editor = "He, Yulan  and
      Ji, Heng  and
      Li, Sujian  and
      Liu, Yang  and
      Chang, Chua-Hui",
    booktitle = "Findings of the Association for Computational Linguistics: AACL-IJCNLP 2022",
    month = nov,
    year = "2022",
    address = "Online only",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-aacl.29",
    pages = "308--318",
    abstract = "Transformers have reached remarkable success in sequence modeling. However, these models have efficiency issues as they need to store all the history token-level representations as memory. We present Memformer, an efficient neural network for sequence modeling, that utilizes an external dynamic memory to encode and retrieve past information. Our model achieves linear time complexity and constant memory space complexity when processing long sequences. We also propose a new optimization scheme, memory replay back-propagation (MRBP), which promotes long-range back-propagation through time with a significantly reduced memory requirement. Experimental results show that Memformer has achieved comparable performance compared against the baselines by using 8.1x less memory space and 3.2x faster on inference. Analysis of the attention pattern shows that our external memory slots can encode and retain important information through timesteps.",
}

@inproceedings{martins-etal-2022-former,
    title = "$\infty$-former: Infinite Memory Transformer",
    author = "Martins, Pedro Henrique  and
      Marinho, Zita  and
      Martins, Andre",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.375",
    doi = "10.18653/v1/2022.acl-long.375",
    pages = "5468--5485",
    abstract = "Transformers are unable to model long-term memories effectively, since the amount of computation they need to perform grows with the context length. While variations of efficient transformers have been proposed, they all have a finite memory capacity and are forced to drop old information. In this paper, we propose the $\infty$-former, which extends the vanilla transformer with an unbounded long-term memory. By making use of a continuous-space attention mechanism to attend over the long-term memory, the $\infty$-former{'}s attention complexity becomes independent of the context length, trading off memory length with precision.In order to control where precision is more important, $\infty$-former maintains {``}sticky memories,{''} being able to model arbitrarily long contexts while keeping the computation budget fixed.Experiments on a synthetic sorting task, language modeling, and document grounded dialogue generation demonstrate the $\infty$-former{'}s ability to retain information from long sequences.",
}

@article{mu2023learning,
  title={Learning to compress prompts with gist tokens},
  author={Mu, Jesse and Li, Xiang Lisa and Goodman, Noah},
  journal={arXiv preprint arXiv:2304.08467},
  year={2023}
}

@article{shi2023context,
  title={In-Context Pretraining: Language Modeling Beyond Document Boundaries},
  author={Shi, Weijia and Min, Sewon and Lomeli, Maria and Zhou, Chunting and Li, Margaret and Lin, Victoria and Smith, Noah A and Zettlemoyer, Luke and Yih, Scott and Lewis, Mike},
  journal={arXiv preprint arXiv:2310.10638},
  year={2023}
}

@article{staniszewski2023structured,
  title={Structured Packing in LLM Training Improves Long Context Utilization},
  author={Staniszewski, Konrad and Tworkowski, Szymon and Jaszczur, Sebastian and Michalewski, Henryk and Kuci{\'n}ski, {\L}ukasz and Mi{\l}o{\'s}, Piotr},
  journal={arXiv preprint arXiv:2312.17296},
  year={2023}
}

@inproceedings{kirillov2023segment,
  title={Segment anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4015--4026},
  year={2023}
}
@inproceedings{gehrmann2021gem,
    title = "The {GEM} Benchmark: Natural Language Generation, its Evaluation and Metrics",
    author = "Gehrmann, Sebastian  and
      Adewumi, Tosin  and
      Aggarwal, Karmanya  and
      Ammanamanchi, Pawan Sasanka  and
      Aremu, Anuoluwapo  and
      Bosselut, Antoine  and
      Chandu, Khyathi Raghavi  and
      Clinciu, Miruna-Adriana  and
      Das, Dipanjan  and
      Dhole, Kaustubh  and
      Du, Wanyu  and
      Durmus, Esin  and
      Du{\v{s}}ek, Ond{\v{r}}ej  and
      Emezue, Chris Chinenye  and
      Gangal, Varun  and
      Garbacea, Cristina  and
      Hashimoto, Tatsunori  and
      Hou, Yufang  and
      Jernite, Yacine  and
      Jhamtani, Harsh  and
      Ji, Yangfeng  and
      Jolly, Shailza  and
      Kale, Mihir  and
      Kumar, Dhruv  and
      Ladhak, Faisal  and
      Madaan, Aman  and
      Maddela, Mounica  and
      Mahajan, Khyati  and
      Mahamood, Saad  and
      Majumder, Bodhisattwa Prasad  and
      Martins, Pedro Henrique  and
      McMillan-Major, Angelina  and
      Mille, Simon  and
      van Miltenburg, Emiel  and
      Nadeem, Moin  and
      Narayan, Shashi  and
      Nikolaev, Vitaly  and
      Niyongabo Rubungo, Andre  and
      Osei, Salomey  and
      Parikh, Ankur  and
      Perez-Beltrachini, Laura  and
      Rao, Niranjan Ramesh  and
      Raunak, Vikas  and
      Rodriguez, Juan Diego  and
      Santhanam, Sashank  and
      Sedoc, Jo{\~a}o  and
      Sellam, Thibault  and
      Shaikh, Samira  and
      Shimorina, Anastasia  and
      Sobrevilla Cabezudo, Marco Antonio  and
      Strobelt, Hendrik  and
      Subramani, Nishant  and
      Xu, Wei  and
      Yang, Diyi  and
      Yerukola, Akhila  and
      Zhou, Jiawei",
    booktitle = "Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021)",
    
    year = "2021",
    
    
    url = "https://aclanthology.org/2021.gem-1.10",
    
    pages = "96--120",
    abstract = "We introduce GEM, a living benchmark for natural language Generation (NLG), its Evaluation, and Metrics. Measuring progress in NLG relies on a constantly evolving ecosystem of automated metrics, datasets, and human evaluation standards. Due to this moving target, new models often still evaluate on divergent anglo-centric corpora with well-established, but flawed, metrics. This disconnect makes it challenging to identify the limitations of current models and opportunities for progress. Addressing this limitation, GEM provides an environment in which models can easily be applied to a wide set of tasks and in which evaluation strategies can be tested. Regular updates to the benchmark will help NLG research become more multilingual and evolve the challenge alongside models. This paper serves as the description of the data for the 2021 shared task at the associated GEM Workshop.",
}

@article{clark2018think,
  title={Think you have solved question answering? {T}ry {ARC}, the {AI2} reasoning challenge},
  author={Clark, Peter and Cowhey, Isaac and Etzioni, Oren and Khot, Tushar and Sabharwal, Ashish and Schoenick, Carissa and Tafjord, Oyvind},
  year={2018},
  journal={arXiv preprint arXiv:1803.05457},
  url={https://arxiv.org/abs/1803.05457}
}

@article{go2009twitter,
  title={Twitter sentiment classification using distant supervision},
  author={Go, Alec and Bhayani, Richa and Huang, Lei},
  journal={CS224N project report, Stanford},
  volume={1},
  number={12},
  pages={2009},
  year={2009},
  url={https://www-cs.stanford.edu/people/alecmgo/papers/TwitterDistantSupervision09.pdf}
}



@inproceedings{rahman-ng-2012-resolving,
    title = "Resolving Complex Cases of Definite Pronouns: The {W}inograd Schema Challenge",
    author = "Rahman, Altaf  and
      Ng, Vincent",
    booktitle = "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning",
    
    year = "2012",
    
    
    url = "https://aclanthology.org/D12-1071",
    pages = "777--789",
}


@inproceedings{orqa,
    title = "Latent Retrieval for Weakly Supervised Open Domain Question Answering",
    author = "Lee, Kenton  and
      Chang, Ming-Wei  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    
    year = "2019",
    
    
    url = "https://aclanthology.org/P19-1612",
    
    pages = "6086--6096",
    abstract = "Recent work on open domain question answering (QA) assumes strong supervision of the supporting evidence and/or assumes a blackbox information retrieval (IR) system to retrieve evidence candidates. We argue that both are suboptimal, since gold evidence is not always available, and QA is fundamentally different from IR. We show for the first time that it is possible to jointly learn the retriever and reader from question-answer string pairs and without any IR system. In this setting, evidence retrieval from all of Wikipedia is treated as a latent variable. Since this is impractical to learn from scratch, we pre-train the retriever with an Inverse Cloze Task. We evaluate on open versions of five QA datasets. On datasets where the questioner already knows the answer, a traditional IR system such as BM25 is sufficient. On datasets where a user is genuinely seeking an answer, we show that learned retrieval is crucial, outperforming BM25 by up to 19 points in exact match.",
}


@inproceedings{dos-santos-gatti-2014-deep,
    title = "Deep Convolutional Neural Networks for Sentiment Analysis of Short Texts",
    author = "dos Santos, C{\'\i}cero  and
      Gatti, Ma{\'\i}ra",
    booktitle = "Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",
    
    year = "2014",
    
    publisher = "Dublin City University and Association for Computational Linguistics",
    url = "https://aclanthology.org/C14-1008",
    pages = "69--78",
}

@misc{yelpdataset,
    author = "Fast.AI",
    title = {{Yelp Sentiment Classification Dataset}},
    note = {\url{https://course.fast.ai/datasets}},
}

@inproceedings{sakaguchi2020winogrande,
  title={Wino{G}rande: An adversarial winograd schema challenge at scale},
  author={Sakaguchi, Keisuke and Le Bras, Ronan and Bhagavatula, Chandra and Choi, Yejin},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  pages={8732--8740},
  year={2020},
  url={https://arxiv.org/abs/1907.10641}
}



@inproceedings{socher-etal-2013-recursive,
    title = "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
    author = "Socher, Richard  and
      Perelygin, Alex  and
      Wu, Jean  and
      Chuang, Jason  and
      Manning, Christopher D.  and
      Ng, Andrew  and
      Potts, Christopher",
    booktitle = "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
    
    year = "2013",
    
    
    url = "https://aclanthology.org/D13-1170",
    pages = "1631--1642",
}

@InProceedings{maas-EtAl:2011:ACL-HLT2011,
  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},
  title     = {Learning Word Vectors for Sentiment Analysis},
  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},
  month     = {June},
  year      = {2011},
  address   = {Portland, Oregon, USA},
  publisher = {Association for Computational Linguistics},
  pages     = {142--150},
  url       = {http://www.aclweb.org/anthology/P11-1015}
}

@inproceedings{zhang-etal-2019-paws,
    title = "{PAWS}: Paraphrase Adversaries from Word Scrambling",
    author = "Zhang, Yuan  and
      Baldridge, Jason  and
      He, Luheng",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    
    year = "2019",
    
    
    url = "https://aclanthology.org/N19-1131",
    
    pages = "1298--1308",
    abstract = "Existing paraphrase identification datasets lack sentence pairs that have high lexical overlap without being paraphrases. Models trained on such data fail to distinguish pairs like flights from New York to Florida and flights from Florida to New York. This paper introduces PAWS (Paraphrase Adversaries from Word Scrambling), a new dataset with 108,463 well-formed paraphrase and non-paraphrase pairs with high lexical overlap. Challenging pairs are generated by controlled word swapping and back translation, followed by fluency and paraphrase judgments by human raters. State-of-the-art models trained on existing datasets have dismal performance on PAWS ({\textless}40{\%} accuracy); however, including PAWS training data for these models improves their accuracy to 85{\%} while maintaining performance on existing tasks. In contrast, models that do not capture non-local contextual information fail even with PAWS training examples. As such, PAWS provides an effective instrument for driving further progress on models that better exploit structure, context, and pairwise comparisons.",
}

@inproceedings{sennrich-etal-2016-edinburgh,
    title = "{E}dinburgh Neural Machine Translation Systems for {WMT} 16",
    author = "Sennrich, Rico  and
      Haddow, Barry  and
      Birch, Alexandra",
    booktitle = "Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",
    
    year = "2016",
    
    
    url = "https://aclanthology.org/W16-2323",
    
    pages = "371--376",
}

@article{rmsnorm,
  author       = {Biao Zhang and
                  Rico Sennrich},
  title        = {Root Mean Square Layer Normalization},
  journal      = {CoRR},
  volume       = {abs/1910.07467},
  year         = {2019},
  url          = {http://arxiv.org/abs/1910.07467},
  eprinttype    = {arXiv},
  eprint       = {1910.07467},
  timestamp    = {Fri, 21 Oct 2022 14:36:42 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1910-07467.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Bucila2006ModelC,
  title={Model compression},
  author={Cristian Bucila and Rich Caruana and Alexandru Niculescu-Mizil},
  booktitle={Knowledge Discovery and Data Mining},
  year={2006},
  url={https://api.semanticscholar.org/CorpusID:11253972}
}

@misc{hinton2015distilling,
      title={Distilling the Knowledge in a Neural Network}, 
      author={Geoffrey Hinton and Oriol Vinyals and Jeff Dean},
      year={2015},
      eprint={1503.02531},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{anil2018large,
      title={Large scale distributed neural network training through online distillation}, 
      author={Rohan Anil and Gabriel Pereyra and Alexandre Passos and Robert Ormandi and George E. Dahl and Geoffrey E. Hinton},
      year={2018},
      eprint={1804.03235},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{beyer2021knowledge,
      title={Knowledge distillation: A good teacher is patient and consistent}, 
      author={Lucas Beyer and Xiaohua Zhai and Amélie Royer and Larisa Markeeva and Rohan Anil and Alexander Kolesnikov},
      year={2021},
      eprint={2106.05237},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{beckerlecun1989,
  title={Improving the convergence of back-propagation learning with second-order methods},
  author={Suzanna Becker and Yann LeCun},
  year={1989},
  url={https://api.semanticscholar.org/CorpusID:59695337}
}

@article{heskes2000,
    author = {Heskes, Tom},
    title = "{On “Natural” Learning and Pruning in Multilayered Perceptrons}",
    journal = {Neural Computation},
    volume = {12},
    number = {4},
    pages = {881-901},
    year = {2000},
    month = {04},
    abstract = "{Several studies have shown that natural gradient descent for on-line learning is much more efficient than standard gradient descent. In this article, we derive natural gradients in a slightly different manner and discuss implications for batch-mode learning and pruning, linking them to existing algorithms such as Levenberg-Marquardt optimization and optimal brain surgeon.The Fisher matrix plays an important role in all these algorithms. The second half of the article discusses a layered approximation of the Fisher matrix specific to multilayered perceptrons. Using this approximation rather than the exact Fisher matrix, we arrive at much faster “natural” learning algorithms and more robust pruning procedures.}",
    issn = {0899-7667},
    doi = {10.1162/089976600300015637},
    url = {https://doi.org/10.1162/089976600300015637},
    eprint = {https://direct.mit.edu/neco/article-pdf/12/4/881/814455/089976600300015637.pdf},
}

@article{duchi2011,
  author  = {John Duchi and Elad Hazan and Yoram Singer},
  title   = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
  journal = {Journal of Machine Learning Research},
  year    = {2011},
  volume  = {12},
  number  = {61},
  pages   = {2121--2159},
  url     = {http://jmlr.org/papers/v12/duchi11a.html}
}

@article{liu-etal-2020-multilingual-denoising,
    title = "Multilingual Denoising Pre-training for Neural Machine Translation",
    author = "Liu, Yinhan  and
      Gu, Jiatao  and
      Goyal, Naman  and
      Li, Xian  and
      Edunov, Sergey  and
      Ghazvininejad, Marjan  and
      Lewis, Mike  and
      Zettlemoyer, Luke",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "8",
    year = "2020",
    url = "https://aclanthology.org/2020.tacl-1.47",
    
    pages = "726--742",
    abstract = "This paper demonstrates that multilingual denoising pre-training produces significant performance gains across a wide variety of machine translation (MT) tasks. We present mBART{---}a sequence-to-sequence denoising auto-encoder pre-trained on large-scale monolingual corpora in many languages using the BART objective (Lewis et al., 2019). mBART is the first method for pre-training a complete sequence-to-sequence model by denoising full texts in multiple languages, whereas previous approaches have focused only on the encoder, decoder, or reconstructing parts of the text. Pre-training a complete model allows it to be directly fine-tuned for supervised (both sentence-level and document-level) and unsupervised machine translation, with no task- specific modifications. We demonstrate that adding mBART initialization produces performance gains in all but the highest-resource settings, including up to 12 BLEU points for low resource MT and over 5 BLEU points for many document-level and unsupervised models. We also show that it enables transfer to language pairs with no bi-text or that were not in the pre-training corpus, and present extensive analysis of which factors contribute the most to effective pre-training.1",
}

@inproceedings{wang2019multi,
  title={Multi-agent dual learning},
  author={Wang, Yiren and Xia, Yingce and He, Tianyu and Tian, Fei and Qin, Tao and Zhai, ChengXiang and Liu, Tie-Yan},
  booktitle={Proceedings of the International Conference on Learning Representations (ICLR) 2019},
  year={2019},
  url={https://openreview.net/forum?id=HyGhN2A5tm}
}

@inproceedings{durrani-etal-2014-edinburghs,
    title = "{E}dinburgh{'}s Phrase-based Machine Translation Systems for {WMT}-14",
    author = "Durrani, Nadir  and
      Haddow, Barry  and
      Koehn, Philipp  and
      Heafield, Kenneth",
    booktitle = "Proceedings of the Ninth Workshop on Statistical Machine Translation",
    
    year = "2014",
    
    
    url = "https://aclanthology.org/W14-3309",
    
    pages = "97--104",
}

@inproceedings{edunov-etal-2018-understanding,
    title = "Understanding Back-Translation at Scale",
    author = "Edunov, Sergey  and
      Ott, Myle  and
      Auli, Michael  and
      Grangier, David",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    
    year = "2018",
    
    
    url = "https://aclanthology.org/D18-1045",
    
    pages = "489--500",
    abstract = "An effective method to improve neural machine translation with monolingual data is to augment the parallel training corpus with back-translations of target language sentences. This work broadens the understanding of back-translation and investigates a number of methods to generate synthetic source sentences. We find that in all but resource poor settings back-translations obtained via sampling or noised beam outputs are most effective. Our analysis shows that sampling or noisy synthetic data gives a much stronger training signal than data generated by beam or greedy search. We also compare how synthetic data compares to genuine bitext and study various domain effects. Finally, we scale to hundreds of millions of monolingual sentences and achieve a new state of the art of 35 BLEU on the WMT{'}14 English-German test set.",
}

@inproceedings{wang-etal-2018-glue,
    title = "{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding",
    author = "Wang, Alex  and
      Singh, Amanpreet  and
      Michael, Julian  and
      Hill, Felix  and
      Levy, Omer  and
      Bowman, Samuel",
    booktitle = "Proceedings of the 2018 {EMNLP} Workshop {B}lackbox{NLP}: Analyzing and Interpreting Neural Networks for {NLP}",
    
    year = "2018",
    
    
    url = "https://aclanthology.org/W18-5446",
    
    pages = "353--355",
    abstract = "Human ability to understand language is \textit{general, flexible, and robust}. In contrast, most NLU models above the word level are designed for a specific task and struggle with out-of-domain data. If we aspire to develop models with understanding beyond the detection of superficial correspondences between inputs and outputs, then it is critical to develop a unified model that can execute a range of linguistic tasks across different domains. To facilitate research in this direction, we present the General Language Understanding Evaluation (GLUE, gluebenchmark.com): a benchmark of nine diverse NLU tasks, an auxiliary dataset for probing models for understanding of specific linguistic phenomena, and an online platform for evaluating and comparing models. For some benchmark tasks, training data is plentiful, but for others it is limited or does not match the genre of the test set. GLUE thus favors models that can represent linguistic knowledge in a way that facilitates sample-efficient learning and effective knowledge-transfer across tasks. While none of the datasets in GLUE were created from scratch for the benchmark, four of them feature privately-held test data, which is used to ensure that the benchmark is used fairly. We evaluate baselines that use ELMo (Peters et al., 2018), a powerful transfer learning technique, as well as state-of-the-art sentence representation models. The best models still achieve fairly low absolute scores. Analysis with our diagnostic dataset yields similarly weak performance over all phenomena tested, with some exceptions.",
}

@article{liu2019roberta,
  title={Ro{BERT}a: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019},
  url={https://openreview.net/forum?id=SyxS0T4tvS}
}

@article{liu2021survey,
  title={Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing},
  author={Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhenbao, and Hayashi, Hiroaki and Neubig, Graham},
  journal={arXiv preprint arXiv:2107.13586},
  year={2021},
  url={https://arxiv.org/abs/2107.13586}
}

@inproceedings{dolan-brockett-2005-automatically,
    title = "Automatically Constructing a Corpus of Sentential Paraphrases",
    author = "Dolan, William B.  and
      Brockett, Chris",
    booktitle = "Proceedings of the Third International Workshop on Paraphrasing ({IWP}2005)",
    year = "2005",
    url = "https://aclanthology.org/I05-5002",
}

@inproceedings{JoshiTriviaQA2017,
    title = "{T}rivia{QA}: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension",
    author = "Joshi, Mandar  and
      Choi, Eunsol  and
      Weld, Daniel  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    
    year = "2017",
    
    
    url = "https://aclanthology.org/P17-1147",
    
    pages = "1601--1611",
    abstract = "We present TriviaQA, a challenging reading comprehension dataset containing over 650K question-answer-evidence triples. TriviaQA includes 95K question-answer pairs authored by trivia enthusiasts and independently gathered evidence documents, six per question on average, that provide high quality distant supervision for answering the questions. We show that, in comparison to other recently introduced large-scale datasets, TriviaQA (1) has relatively complex, compositional questions, (2) has considerable syntactic and lexical variability between questions and corresponding answer-evidence sentences, and (3) requires more cross sentence reasoning to find answers. We also present two baseline algorithms: a feature-based classifier and a state-of-the-art neural network, that performs well on SQuAD reading comprehension. Neither approach comes close to human performance (23{\%} and 40{\%} vs. 80{\%}), suggesting that TriviaQA is a challenging testbed that is worth significant future study.",
}


@article{singh2015jupiter,
  title={Jupiter rising: A decade of clos topologies and centralized control in google's datacenter network},
  author={Singh, Arjun and Ong, Joon and Agarwal, Amit and Anderson, Glen and Armistead, Ashby and Bannon, Roy and Boving, Seb and Desai, Gaurav and Felderman, Bob and Germano, Paulie and others},
  journal={ACM SIGCOMM computer communication review},
  volume={45},
  number={4},
  pages={183--197},
  year={2015},
  publisher={ACM New York, NY, USA}
}

@article{selfconsistency,
  title={Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2022}
}

@article{pi2022reasoning,
  title={Reasoning Like Program Executors},
  author={Pi, Xinyu and Liu, Qian and Chen, Bei and Ziyadi, Morteza and Lin, Zeqi and Gao, Yan and Fu, Qiang and Lou, Jian-Guang and Chen, Weizhu},
  journal={arXiv preprint arXiv:2201.11473},
  year={2022}
}

@inproceedings{piekos-etal-2021-measuring,
    title = "Measuring and Improving {BERT}{'}s Mathematical Abilities by Predicting the Order of Reasoning.",
    author = "Piekos, Piotr  and
      Malinowski, Mateusz  and
      Michalewski, Henryk",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-short.49",
    doi = "10.18653/v1/2021.acl-short.49",
    pages = "383--394",
    abstract = "Imagine you are in a supermarket. You have two bananas in your basket and want to buy four apples. How many fruits do you have in total? This seemingly straightforward question can be challenging for data-driven language models, even if trained at scale. However, we would expect such generic language models to possess some mathematical abilities in addition to typical linguistic competence. Towards this goal, we investigate if a commonly used language model, BERT, possesses such mathematical abilities and, if so, to what degree. For that, we fine-tune BERT on a popular dataset for word math problems, AQuA-RAT, and conduct several tests to understand learned representations better. Since we teach models trained on natural language to do formal mathematics, we hypothesize that such models would benefit from training on semi-formal steps that explain how math results are derived. To better accommodate such training, we also propose new pretext tasks for learning mathematical rules. We call them (Neighbor) Reasoning Order Prediction (ROP or NROP). With this new model, we achieve significantly better outcomes than data-driven baselines and even on-par with more tailored models.",
}

@article{lan2021mwptoolkit,
  title={MWPToolkit: An Open-Source Framework for Deep Learning-Based Math Word Problem Solvers},
  author={Lan, Yihuai and Wang, Lei and Zhang, Qiyuan and Lan, Yunshi and Dai, Bing Tian and Wang, Yan and Zhang, Dongxiang and Lim, Ee-Peng},
  journal={arXiv preprint arXiv:2109.00799},
  year={2021}
}



@article{nye2021show,
  title={Show Your Work: Scratchpads for Intermediate Computation with Language Models},
  author={Nye, Maxwell and Andreassen, Anders Johan and Gur-Ari, Guy and Michalewski, Henryk and Austin, Jacob and Bieber, David and Dohan, David and Lewkowycz, Aitor and Bosma, Maarten and Luan, David and others},
  journal={arXiv preprint arXiv:2112.00114},
  year={2021}
}

@inproceedings{patel-etal-2021-nlp,
    title = "Are {NLP} Models really able to Solve Simple Math Word Problems?",
    author = "Patel, Arkil  and
      Bhattamishra, Satwik  and
      Goyal, Navin",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.168",
    doi = "10.18653/v1/2021.naacl-main.168",
    pages = "2080--2094",
    abstract = "The problem of designing NLP solvers for math word problems (MWP) has seen sustained research activity and steady gains in the test accuracy. Since existing solvers achieve high performance on the benchmark datasets for elementary level MWPs containing one-unknown arithmetic word problems, such problems are often considered {``}solved{''} with the bulk of research attention moving to more complex MWPs. In this paper, we restrict our attention to English MWPs taught in grades four and lower. We provide strong evidence that the existing MWP solvers rely on shallow heuristics to achieve high performance on the benchmark datasets. To this end, we show that MWP solvers that do not have access to the question asked in the MWP can still solve a large fraction of MWPs. Similarly, models that treat MWPs as bag-of-words can also achieve surprisingly high accuracy. Further, we introduce a challenge dataset, SVAMP, created by applying carefully chosen variations over examples sampled from existing datasets. The best accuracy achieved by state-of-the-art models is substantially lower on SVAMP, thus showing that much remains to be done even for the simplest of the MWPs.",
}

@inproceedings{koncel-kedziorski-etal-2016-mawps,
    title = "{MAWPS}: A Math Word Problem Repository",
    author = "Koncel-Kedziorski, Rik  and
      Roy, Subhro  and
      Amini, Aida  and
      Kushman, Nate  and
      Hajishirzi, Hannaneh",
    booktitle = "Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2016",
    address = "San Diego, California",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N16-1136",
    doi = "10.18653/v1/N16-1136",
    pages = "1152--1157",
}

@inproceedings{ling-etal-2017-program,
    title = "Program Induction by Rationale Generation: Learning to Solve and Explain Algebraic Word Problems",
    author = "Ling, Wang  and
      Yogatama, Dani  and
      Dyer, Chris  and
      Blunsom, Phil",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-1015",
    doi = "10.18653/v1/P17-1015",
    pages = "158--167",
    abstract = "Solving algebraic word problems requires executing a series of arithmetic operations{---}a program{---}to obtain a final answer. However, since programs can be arbitrarily complicated, inducing them directly from question-answer pairs is a formidable challenge. To make this task more feasible, we solve these problems by generating answer rationales, sequences of natural language and human-readable mathematical expressions that derive the final answer through a series of small steps. Although rationales do not explicitly specify programs, they provide a scaffolding for their structure via intermediate milestones. To evaluate our approach, we have created a new 100,000-sample dataset of questions, answers and rationales. Experimental results show that indirect supervision of program learning via answer rationales is a promising strategy for inducing arithmetic programs.",
}

@inproceedings{talmor-etal-2019-commonsenseqa,
    title = "{C}ommonsense{QA}: A Question Answering Challenge Targeting Commonsense Knowledge",
    author = "Talmor, Alon  and
      Herzig, Jonathan  and
      Lourie, Nicholas  and
      Berant, Jonathan",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1421",
    doi = "10.18653/v1/N19-1421",
    pages = "4149--4158",
    abstract = "When answering a question, people often draw upon their rich world knowledge in addition to the particular context. Recent work has focused primarily on answering questions given some relevant document or context, and required very little general background. To investigate question answering with prior knowledge, we present CommonsenseQA: a challenging new dataset for commonsense question answering. To capture common sense beyond associations, we extract from ConceptNet (Speer et al., 2017) multiple target concepts that have the same semantic relation to a single source concept. Crowd-workers are asked to author multiple-choice questions that mention the source concept and discriminate in turn between each of the target concepts. This encourages workers to create questions with complex semantics that often require prior knowledge. We create 12,247 questions through this procedure and demonstrate the difficulty of our task with a large number of strong baselines. Our best baseline is based on BERT-large (Devlin et al., 2018) and obtains 56{\%} accuracy, well below human performance, which is 89{\%}.",
}

@article{geva-etal-2021-aristotle,
    title = "Did Aristotle Use a Laptop? A Question Answering Benchmark with Implicit Reasoning Strategies",
    author = "Geva, Mor  and
      Khashabi, Daniel  and
      Segal, Elad  and
      Khot, Tushar  and
      Roth, Dan  and
      Berant, Jonathan",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "9",
    year = "2021",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2021.tacl-1.21",
    doi = "10.1162/tacl_a_00370",
    pages = "346--361",
    abstract = "Abstract A key limitation in current datasets for multi-hop reasoning is that the required steps for answering the question are mentioned in it explicitly. In this work, we introduce StrategyQA, a question answering (QA) benchmark where the required reasoning steps are implicit in the question, and should be inferred using a strategy. A fundamental challenge in this setup is how to elicit such creative questions from crowdsourcing workers, while covering a broad range of potential strategies. We propose a data collection procedure that combines term-based priming to inspire annotators, careful control over the annotator population, and adversarial filtering for eliminating reasoning shortcuts. Moreover, we annotate each question with (1) a decomposition into reasoning steps for answering it, and (2) Wikipedia paragraphs that contain the answers to each step. Overall, StrategyQA includes 2,780 examples, each consisting of a strategy question, its decomposition, and evidence paragraphs. Analysis shows that questions in StrategyQA are short, topic-diverse, and cover a wide range of strategies. Empirically, we show that humans perform well (87{\%}) on this task, while our best baseline reaches an accuracy of ∼ 66{\%}.",
}

@article{du2021glam,
  title={{GLaM}: Efficient Scaling of Language Models with Mixture-of-Experts},
  author={Du, Nan and Huang, Yanping and Dai, Andrew M. and Tong, Simon and Lepikhin, Dmitry and Xu, Yuanzhong and Krikun, Maxim and Zhou, Yanqi and Yu, Adams Wei and Firat, Orhan and others},
  journal={arXiv preprint arXiv:2112.06905},
  year={2021},
  url={https://arxiv.org/pdf/2112.06905}
}

@article{smith2022using,
  title={Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model},
  author={Smith, Shaden and Patwary, Mostofa and Norick, Brandon and LeGresley, Patrick and Rajbhandari, Samyam and Casper, Jared and Liu, Zhun and Prabhumoye, Shrimai and Zerveas, George and Korthikanti, Vijay and others},
  journal={arXiv preprint arXiv:2201.11990},
  year={2022}
}

@inproceedings{clark-etal-2019-boolq,
    title = "{B}ool{Q}: Exploring the Surprising Difficulty of Natural Yes/No Questions",
    author = "Clark, Christopher  and
      Lee, Kenton  and
      Chang, Ming-Wei  and
      Kwiatkowski, Tom  and
      Collins, Michael  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    
    year = "2019",
    
    
    url = "https://aclanthology.org/N19-1300",
    
    pages = "2924--2936",
    abstract = "In this paper we study yes/no questions that are naturally occurring {---} meaning that they are generated in unprompted and unconstrained settings. We build a reading comprehension dataset, BoolQ, of such questions, and show that they are unexpectedly challenging. They often query for complex, non-factoid information, and require difficult entailment-like inference to solve. We also explore the effectiveness of a range of transfer learning baselines. We find that transferring from entailment data is more effective than transferring from paraphrase or extractive QA data, and that it, surprisingly, continues to be very beneficial even when starting from massive pre-trained language models such as BERT. Our best method trains BERT on MultiNLI and then re-trains it on our train set. It achieves 80.4{\%} accuracy compared to 90{\%} accuracy of human annotators (and 62{\%} majority-baseline), leaving a significant gap for future work.",
}

@inproceedings{Dua2019DROP,
    title = "{DROP}: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs",
    author = "Dua, Dheeru  and
      Wang, Yizhong  and
      Dasigi, Pradeep  and
      Stanovsky, Gabriel  and
      Singh, Sameer  and
      Gardner, Matt",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    
    year = "2019",
    
    
    url = "https://aclanthology.org/N19-1246",
    
    pages = "2368--2378",
    abstract = "Reading comprehension has recently seen rapid progress, with systems matching humans on the most popular datasets for the task. However, a large body of work has highlighted the brittleness of these systems, showing that there is much work left to be done. We introduce a new reading comprehension benchmark, DROP, which requires Discrete Reasoning Over the content of Paragraphs. In this crowdsourced, adversarially-created, 55k-question benchmark, a system must resolve references in a question, perhaps to multiple input positions, and perform discrete operations over them (such as addition, counting, or sorting). These operations require a much more comprehensive understanding of the content of paragraphs, as they remove the paraphrase-and-entity-typing shortcuts available in prior datasets. We apply state-of-the-art methods from both the reading comprehension and semantic parsing literatures on this dataset and show that the best systems only achieve 38.4{\%} F1 on our generalized accuracy metric, while expert human performance is 96{\%}. We additionally present a new model that combines reading comprehension methods with simple numerical reasoning to achieve 51{\%} F1.",
}

@inproceedings{rajpurkar-etal-2016-squad,
    title = "{SQ}u{AD}: 100,000+ Questions for Machine Comprehension of Text",
    author = "Rajpurkar, Pranav  and
      Zhang, Jian  and
      Lopyrev, Konstantin  and
      Liang, Percy",
    booktitle = "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
    
    year = "2016",
    
    
    url = "https://aclanthology.org/D16-1264",
    
    pages = "2383--2392",
}

@article{DBLP:journals/corr/abs-1810-12885,
  author    = {Sheng Zhang and
               Xiaodong Liu and
               Jingjing Liu and
               Jianfeng Gao and
               Kevin Duh and
               Benjamin Van Durme},
  title     = {ReCoRD: Bridging the Gap between Human and Machine Commonsense Reading
               Comprehension},
  journal   = {CoRR},
  volume    = {abs/1810.12885},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.12885},
  archivePrefix = {arXiv},
  eprint    = {1810.12885},
  timestamp = {Fri, 04 Sep 2020 16:10:07 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-12885.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{ye2021crossfit,
  title={CrossFit: A Few-shot Learning Challenge for Cross-task Generalization in {NLP}},
  author={Ye, Qinyuan and Lin, Bill Yuchen and Ren, Xiang},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year={2021},
  url={https://arxiv.org/abs/2104.08835},
}

@inproceedings{see-etal-2017-get,
    title = "Get To The Point: Summarization with Pointer-Generator Networks",
    author = "See, Abigail  and
      Liu, Peter J.  and
      Manning, Christopher D.",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    
    year = "2017",
    
    
    url = "https://aclanthology.org/P17-1099",
    
    pages = "1073--1083",
    abstract = "Neural sequence-to-sequence models have provided a viable new approach for abstractive text summarization (meaning they are not restricted to simply selecting and rearranging passages from the original text). However, these models have two shortcomings: they are liable to reproduce factual details inaccurately, and they tend to repeat themselves. In this work we propose a novel architecture that augments the standard sequence-to-sequence attentional model in two orthogonal ways. First, we use a hybrid pointer-generator network that can copy words from the source text via pointing, which aids accurate reproduction of information, while retaining the ability to produce novel words through the generator. Second, we use coverage to keep track of what has been summarized, which discourages repetition. We apply our model to the CNN / Daily Mail summarization task, outperforming the current abstractive state-of-the-art by at least 2 ROUGE points.",
}

@inproceedings{zhang2019slg,
    title = "This Email Could Save Your Life: Introducing the Task of Email Subject Line Generation",
    author = "Zhang, Rui  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    
    year = "2019",
    
    
    url = "https://aclanthology.org/P19-1043",
}

@inproceedings{banon-etal-2020-paracrawl,
    title = "{P}ara{C}rawl: Web-Scale Acquisition of Parallel Corpora",
    author = "Ba{\~n}{\'o}n, Marta  and
      Chen, Pinzhen  and
      Haddow, Barry  and
      Heafield, Kenneth  and
      Hoang, Hieu  and
      Espl{\`a}-Gomis, Miquel  and
      Forcada, Mikel L.  and
      Kamran, Amir  and
      Kirefu, Faheem  and
      Koehn, Philipp  and
      Ortiz Rojas, Sergio  and
      Pla Sempere, Leopoldo  and
      Ram{\'\i}rez-S{\'a}nchez, Gema  and
      Sarr{\'\i}as, Elsa  and
      Strelec, Marek  and
      Thompson, Brian  and
      Waites, William  and
      Wiggins, Dion  and
      Zaragoza, Jaume",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    
    year = "2020",
    
    
    url = "https://aclanthology.org/2020.acl-main.417",
    pages = "4555--4567",
    abstract = "We report on methods to create the largest publicly available parallel corpora by crawling the web, using open source software. We empirically compare alternative methods and publish benchmark data sets for sentence alignment and sentence pair filtering. We also describe the parallel corpora released and evaluate their quality and their usefulness to create machine translation systems.",
}

@inproceedings{tam2021adapet,
  title={Improving and Simplifying Pattern Exploiting Training},
  author={Tam, Derek and Menton Rakesh R. and Bansal, Mohit and Srivastava, Shashank and Raffel, Colin},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year={2021},
  url={https://arxiv.org/pdf/2103.11955},
}

@article{vanschoren2018meta,
  title={Meta-learning: A survey},
  author={Vanschoren, Joaquin},
  year={2018},
  journal={arXiv preprint arXiv:1810.03548},
  url={https://arxiv.org/abs/1810.03548},
}

@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={Proceedings of the International Conference on Machine Learning (ICML)},
  pages={1126--1135},
  year={2017},
  url={https://arxiv.org/abs/1703.03400}
}

@article{patterson2021carbon,
  title={Carbon emissions and large neural network training},
  author={Patterson, David and Gonzalez, Joseph and Le, Quoc and Liang, Chen and Munguia, Lluis-Miquel and Rothchild, Daniel and So, David and Texier, Maud and Dean, Jeff},
  journal={arXiv preprint arXiv:2104.10350},
  year={2021}
}

@article{aghajanyan2021muppet,
  title={Muppet: Massive Multi-task Representations with Pre-Finetuning},
  author={Aghajanyan, Armen and Gupta, Anchit and Shrivastava, Akshat and Chen, Xilun and Zettlemoyer, Luke and Gupta, Sonal},
  year={2021},
  journal={arXiv preprint arXiv:2101.11038},
  url={https://arxiv.org/abs/2101.11038}
}

@inproceedings{axelrod-etal-2011-domain,
    title = "Domain Adaptation via Pseudo In-Domain Data Selection",
    author = "Axelrod, Amittai  and
      He, Xiaodong  and
      Gao, Jianfeng",
    booktitle = "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing",
    
    year = "2011",
    
    
    url = "https://aclanthology.org/D11-1033",
    pages = "355--362",
}

@article{raffel2019exploring,
  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {Journal of {M}achine {L}earning {R}esearch},
  year    = {2020},
  volume  = {21},
  number  = {140},
  pages   = {1-67},
  url     = {http://jmlr.org/papers/v21/20-074.html}
}

@inproceedings{khashabi-etal-2018-looking,
    title = "Looking Beyond the Surface: A Challenge Set for Reading Comprehension over Multiple Sentences",
    author = "Khashabi, Daniel  and
      Chaturvedi, Snigdha  and
      Roth, Michael  and
      Upadhyay, Shyam  and
      Roth, Dan",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    
    year = "2018",
    
    
    url = "https://aclanthology.org/N18-1023",
    pages = "252--262",
    abstract = "We present a reading comprehension challenge in which questions can only be answered by taking into account information from multiple sentences. We solicit and verify questions and answers for this challenge through a 4-step crowdsourcing experiment. Our challenge dataset contains 6,500+ questions for 1000+ paragraphs across 7 different domains (elementary school science, news, travel guides, fiction stories, etc) bringing in linguistic diversity to the texts and to the questions wordings. On a subset of our dataset, we found human solvers to achieve an F1-score of 88.1{\%}. We analyze a range of baselines, including a recent state-of-art reading comprehension system, and demonstrate the difficulty of this challenge, despite a high human performance. The dataset is the first to study multi-sentence inference at scale, with an open-ended set of question types that requires reasoning skills.",
}
    
@inproceedings{levesque2012winograd,
  title={The {W}inograd {S}chema {C}hallenge},
  author={Levesque, Hector and Davis, Ernest and Morgenstern, Leora},
  booktitle={Thirteenth International Conference on the Principles of Knowledge Representation and Reasoning},
  year={2012},
  url={https://dl.acm.org/doi/10.5555/3031843.3031909}
}

@inproceedings{bowman-etal-2015-large,
    title = "A large annotated corpus for learning natural language inference",
    author = "Bowman, Samuel R.  and
      Angeli, Gabor  and
      Potts, Christopher  and
      Manning, Christopher D.",
    booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    
    year = "2015",
    
    
    url = "https://aclanthology.org/D15-1075",
    
    pages = "632--642",
}

@InProceedings{N18-1101,
  author = "Williams, Adina
            and Nangia, Nikita
            and Bowman, Samuel",
  title = "A Broad-Coverage Challenge Corpus for 
           Sentence Understanding through Inference",
  booktitle = "Proceedings of the 2018 Conference of 
               the North American Chapter of the 
               Association for Computational Linguistics:
               Human Language Technologies, Volume 1 (Long
               Papers)",
  year = "2018",
  
  pages = "1112--1122",
  location = "New Orleans, Louisiana",
  url = "http://aclweb.org/anthology/N18-1101"
}

@inproceedings{khashabi-etal-2020-unifiedqa,
    title = "{UNIFIEDQA}: Crossing Format Boundaries with a Single {QA} System",
    author = "Khashabi, Daniel  and
      Min, Sewon  and
      Khot, Tushar  and
      Sabharwal, Ashish  and
      Tafjord, Oyvind  and
      Clark, Peter  and
      Hajishirzi, Hannaneh",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    year = "2020",
    pages = "1896--1907",
    url = "https://aclanthology.org/2020.findings-emnlp.171",
}

@article{min2021metaicl,
  title={MetaICL: Learning to Learn In Context},
  author={Min, Sewon and Lewis, Mike and Zettlemoyer, Luke and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2110.15943},
  year={2021},
  url={https://arxiv.org/abs/2110.15943},
}

@article{sanh2021multitask,
  title={Multitask Prompted Training Enables Zero-Shot Task Generalization},
  author={Sanh, Victor and Webson, Albert and Raffel, Colin and Bach, Stephen H and Sutawika, Lintang and Alyafeai, Zaid and Chaffin, Antoine and Stiegler, Arnaud and Scao, Teven Le and Raja, Arun and others},
  journal={Proceedings of the International Conference on Learning Representations},
  year={2021},
  url={https://arxiv.org/abs/2110.08207}
}
@misc{kalyan2021coffee,
      title={{How Much Coffee Was Consumed During EMNLP 2019? Fermi Problems: A New Reasoning Challenge for AI}}, 
      author={Ashwin Kalyan and Abhinav Kumar and Arjun Chandrasekaran and Ashish Sabharwal and Peter Clark},
      year={2021},
      eprint={2110.14207},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{ouyang2022instructgpt,
  title={Training language models to follow instructions with human feedback},
  author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
  journal={Preprint},
  year={2022},
  url={https://cdn.openai.com/papers/Training_language_models_to_follow_instructions_with_human_feedback.pdf}
}

@article{mccann2018natural,
  title={The natural language decathlon: Multitask learning as question answering},
  author={McCann, Bryan and Keskar, Nitish Shirish and Xiong, Caiming and Socher, Richard},
  year={2018},
  journal={arXiv preprint arXiv:1806.08730},
  url={https://arxiv.org/abs/1806.08730},
}

@misc{zheng2023progressivehint,
      title={Progressive-Hint Prompting Improves Reasoning in Large Language Models}, 
      author={Chuanyang Zheng and Zhengying Liu and Enze Xie and Zhenguo Li and Yu Li},
      year={2023},
      eprint={2304.09797},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{efrat2020turking,
  title={The {T}urking {T}est: Can Language Models Understand Instructions?},
  author={Efrat, Avia and Levy, Omer},
  year={2020},
  journal={arXiv preprint arXiv:2010.11982},
  url={https://arxiv.org/abs/2010.11982},
}

@inproceedings{ye-ren-2021-learning,
    title = "Learning to Generate Task-Specific Adapters from Task Description",
    author = "Ye, Qinyuan  and
      Ren, Xiang",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)",
    
    year = "2021",
    
    
    url = "https://aclanthology.org/2021.acl-short.82",
    pages = "646--653",
    abstract = "Pre-trained text-to-text transformers such as BART have achieved impressive performance across a range of NLP tasks. Recent study further shows that they can learn to generalize to novel tasks, by including task descriptions as part of the source sequence and training the model with (source, target) examples. At test time, these fine-tuned models can make inferences on new tasks using the new task descriptions as part of the input. However, this approach has potential limitations, as the model learns to solve individual (source, target) examples (i.e., at the instance level), instead of learning to solve tasks by taking all examples within a task as a whole (i.e., at the task level). To this end, we introduce Hypter, a framework that improves text-to-text transformer{'}s generalization ability to unseen tasks by training a hypernetwork to generate task-specific, light-weight adapters from task descriptions. Experiments on ZEST dataset and a synthetic SQuAD dataset demonstrate that Hypter improves upon fine-tuning baselines. Notably, when using BART-Large as the main network, Hypter brings 11.3{\%} comparative improvement on ZEST dataset.",
}


@inproceedings{cao-daume-iii-2020-toward,
    title = "Toward Gender-Inclusive Coreference Resolution",
    author = "Cao, Yang Trista  and
      Daum{\'e} III, Hal",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.418",
    doi = "10.18653/v1/2020.acl-main.418",
    pages = "4568--4595",
    abstract = "Correctly resolving textual mentions of people fundamentally entails making inferences about those people. Such inferences raise the risk of systemic biases in coreference resolution systems, including biases that can harm binary and non-binary trans and cis stakeholders. To better understand such biases, we foreground nuanced conceptualizations of gender from sociology and sociolinguistics, and develop two new datasets for interrogating bias in crowd annotations and in existing coreference resolution systems. Through these studies, conducted on English text, we confirm that without acknowledging and building systems that recognize the complexity of gender, we build systems that lead to many potential harms.",
}


@inproceedings{dev-etal-2021-harms,
    title = "Harms of Gender Exclusivity and Challenges in Non-Binary Representation in Language Technologies",
    author = "Dev, Sunipa  and
      Monajatipoor, Masoud  and
      Ovalle, Anaelia  and
      Subramonian, Arjun  and
      Phillips, Jeff  and
      Chang, Kai-Wei",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.150",
    doi = "10.18653/v1/2021.emnlp-main.150",
    pages = "1968--1994",
    abstract = "Gender is widely discussed in the context of language tasks and when examining the stereotypes propagated by language models. However, current discussions primarily treat gender as binary, which can perpetuate harms such as the cyclical erasure of non-binary gender identities. These harms are driven by model and dataset biases, which are consequences of the non-recognition and lack of understanding of non-binary genders in society. In this paper, we explain the complexity of gender and language around it, and survey non-binary persons to understand harms associated with the treatment of gender as binary in English language technologies. We also detail how current language representations (e.g., GloVe, BERT) capture and perpetuate these harms and related challenges that need to be acknowledged and addressed for representations to equitably encode gender information.",
}

@inproceedings{jacobs-2021-measurement,
author = {Jacobs, Abigail Z. and Wallach, Hanna},
title = {Measurement and Fairness},
year = {2021},
isbn = {9781450383097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442188.3445901},
doi = {10.1145/3442188.3445901},
booktitle = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
pages = {375–385},
numpages = {11},
keywords = {construct reliability, construct validity, fairness, measurement},
location = {Virtual Event, Canada},
series = {FAccT '21}
}


@inproceedings{weller-etal-2020-learning,
    title = "Learning from Task Descriptions",
    author = "Weller, Orion  and
      Lourie, Nicholas  and
      Gardner, Matt  and
      Peters, Matthew E.",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    
    year = "2020",
    
    
    url = "https://aclanthology.org/2020.emnlp-main.105",
    
    pages = "1361--1375",
    abstract = "Typically, machine learning systems solve new tasks by training on thousands of examples. In contrast, humans can solve new tasks by reading some instructions, with perhaps an example or two. To take a step toward closing this gap, we introduce a framework for developing NLP systems that solve new tasks after reading their descriptions, synthesizing prior work in this area. We instantiate this frame- work with a new English language dataset, ZEST, structured for task-oriented evaluation on unseen tasks. Formulating task descriptions as questions, we ensure each is general enough to apply to many possible inputs, thus comprehensively evaluating a model{'}s ability to solve each task. Moreover, the dataset{'}s structure tests specific types of systematic generalization. We find that the state-of-the-art T5 model achieves a score of 12{\%} on ZEST, leaving a significant challenge for NLP researchers.",
}

@article{mishra2021natural,
  title={Natural {I}nstructions: Benchmarking generalization to new tasks from natural language instructions},
  author={Mishra, Swaroop and Khashabi, Daniel and Baral, Chitta and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2104.08773},
  year={2021},
  url={https://arxiv.org/abs/2104.08773}
}

@article{pratap2020massively,
  title={Massively multilingual {ASR}: 50 languages, 1 model, 1 billion parameters},
  author={Pratap, Vineel and Sriram, Anuroop and Tomasello, Paden and Hannun, Awni and Liptchinsky, Vitaliy and Synnaeve, Gabriel and Collobert, Ronan},
  journal={arXiv preprint arXiv:2007.03001},
  year={2020},
  url={https://arxiv.org/abs/2007.03001}
}

@article{arivazhagan2019massively,
  title={Massively multilingual neural machine translation in the wild: {F}indings and challenges},
  author={Arivazhagan, Naveen and Bapna, Ankur and Firat, Orhan and Lepikhin, Dmitry and Johnson, Melvin and Krikun, Maxim and Chen, Mia Xu and Cao, Yuan and Foster, George and Cherry, Colin and others},
  journal={arXiv preprint arXiv:1907.05019},
  year={2019},
  url={https://arxiv.org/abs/1907.05019},
}

@inproceedings{
    tanzer2023mtob,
    title={A Benchmark for Learning to Translate a New Language from One Grammar Book},
    author={Garrett Tanzer and Mirac Suzgun and Eline Visser and Dan Jurafsky and Luke Melas-Kyriazi},
    year={2023},
    booktitle={Arxiv},
}

@article{weidinger2024holistic,
  title={Holistic Safety and Responsibility Evaluations of Advanced AI Models},
  author={Weidinger, Laura and Barnhart, Joslyn and Brennan, Jenny and Butterfield, Christina and Young, Susie and Hawkins, Will and Hendricks, Lisa Anne and Comanescu, Ramona and Chang, Oscar and Rodriguez, Mikel and others},
  journal={arXiv preprint arXiv:2404.14068},
  year={2024}
}

@inproceedings{buolamwini2018gender,
  title={Gender shades: Intersectional accuracy disparities in commercial gender classification},
  author={Buolamwini, Joy and Gebru, Timnit},
  booktitle={Conference on fairness, accountability and transparency},
  pages={77--91},
  year={2018},
  organization={PMLR}
}

@article{zhang2022contrastive,
  title={Contrastive adapters for foundation model group robustness},
  author={Zhang, Michael and R{\'e}, Christopher},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={21682--21697},
  year={2022}
}

@inproceedings{de2019commitmentbank,
  title={The {C}ommitment{B}ank: {I}nvestigating projection in naturally occurring discourse},
  author={De Marneffe, Marie-Catherine and Simons, Mandy and Tonhauser, Judith},
  booktitle={Proceedings of Sinn und Bedeutung},
  pages={107--124},
  year={2019},
  url={https://ojs.ub.uni-konstanz.de/sub/index.php/sub/article/view/601}, 
}

@inproceedings{bentivogli2009fifth,
  title={The {F}ifth {PASCAL} {R}ecognizing {T}extual {E}ntailment {C}hallenge.},
  author={Bentivogli, Luisa and Clark, Peter and Dagan, Ido and Giampiccolo, Danilo},
  booktitle={TAC},
  year={2009},
  url={https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.232.1231&rep=rep1&type=pdf}
}

@inproceedings{giampiccolo-etal-2007-third,
    title = "The Third {PASCAL} Recognizing Textual Entailment Challenge",
    author = "Giampiccolo, Danilo  and
      Magnini, Bernardo  and
      Dagan, Ido  and
      Dolan, Bill",
    booktitle = "Proceedings of the {ACL}-{PASCAL} Workshop on Textual Entailment and Paraphrasing",
    
    year = "2007",
    
    
    url = "https://aclanthology.org/W07-1401",
    pages = "1--9",
}

@inproceedings{haim2006second,
  title={The {S}econd {PASCAL} {R}ecognising {T}extual {E}ntailment {C}hallenge},
  author={Haim, R Bar and Dagan, Ido and Dolan, Bill and Ferro, Lisa and Giampiccolo, Danilo and Magnini, Bernardo and Szpektor, Idan},
  booktitle={Proceedings of the Second PASCAL Challenges Workshop on Recognising Textual Entailment},
  year={2006},
  url={http://www.cs.biu.ac.il/~szpekti/papers/RTE2-organizers.pdf}
}

@inproceedings{10.1007/11736790_9,
author = {Dagan, Ido and Glickman, Oren and Magnini, Bernardo},
title = {The {PASCAL} {R}ecognising {T}extual {E}ntailment Challenge},
year = {2005},
url = {https://doi.org/10.1007/11736790_9},

abstract = {This paper describes the PASCAL Network of Excellence first Recognising Textual Entailment
(RTE-1) Challenge benchmark. The RTE task is defined as recognizing, given two text
fragments, whether the meaning of one text can be inferred (entailed) from the other.
This application-independent task is suggested as capturing major inferences about
the variability of semantic expression which are commonly needed across multiple applications.
The Challenge has raised noticeable attention in the research community, attracting
17 submissions from diverse groups, suggesting the generic relevance of the task.},
booktitle = {Proceedings of the First International Conference on Machine Learning Challenges: Evaluating Predictive Uncertainty Visual Object Classification, and Recognizing Textual Entailment},
pages = {177–190},
numpages = {14},
location = {Southampton, UK},
series = {MLCW'05}
}

@article{shazeer2020glu,
  author    = {Noam Shazeer},
  title     = {{GLU} Variants Improve Transformer},
  journal   = {CoRR},
  volume    = {abs/2002.05202},
  year      = {2020},
  url       = {https://arxiv.org/abs/2002.05202},
  eprinttype = {arXiv},
  eprint    = {2002.05202},
  timestamp = {Fri, 14 Feb 2020 12:07:41 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2002-05202.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{vaswani2017,
  author    = {Ashish Vaswani and
               Noam Shazeer and
               Niki Parmar and
               Jakob Uszkoreit and
               Llion Jones and
               Aidan N. Gomez and
               Lukasz Kaiser and
               Illia Polosukhin},
  title     = {Attention Is All You Need},
  journal   = {CoRR},
  volume    = {abs/1706.03762},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.03762},
  eprinttype = {arXiv},
  eprint    = {1706.03762},
  timestamp = {Sat, 23 Jan 2021 01:20:40 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{srivastava-etal-2018-zero,
    title = "Zero-shot Learning of Classifiers from Natural Language Quantification",
    author = "Srivastava, Shashank  and
      Labutov, Igor  and
      Mitchell, Tom",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    
    year = "2018",
    
    
    url = "https://aclanthology.org/P18-1029",
    
    pages = "306--316",
    abstract = "Humans can efficiently learn new concepts using language. We present a framework through which a set of explanations of a concept can be used to learn a classifier without access to any labeled examples. We use semantic parsing to map explanations to probabilistic assertions grounded in latent class labels and observed attributes of unlabeled data, and leverage the differential semantics of linguistic quantifiers (e.g., {`}usually{'} vs {`}always{'}) to drive model training. Experiments on three domains show that the learned classifiers outperform previous approaches for learning with limited data, and are comparable with fully supervised classifiers trained from a small number of labeled examples.",
}

@inproceedings{sambasivan-2021-reimagining,
author = {Sambasivan, Nithya and Arnesen, Erin and Hutchinson, Ben and Doshi, Tulsee and Prabhakaran, Vinodkumar},
title = {Re-Imagining Algorithmic Fairness in {India} and Beyond},
year = {2021},
isbn = {9781450383097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442188.3445896},
doi = {10.1145/3442188.3445896},
booktitle = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
pages = {315–328},
numpages = {14},
keywords = {India, religion, ability, decoloniality, caste, feminism, class, gender, critical algorithmic studies, algorithmic fairness, anti-caste politics},
location = {Virtual Event, Canada},
series = {FAccT '21}
}

@inproceedings{bird-2020-decolonising,
    title = "Decolonising Speech and Language Technology",
    author = "Bird, Steven",
    editor = "Scott, Donia  and
      Bel, Nuria  and
      Zong, Chengqing",
    booktitle = "Proceedings of the 28th International Conference on Computational Linguistics",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2020.coling-main.313",
    doi = "10.18653/v1/2020.coling-main.313",
    pages = "3504--3519",
}

@inproceedings{blodgett-etal-2021-stereotyping,
    title = "Stereotyping {N}orwegian Salmon: An Inventory of Pitfalls in Fairness Benchmark Datasets",
    author = "Blodgett, Su Lin  and
      Lopez, Gilsinia  and
      Olteanu, Alexandra  and
      Sim, Robert  and
      Wallach, Hanna",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.81",
    doi = "10.18653/v1/2021.acl-long.81",
    pages = "1004--1015"
}


@inproceedings{blodgett-etal-2020-language,
    title = "Language (Technology) is Power: A Critical Survey of {``}Bias{''} in {NLP}",
    author = "Blodgett, Su Lin  and
      Barocas, Solon  and
      Daum{\'e} III, Hal  and
      Wallach, Hanna",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.485",
    doi = "10.18653/v1/2020.acl-main.485",
    pages = "5454--5476"
}

@article{sheng-2021-societal,
  author    = {Emily Sheng and
               Kai{-}Wei Chang and
               Premkumar Natarajan and
               Nanyun Peng},
  title     = {Societal Biases in Language Generation: Progress and Challenges},
  journal   = {CoRR},
  volume    = {abs/2105.04054},
  year      = {2021},
  url       = {https://arxiv.org/abs/2105.04054},
  eprinttype = {arXiv},
  eprint    = {2105.04054},
  timestamp = {Fri, 14 May 2021 12:13:30 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2105-04054.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{weidinger-2021-ethical,
  author    = {Laura Weidinger and
               John Mellor and
               Maribeth Rauh and
               Conor Griffin and
               Jonathan Uesato and
               Po{-}Sen Huang and
               Myra Cheng and
               Mia Glaese and
               Borja Balle and
               Atoosa Kasirzadeh and
               Zac Kenton and
               Sasha Brown and
               Will Hawkins and
               Tom Stepleton and
               Courtney Biles and
               Abeba Birhane and
               Julia Haas and
               Laura Rimell and
               Lisa Anne Hendricks and
               William S. Isaac and
               Sean Legassick and
               Geoffrey Irving and
               Iason Gabriel},
  title     = {Ethical and social risks of harm from Language Models},
  journal   = {CoRR},
  volume    = {abs/2112.04359},
  year      = {2021},
  url       = {https://arxiv.org/abs/2112.04359},
  eprinttype = {arXiv},
  eprint    = {2112.04359},
  timestamp = {Mon, 13 Dec 2021 17:51:48 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2112-04359.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2104-08758,
  author    = {Jesse Dodge and
               Maarten Sap and
               Ana Marasovic and
               William Agnew and
               Gabriel Ilharco and
               Dirk Groeneveld and
               Matt Gardner},
  title     = {Documenting the English Colossal Clean Crawled Corpus},
  journal   = {CoRR},
  volume    = {abs/2104.08758},
  year      = {2021},
  url       = {https://arxiv.org/abs/2104.08758},
  eprinttype = {arXiv},
  eprint    = {2104.08758},
  timestamp = {Mon, 26 Apr 2021 17:25:10 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2104-08758.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{dev-2021-bias-measures,
  author    = {Sunipa Dev and
               Emily Sheng and
               Jieyu Zhao and
               Jiao Sun and
               Yu Hou and
               Mattie Sanseverino and
               Jiin Kim and
               Nanyun Peng and
               Kai{-}Wei Chang},
  title     = {What do Bias Measures Measure?},
  journal   = {CoRR},
  volume    = {abs/2108.03362},
  year      = {2021},
  url       = {https://arxiv.org/abs/2108.03362},
  eprinttype = {arXiv},
  eprint    = {2108.03362},
  timestamp = {Wed, 11 Aug 2021 15:24:08 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2108-03362.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{kocijan-etal-2019-surprisingly,
    title = "A Surprisingly Robust Trick for the {W}inograd Schema Challenge",
    author = "Kocijan, Vid  and
      Cretu, Ana-Maria  and
      Camburu, Oana-Maria  and
      Yordanov, Yordan  and
      Lukasiewicz, Thomas",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1478",
    doi = "10.18653/v1/P19-1478",
    pages = "4837--4842"
}


@article{kocijan-2020-winograd,
  author    = {Vid Kocijan and
               Thomas Lukasiewicz and
               Ernest Davis and
               Gary Marcus and
               Leora Morgenstern},
  title     = {A Review of Winograd Schema Challenge Datasets and Approaches},
  journal   = {CoRR},
  volume    = {abs/2004.13831},
  year      = {2020},
  url       = {https://arxiv.org/abs/2004.13831},
  eprinttype = {arXiv},
  eprint    = {2004.13831},
  timestamp = {Sat, 02 May 2020 19:17:26 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2004-13831.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{kumar-etal-2019-zero,
    title = "Zero-shot Word Sense Disambiguation using Sense Definition Embeddings",
    author = "Kumar, Sawan  and
      Jat, Sharmistha  and
      Saxena, Karan  and
      Talukdar, Partha",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    
    year = "2019",
    
    
    url = "https://aclanthology.org/P19-1568",
    
    pages = "5670--5681",
    abstract = "Word Sense Disambiguation (WSD) is a long-standing but open problem in Natural Language Processing (NLP). WSD corpora are typically small in size, owing to an expensive annotation process. Current supervised WSD methods treat senses as discrete labels and also resort to predicting the Most-Frequent-Sense (MFS) for words unseen during training. This leads to poor performance on rare and unseen senses. To overcome this challenge, we propose Extended WSD Incorporating Sense Embeddings (EWISE), a supervised model to perform WSD by predicting over a continuous sense embedding space as opposed to a discrete label space. This allows EWISE to generalize over both seen and unseen senses, thus achieving generalized zero-shot learning. To obtain target sense embeddings, EWISE utilizes sense definitions. EWISE learns a novel sentence encoder for sense definitions by using WordNet relations and also ConvE, a recently proposed knowledge graph embedding method. We also compare EWISE against other sentence encoders pretrained on large corpora to generate definition embeddings. EWISE achieves new state-of-the-art WSD performance.",
}

@inproceedings{liu-etal-2019-reconstructing,
    title = "Reconstructing Capsule Networks for Zero-shot Intent Classification",
    author = "Liu, Han  and
      Zhang, Xiaotong  and
      Fan, Lu  and
      Fu, Xuandi  and
      Li, Qimai  and
      Wu, Xiao-Ming  and
      Lam, Albert Y.S.",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    
    year = "2019",
    
    
    url = "https://aclanthology.org/D19-1486",
    
    pages = "4799--4809",
    abstract = "Intent classification is an important building block of dialogue systems. With the burgeoning of conversational AI, existing systems are not capable of handling numerous fast-emerging intents, which motivates zero-shot intent classification. Nevertheless, research on this problem is still in the incipient stage and few methods are available. A recently proposed zero-shot intent classification method, IntentCapsNet, has been shown to achieve state-of-the-art performance. However, it has two unaddressed limitations: (1) it cannot deal with polysemy when extracting semantic capsules; (2) it hardly recognizes the utterances of unseen intents in the generalized zero-shot intent classification setting. To overcome these limitations, we propose to reconstruct capsule networks for zero-shot intent classification. First, we introduce a dimensional attention mechanism to fight against polysemy. Second, we reconstruct the transformation matrices for unseen intents by utilizing abundant latent information of the labeled utterances, which significantly improves the model generalization ability. Experimental results on two task-oriented dialogue datasets in different languages show that our proposed method outperforms IntentCapsNet and other strong baselines.",
}

@inproceedings{corazza-etal-2020-hybrid,
    title = "Hybrid Emoji-Based Masked Language Models for Zero-Shot Abusive Language Detection",
    author = "Corazza, Michele  and
      Menini, Stefano  and
      Cabrio, Elena  and
      Tonelli, Sara  and
      Villata, Serena",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    
    year = "2020",
    
    
    url = "https://aclanthology.org/2020.findings-emnlp.84",
    
    pages = "943--949",
    abstract = "Recent studies have demonstrated the effectiveness of cross-lingual language model pre-training on different NLP tasks, such as natural language inference and machine translation. In our work, we test this approach on social media data, which are particularly challenging to process within this framework, since the limited length of the textual messages and the irregularity of the language make it harder to learn meaningful encodings. More specifically, we propose a hybrid emoji-based Masked Language Model (MLM) to leverage the common information conveyed by emojis across different languages and improve the learned cross-lingual representation of short text messages, with the goal to perform zero- shot abusive language detection. We compare the results obtained with the original MLM to the ones obtained by our method, showing improved performance on German, Italian and Spanish.",
}

@article{DBLP:journals/corr/abs-2009-11201,
  author    = {Xavier Garcia and
               Aditya Siddhant and
               Orhan Firat and
               Ankur P. Parikh},
  title     = {Harnessing Multilinguality in Unsupervised Machine Translation for
               Rare Languages},
  journal   = {CoRR},
  volume    = {abs/2009.11201},
  year      = {2020},
  url       = {https://arxiv.org/abs/2009.11201},
  eprinttype = {arXiv},
  eprint    = {2009.11201},
  timestamp = {Wed, 30 Sep 2020 16:16:22 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2009-11201.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2201-03110,
  author    = {Aditya Siddhant and
               Ankur Bapna and
               Orhan Firat and
               Yuan Cao and
               Mia Xu Chen and
               Isaac Caswell and
               Xavier Garcia},
  title     = {Towards the Next 1000 Languages in Multilingual Machine Translation:
               Exploring the Synergy Between Supervised and Self-Supervised Learning},
  journal   = {CoRR},
  volume    = {abs/2201.03110},
  year      = {2022},
  url       = {https://arxiv.org/abs/2201.03110},
  eprinttype = {arXiv},
  eprint    = {2201.03110},
  timestamp = {Thu, 20 Jan 2022 14:21:35 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2201-03110.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{dev-2019-measuring,
  author    = {Sunipa Dev and
               Tao Li and
               Jeff M. Phillips and
               Vivek Srikumar},
  title     = {On Measuring and Mitigating Biased Inferences of Word Embeddings},
  journal   = {CoRR},
  volume    = {abs/1908.09369},
  year      = {2019},
  url       = {http://arxiv.org/abs/1908.09369},
  eprinttype = {arXiv},
  eprint    = {1908.09369},
  timestamp = {Tue, 24 Aug 2021 09:55:01 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1908-09369.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{kurita2019quantifying,
place = {Country unknown/Code not available}, title = {Quantifying Social Biases in Contextual Word Representations}, url = {https://par.nsf.gov/biblio/10098355}, abstractNote = {Contextual word embeddings such as BERT have achieved state of the art performance in numerous NLP tasks. Since they are optimized to capture the statistical properties of training data, they tend to pick up on and amplify social stereotypes present in the data as well. In this study, we (1) propose a template-based method to quantify bias in BERT; (2) show that this method obtains more consistent results in capturing social biases than the traditional cosine based method; and (3) conduct a case study, evaluating gender bias in a downstream task of Gender Pronoun Resolution. Although our case study focuses on gender bias, the proposed technique is generalizable to unveiling other biases, including in multiclass settings, such as racial and religious biases.}, journal = {1st ACL Workshop on Gender Bias for Natural Language Processing}, author = {Kurita, Keita and Vyas, Nidhi and Pareek, Ayush and Black, Alan W and Tsvetkov, Yulia}, 
year = 2019}

@inproceedings{pham-etal-2019-improving,
    title = "Improving Zero-shot Translation with Language-Independent Constraints",
    author = "Pham, Ngoc-Quan  and
      Niehues, Jan  and
      Ha, Thanh-Le  and
      Waibel, Alexander",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 1: Research Papers)",
    
    year = "2019",
    
    
    url = "https://aclanthology.org/W19-5202",
    
    pages = "13--23",
    abstract = "An important concern in training multilingual neural machine translation (NMT) is to translate between language pairs unseen during training, i.e zero-shot translation. Improving this ability kills two birds with one stone by providing an alternative to pivot translation which also allows us to better understand how the model captures information between languages. In this work, we carried out an investigation on this capability of the multilingual NMT models. First, we intentionally create an encoder architecture which is independent with respect to the source language. Such experiments shed light on the ability of NMT encoders to learn multilingual representations, in general. Based on such proof of concept, we were able to design regularization methods into the standard Transformer model, so that the whole architecture becomes more robust in zero-shot conditions. We investigated the behaviour of such models on the standard IWSLT 2017 multilingual dataset. We achieved an average improvement of 2.23 BLEU points across 12 language pairs compared to the zero-shot performance of a state-of-the-art multilingual system. Additionally, we carry out further experiments in which the effect is confirmed even for language pairs with multiple intermediate pivots.",
}

@inproceedings{mitchell-2019-model,
author = {Mitchell, Margaret and Wu, Simone and Zaldivar, Andrew and Barnes, Parker and Vasserman, Lucy and Hutchinson, Ben and Spitzer, Elena and Raji, Inioluwa Deborah and Gebru, Timnit},
title = {Model Cards for Model Reporting},
year = {2019},
isbn = {9781450361255},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3287560.3287596},
doi = {10.1145/3287560.3287596},
abstract = {Trained machine learning models are increasingly used to perform high-impact tasks in areas such as law enforcement, medicine, education, and employment. In order to clarify the intended use cases of machine learning models and minimize their usage in contexts for which they are not well suited, we recommend that released models be accompanied by documentation detailing their performance characteristics. In this paper, we propose a framework that we call model cards, to encourage such transparent model reporting. Model cards are short documents accompanying trained machine learning models that provide benchmarked evaluation in a variety of conditions, such as across different cultural, demographic, or phenotypic groups (e.g., race, geographic location, sex, Fitzpatrick skin type [15]) and intersectional groups (e.g., age and race, or sex and Fitzpatrick skin type) that are relevant to the intended application domains. Model cards also disclose the context in which models are intended to be used, details of the performance evaluation procedures, and other relevant information. While we focus primarily on human-centered machine learning models in the application fields of computer vision and natural language processing, this framework can be used to document any trained machine learning model. To solidify the concept, we provide cards for two supervised models: One trained to detect smiling faces in images, and one trained to detect toxic comments in text. We propose model cards as a step towards the responsible democratization of machine learning and related artificial intelligence technology, increasing transparency into how well artificial intelligence technology works. We hope this work encourages those releasing trained machine learning models to accompany model releases with similar detailed evaluation numbers and other relevant documentation.},
booktitle = {Proceedings of the Conference on Fairness, Accountability, and Transparency},
pages = {220–229},
numpages = {10},
keywords = {ML model evaluation, disaggregated evaluation, fairness evaluation, datasheets, ethical considerations, documentation, model cards},
location = {Atlanta, GA, USA},
series = {FAT* '19}
}

@article{malik-2021-socially,
  author    = {Vijit Malik and
               Sunipa Dev and
               Akihiro Nishi and
               Nanyun Peng and
               Kai{-}Wei Chang},
  title     = {Socially Aware Bias Measurements for Hindi Language Representations},
  journal   = {CoRR},
  volume    = {abs/2110.07871},
  year      = {2021},
  url       = {https://arxiv.org/abs/2110.07871},
  eprinttype = {arXiv},
  eprint    = {2110.07871},
  timestamp = {Fri, 22 Oct 2021 13:33:09 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2110-07871.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{lauscher-etal-2020-zero,
    title = "From Zero to Hero: {O}n the Limitations of Zero-Shot Language Transfer with Multilingual {T}ransformers",
    author = "Lauscher, Anne  and
      Ravishankar, Vinit  and
      Vuli{\'c}, Ivan  and
      Glava{\v{s}}, Goran",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    
    year = "2020",
    
    
    url = "https://aclanthology.org/2020.emnlp-main.363",
    
    pages = "4483--4499",
    abstract = "Massively multilingual transformers (MMTs) pretrained via language modeling (e.g., mBERT, XLM-R) have become a default paradigm for zero-shot language transfer in NLP, offering unmatched transfer performance. Current evaluations, however, verify their efficacy in transfers (a) to languages with sufficiently large pretraining corpora, and (b) between close languages. In this work, we analyze the limitations of downstream language transfer with MMTs, showing that, much like cross-lingual word embeddings, they are substantially less effective in resource-lean scenarios and for distant languages. Our experiments, encompassing three lower-level tasks (POS tagging, dependency parsing, NER) and two high-level tasks (NLI, QA), empirically correlate transfer performance with linguistic proximity between source and target languages, but also with the size of target language corpora used in MMT pretraining. Most importantly, we demonstrate that the inexpensive few-shot transfer (i.e., additional fine-tuning on a few target-language instances) is surprisingly effective across the board, warranting more research efforts reaching beyond the limiting zero-shot conditions.",
}

@article{johnson-etal-2017-googles,
    title = "{G}oogle{'}s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation",
    author = "Johnson, Melvin  and
      Schuster, Mike  and
      Le, Quoc V.  and
      Krikun, Maxim  and
      Wu, Yonghui  and
      Chen, Zhifeng  and
      Thorat, Nikhil  and
      Vi{\'e}gas, Fernanda  and
      Wattenberg, Martin  and
      Corrado, Greg  and
      Hughes, Macduff  and
      Dean, Jeffrey",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "5",
    year = "2017",
    url = "https://aclanthology.org/Q17-1024",
    
    pages = "339--351",
    abstract = "We propose a simple solution to use a single Neural Machine Translation (NMT) model to translate between multiple languages. Our solution requires no changes to the model architecture from a standard NMT system but instead introduces an artificial token at the beginning of the input sentence to specify the required target language. Using a shared wordpiece vocabulary, our approach enables Multilingual NMT systems using a single model. On the WMT{'}14 benchmarks, a single multilingual model achieves comparable performance for English→French and surpasses state-of-theart results for English→German. Similarly, a single multilingual model surpasses state-of-the-art results for French→English and German→English on WMT{'}14 and WMT{'}15 benchmarks, respectively. On production corpora, multilingual models of up to twelve language pairs allow for better translation of many individual pairs. Our models can also learn to perform implicit bridging between language pairs never seen explicitly during training, showing that transfer learning and zero-shot translation is possible for neural translation. Finally, we show analyses that hints at a universal interlingua representation in our models and also show some interesting examples when mixing languages.",
}

@inproceedings{NEURIPS2019_c04c19c2,
 author = {Conneau, Alexis and Lample, Guillaume},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 title = {Cross-lingual Language Model Pretraining},
 url = {https://proceedings.neurips.cc/paper/2019/file/c04c19c2c2474dbf5f7ac4372c5b9af1-Paper.pdf},
 volume = {32},
 year = {2019}
}

@article{zhong2021meta,
  title={Meta-tuning Language Models to Answer Prompts Better},
  author={Zhong, Ruiqi and Lee, Kristy and Zhang, Zheng and Klein, Dan},
  journal={arXiv preprint arXiv:2104.04670},
  year={2021},
  url={https://arxiv.org/abs/2104.04670},
}

@article{Worsham2020MultitaskLF,
  title={Multi-task learning for natural language processing in the 2020s: where are we going?},
  author={Joseph Worsham and J. Kalita},
  year={2020},
  journal={arXiv preprint arXiv:2007.16008},
  url={https://arxiv.org/abs/2007.16008}
}

@inproceedings{romera2015embarrassingly,
  title={An embarrassingly simple approach to zero-shot learning},
  author={Romera-Paredes, Bernardino and Torr, Philip},
  booktitle={Proceedings of the International Conference on Machine Learning},
  pages={2152--2161},
  year={2015},
  url={https://proceedings.mlr.press/v37/romera-paredes15.pdf},
}

@inproceedings{yin-etal-2019-benchmarking,
    title = "Benchmarking Zero-shot Text Classification: Datasets, Evaluation and Entailment Approach",
    author = "Yin, Wenpeng  and
      Hay, Jamaal  and
      Roth, Dan",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    
    year = "2019",
    
    
    url = "https://aclanthology.org/D19-1404",
    
    pages = "3914--3923",
    abstract = "Zero-shot text classification (0Shot-TC) is a challenging NLU problem to which little attention has been paid by the research community. 0Shot-TC aims to associate an appropriate label with a piece of text, irrespective of the text domain and the aspect (e.g., topic, emotion, event, etc.) described by the label. And there are only a few articles studying 0Shot-TC, all focusing only on topical categorization which, we argue, is just the tip of the iceberg in 0Shot-TC. In addition, the chaotic experiments in literature make no uniform comparison, which blurs the progress. This work benchmarks the 0Shot-TC problem by providing unified datasets, standardized evaluations, and state-of-the-art baselines. Our contributions include: i) The datasets we provide facilitate studying 0Shot-TC relative to conceptually different and diverse aspects: the {``}topic{''} aspect includes {``}sports{''} and {``}politics{''} as labels; the {``}emotion{''} aspect includes {``}joy{''} and {``}anger{''}; the {``}situation{''} aspect includes {``}medical assistance{''} and {``}water shortage{''}. ii) We extend the existing evaluation setup (label-partially-unseen) {--} given a dataset, train on some labels, test on all labels {--} to include a more challenging yet realistic evaluation label-fully-unseen 0Shot-TC (Chang et al., 2008), aiming at classifying text snippets without seeing task specific training data at all. iii) We unify the 0Shot-TC of diverse aspects within a textual entailment formulation and study it this way.",
}

@inproceedings{lampert2009learning,
  title={Learning to detect unseen object classes by between-class attribute transfer},
  author={Lampert, Christoph H and Nickisch, Hannes and Harmeling, Stefan},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition},
  pages={951--958},
  year={2009},
  organization={IEEE},
  url={https://ieeexplore.ieee.org/document/5206594}
}

@article{caruana1997multitask,
  title={Multitask learning},
  author={Caruana, Rich},
  journal={Machine learning},
  volume={28},
  number={1},
  pages={41--75},
  year={1997},
  publisher={Springer}
}

@article{Bommasani2021OnTO,
  title={On the Opportunities and Risks of Foundation Models},
  author={Rishi Bommasani and Drew A. Hudson and E. Adeli and R. Altman and Simran Arora and Sydney von Arx and Michael S. Bernstein and Jeannette Bohg and Antoine Bosselut and Emma Brunskill and E. Brynjolfsson and S. Buch and D. Card and Rodrigo Castellon and Niladri S. Chatterji and Annie Chen and Kathleen Creel and Jared Quincy Davis and Dora Demszky and Chris Donahue and Moussa Doumbouya and Esin Durmus and S. Ermon and J. Etchemendy and Kawin Ethayarajh and L. Fei-Fei and Chelsea Finn and Trevor Gale and Lauren E. Gillespie and Karan Goel and Noah D. Goodman and S. Grossman and Neel Guha and Tatsunori Hashimoto and Peter Henderson and John Hewitt and Daniel E. Ho and Jenny Hong and Kyle Hsu and Jing Huang and Thomas F. Icard and Saahil Jain and Dan Jurafsky and Pratyusha Kalluri and Siddharth Karamcheti and G. Keeling and Fereshte Khani and O. Khattab and Pang Wei Koh and M. Krass and Ranjay Krishna and Rohith Kuditipudi and Ananya Kumar and Faisal Ladhak and Mina Lee and Tony Lee and J. Leskovec and Isabelle Levent and Xiang Lisa Li and Xuechen Li and Tengyu Ma and Ali Malik and Christopher D. Manning and Suvir P. Mirchandani and Eric Mitchell and Zanele Munyikwa and Suraj Nair and Avanika Narayan and D. Narayanan and Ben Newman and Allen Nie and J. C. Niebles and H. Nilforoshan and Julian Nyarko and Giray Ogut and Laurel Orr and Isabel Papadimitriou and Joon Sung Park and C. Piech and Eva Portelance and Christopher Potts and Aditi Raghunathan and Robert Reich and Hongyu Ren and Frieda Rong and Yusuf H. Roohani and Camilo Ruiz and Jack Ryan and Christopher R'e and D. Sadigh and Shiori Sagawa and Keshav Santhanam and Andy Shih and K. Srinivasan and Alex Tamkin and Rohan Taori and Armin W. Thomas and Florian Tram{\`e}r and Rose E. Wang and William Wang and Bohan Wu and Jiajun Wu and Yuhuai Wu and Sang Michael Xie and Michihiro Yasunaga and Jiaxuan You and M. Zaharia and Michael Zhang and Tianyi Zhang and Xikun Zhang and Yuhui Zhang and Lucia Zheng and Kaitlyn Zhou and Percy Liang},
  year={2021},
  journal={arXiv preprint arXiv:2108.07258},
  url={https://arxiv.org/abs/2108.07258},
}

@article{Austin2021ProgramSW,
  title={Program Synthesis with Large Language Models},
  author={Jacob Austin and Augustus Odena and Maxwell Nye and Maarten Bosma and Henryk Michalewski and David Dohan and Ellen Jiang and Carrie Cai and Michael Terry and Quoc Le and Charles Sutton},
  year={2021},
  journal={arXiv preprint arXiv:2108.07732},
  url={https://arxiv.org/abs/2108.07732},
}

@inproceedings{bender-2021-dangers,
author = {Bender, Emily M. and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
title = {On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?},
year = {2021},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3442188.3445922},

abstract = {The past 3 years of work in NLP have been characterized by the development and deployment
of ever larger language models, especially for English. BERT, its variants, GPT-2/3,
and others, most recently Switch-C, have pushed the boundaries of the possible both
through architectural innovations and through sheer size. Using these pretrained models
and the methodology of fine-tuning them for specific tasks, researchers have extended
the state of the art on a wide array of tasks as measured by leaderboards on specific
benchmarks for English. In this paper, we take a step back and ask: How big is too
big? What are the possible risks associated with this technology and what paths are
available for mitigating those risks? We provide recommendations including weighing
the environmental and financial costs first, investing resources into curating and
carefully documenting datasets rather than ingesting everything on the web, carrying
out pre-development exercises evaluating how the planned approach fits into research
and development goals and supports stakeholder values, and encouraging research directions
beyond ever larger language models.},
booktitle = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
pages = {610–623},
numpages = {14},
location = {Virtual Event, Canada},
series = {FAccT '21}
}

@inproceedings{bender-koller-2020-climbing,
    title = "Climbing towards {NLU}: {On} Meaning, Form, and Understanding in the Age of Data",
    author = "Bender, Emily M.  and
      Koller, Alexander",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    
    year = "2020",
    
    
    url = "https://aclanthology.org/2020.acl-main.463",
    
    pages = "5185--5198",
    abstract = "The success of the large neural language models on many NLP tasks is exciting. However, we find that these successes sometimes lead to hype in which these models are being described as {``}understanding{''} language or capturing {``}meaning{''}. In this position paper, we argue that a system trained only on form has a priori no way to learn meaning. In keeping with the ACL 2020 theme of {``}Taking Stock of Where We{'}ve Been and Where We{'}re Going{''}, we argue that a clear understanding of the distinction between form and meaning will help guide the field towards better science around natural language understanding.",
}

@inproceedings{qin-eisner-2021,
  aclid =       {2021.naacl-main.410},
  author =      {Guanghui Qin and Jason Eisner},
  title =       {Learning How To Ask: Querying {LM}s with Mixtures of
                 Soft Prompts},
  booktitle =   {Proceedings of the 2021 Conference of the North
                 American Chapter of the Association for Computational
                 Linguistics: Human Language Technologies (NAACL-HLT)},
  pages =       {5203--5212},
  year =        {2021},
  
  
  url =         {http://cs.jhu.edu/~jason/papers/#qin-eisner-2021}
}


@inproceedings{li-liang-2021-prefix,
    title = "Prefix-Tuning: Optimizing Continuous Prompts for Generation",
    author = "Li, Xiang Lisa  and
      Liang, Percy",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    
    year = "2021",
    
    
    url = "https://aclanthology.org/2021.acl-long.353",
    
    pages = "4582--4597",
    abstract = "Fine-tuning is the de facto way of leveraging large pretrained language models for downstream tasks. However, fine-tuning modifies all the language model parameters and therefore necessitates storing a full copy for each task. In this paper, we propose prefix-tuning, a lightweight alternative to fine-tuning for natural language generation tasks, which keeps language model parameters frozen and instead optimizes a sequence of continuous task-specific vectors, which we call the prefix. Prefix-tuning draws inspiration from prompting for language models, allowing subsequent tokens to attend to this prefix as if it were {``}virtual tokens{''}. We apply prefix-tuning to GPT-2 for table-to-text generation and to BART for summarization. We show that by learning only 0.1{\%} of the parameters, prefix-tuning obtains comparable performance in the full data setting, outperforms fine-tuning in low-data settings, and extrapolates better to examples with topics that are unseen during training.",
}

@inproceedings{lester-prompt-tuning,
  author    = {Brian Lester and
               Rami Al{-}Rfou and
               Noah Constant},
  title     = {The Power of Scale for Parameter-Efficient Prompt Tuning},
    booktitle = "Proceedings of the Conference on Empirical Methods in Natural Language Processing",
    year = {2021},
  url = {https://arxiv.org/abs/2104.08691},
}

@article{solaiman2021process,
  title={Process for Adapting Language Models to Society (PALMS) with Values-Targeted Datasets},
  author={Solaiman, Irene and Dennison, Christy},
  journal={arXiv preprint arXiv:2106.10328},
  year={2021},
  url={https://arxiv.org/abs/2106.10328},
}

@inproceedings{rasley2020deepspeed,
  title={Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters},
  author={Rasley, Jeff and Rajbhandari, Samyam and Ruwase, Olatunji and He, Yuxiong},
  booktitle={Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={3505--3506},
  year={2020}
}

@article{zaheer2020big,
  title={Big bird: Transformers for longer sequences},
  author={Zaheer, Manzil and Guruganesh, Guru and Dubey, Kumar Avinava and Ainslie, Joshua and Alberti, Chris and Ontanon, Santiago and Pham, Philip and Ravula, Anirudh and Wang, Qifan and Yang, Li and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={17283--17297},
  year={2020}
}

@InProceedings{pmlr-v119-guu20a,
  title = 	 {Retrieval Augmented Language Model Pre-Training},
  author =       {Guu, Kelvin and Lee, Kenton and Tung, Zora and Pasupat, Panupong and Chang, Mingwei},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {3929--3938},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/guu20a/guu20a.pdf},
  url = 	 {https://proceedings.mlr.press/v119/guu20a.html},
  abstract = 	 {Language model pre-training has been shown to capture a surprising amount of world knowledge, crucial for NLP tasks such as question answering. However, this knowledge is stored implicitly in the parameters of a neural network, requiring ever-larger networks to cover more facts. To capture knowledge in a more modular and interpretable way, we augment language model pre-training with a latent knowledge retriever, which allows the model to retrieve and attend over documents from a large corpus such as Wikipedia, used during pre-training, fine-tuning and inference. For the first time, we show how to pre-train such a knowledge retriever in an unsupervised manner, using masked language modeling as the learning signal and backpropagating through a retrieval step that considers millions of documents. We demonstrate the effectiveness of Retrieval-Augmented Language Model pre-training (REALM) by fine-tuning on the challenging task of Open-domain Question Answering (Open-QA). We compare against state-of-the-art models for both explicit and implicit knowledge storage on three popular Open-QA benchmarks, and find that we outperform all previous methods by a significant margin (4-16% absolute accuracy), while also providing qualitative benefits such as interpretability and modularity.}
}

@article{mathqa2019,
  author    = {Aida Amini and
               Saadia Gabriel and
               Shanchuan Lin and
               Rik Koncel{-}Kedziorski and
               Yejin Choi and
               Hannaneh Hajishirzi},
  title     = {MathQA: Towards Interpretable Math Word Problem Solving with Operation-Based
               Formalisms},
  journal   = {CoRR},
  volume    = {abs/1905.13319},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.13319},
  eprinttype = {arXiv},
  eprint    = {1905.13319},
  timestamp = {Sat, 23 Jan 2021 01:19:32 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1905-13319.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{transcoder2020,
  author    = {Marie{-}Anne Lachaux and
               Baptiste Rozi{\`{e}}re and
               Lowik Chanussot and
               Guillaume Lample},
  title     = {Unsupervised Translation of Programming Languages},
  journal   = {CoRR},
  volume    = {abs/2006.03511},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.03511},
  eprinttype = {arXiv},
  eprint    = {2006.03511},
  timestamp = {Tue, 09 Jun 2020 16:38:02 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2006-03511.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{rajbhandari2021zero,
  title={Zero-infinity: Breaking the gpu memory wall for extreme scale deep learning},
  author={Rajbhandari, Samyam and Ruwase, Olatunji and Rasley, Jeff and Smith, Shaden and He, Yuxiong},
  booktitle={Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={1--14},
  year={2021}
}

@inproceedings{narayanan2021memory,
  title={Memory-efficient pipeline-parallel dnn training},
  author={Narayanan, Deepak and Phanishayee, Amar and Shi, Kaiyu and Chen, Xie and Zaharia, Matei},
  booktitle={International Conference on Machine Learning},
  pages={7937--7947},
  year={2021},
  organization={PMLR}
}

@inproceedings{ren2021zero,
  title={$\{$ZeRO-Offload$\}$: Democratizing $\{$Billion-Scale$\}$ Model Training},
  author={Ren, Jie and Rajbhandari, Samyam and Aminabadi, Reza Yazdani and Ruwase, Olatunji and Yang, Shuangyan and Zhang, Minjia and Li, Dong and He, Yuxiong},
  booktitle={2021 USENIX Annual Technical Conference (USENIX ATC 21)},
  pages={551--564},
  year={2021}
}

@article{li2020pytorch,
  title={Pytorch distributed: Experiences on accelerating data parallel training},
  author={Li, Shen and Zhao, Yanli and Varma, Rohan and Salpekar, Omkar and Noordhuis, Pieter and Li, Teng and Paszke, Adam and Smith, Jeff and Vaughan, Brian and Damania, Pritam and others},
  journal={arXiv preprint arXiv:2006.15704},
  year={2020}
}

@inproceedings{rajbhandari2020zero,
  title={Zero: Memory optimizations toward training trillion parameter models},
  author={Rajbhandari, Samyam and Rasley, Jeff and Ruwase, Olatunji and He, Yuxiong},
  booktitle={SC20: International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={1--16},
  year={2020},
  organization={IEEE}
}


@article{wu2021recursively,
  title={Recursively Summarizing Books with Human Feedback},
  author={Wu, Jeff and Ouyang, Long and Ziegler, Daniel M and Stiennon, Nissan and Lowe, Ryan and Leike, Jan and Christiano, Paul},
  journal={arXiv preprint arXiv:2109.10862},
  year={2021},
  url = {https://arxiv.org/abs/2109.10862},
}

@inproceedings{lepikhin2020gshard,
  title={{GShard}: Scaling Giant Models with Conditional Computation and Automatic Sharding},
  author={Lepikhin, Dmitry and Lee, HyoukJoong and Xu, Yuanzhong and Chen, Dehao and Firat, Orhan and Huang, Yanping and Krikun, Maxim and Shazeer, Noam and Chen, Zhifeng},
  booktitle={International Conference on Learning Representations},
  year={2020},
  url={https://openreview.net/forum?id=qrwe7XHTmYb}
}

@article{fedus2021switch,
  title={Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity},
  author={Fedus, William and Zoph, Barret and Shazeer, Noam},
  journal={arXiv preprint arXiv:2101.03961},
  year={2021},
  url={https://arxiv.org/abs/2101.03961}
}

@proceedings{wmt16,
    title = "Proceedings of the First Conference on Machine Translation: Volume 1, Research Papers",
    editor = {Bojar, Ond{\v{r}}ej  and
      Buck, Christian  and
      Chatterjee, Rajen  and
      Federmann, Christian  and
      Guillou, Liane  and
      Haddow, Barry  and
      Huck, Matthias  and
      Yepes, Antonio Jimeno  and
      N{\'e}v{\'e}ol, Aur{\'e}lie  and
      Neves, Mariana  and
      Pecina, Pavel  and
      Popel, Martin  and
      Koehn, Philipp  and
      Monz, Christof  and
      Negri, Matteo  and
      Post, Matt  and
      Specia, Lucia  and
      Verspoor, Karin  and
      Tiedemann, J{\"o}rg  and
      Turchi, Marco},
    
    year = "2016",
    
    
    url = "https://aclanthology.org/W16-2200",
    
}

@inproceedings{wmt22,
    title = "Findings of the 2022 Conference on Machine Translation ({WMT}22)",
    author = "Kocmi, Tom  and
      Bawden, Rachel  and
      Bojar, Ond{\v{r}}ej  and
      Dvorkovich, Anton  and
      Federmann, Christian  and
      Fishel, Mark  and
      Gowda, Thamme  and
      Graham, Yvette  and
      Grundkiewicz, Roman  and
      Haddow, Barry  and
      Knowles, Rebecca  and
      Koehn, Philipp  and
      Monz, Christof  and
      Morishita, Makoto  and
      Nagata, Masaaki  and
      Nakazawa, Toshiaki  and
      Nov{\'a}k, Michal  and
      Popel, Martin  and
      Popovi{\'c}, Maja",
    booktitle = "Proceedings of the Seventh Conference on Machine Translation (WMT)",
    month = dec,
    year = "2022",
    url = "https://aclanthology.org/2022.wmt-1.1",

}
@proceedings{wmt14,
    title = "Proceedings of the Ninth Workshop on Statistical Machine Translation",
    editor = "Bojar, Ond{\v{r}}ej  and
      Buck, Christian  and
      Federmann, Christian  and
      Haddow, Barry  and
      Koehn, Philipp  and
      Monz, Christof  and
      Post, Matt  and
      Specia, Lucia",
    
    year = "2014",
    
    
    url = "https://aclanthology.org/W14-3300",
    
}

@inproceedings{schick-schutze-2021-exploiting,
    title = "Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Language Inference",
    author = {Schick, Timo  and
      Sch{\"u}tze, Hinrich},
    booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
    
    year = "2021",
    
    
    url = "https://aclanthology.org/2021.eacl-main.20",
    pages = "255--269",
    abstract = "Some NLP tasks can be solved in a fully unsupervised fashion by providing a pretrained language model with {``}task descriptions{''} in natural language (e.g., Radford et al., 2019). While this approach underperforms its supervised counterpart, we show in this work that the two ideas can be combined: We introduce Pattern-Exploiting Training (PET), a semi-supervised training procedure that reformulates input examples as cloze-style phrases to help language models understand a given task. These phrases are then used to assign soft labels to a large set of unlabeled examples. Finally, standard supervised training is performed on the resulting training set. For several tasks and languages, PET outperforms supervised training and strong semi-supervised approaches in low-resource settings by a large margin.",
}

@inproceedings{fabbri-etal-2019-multi,
    title = "Multi-News: A Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model",
    author = "Fabbri, Alexander  and
      Li, Irene  and
      She, Tianwei  and
      Li, Suyi  and
      Radev, Dragomir",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    
    year = "2019",
    
    
    url = "https://aclanthology.org/P19-1102",
    
    pages = "1074--1084",
    abstract = "Automatic generation of summaries from multiple news articles is a valuable tool as the number of online publications grows rapidly. Single document summarization (SDS) systems have benefited from advances in neural encoder-decoder model thanks to the availability of large datasets. However, multi-document summarization (MDS) of news articles has been limited to datasets of a couple of hundred examples. In this paper, we introduce Multi-News, the first large-scale MDS news dataset. Additionally, we propose an end-to-end model which incorporates a traditional extractive summarization model with a standard SDS model and achieves competitive results on MDS datasets. We benchmark several methods on Multi-News and hope that this work will promote advances in summarization in the multi-document setting.",
}

@inproceedings{NIPS2015_250cf8b5,
 author = {Zhang, Xiang and Zhao, Junbo and LeCun, Yann},
 booktitle = {NIPS},
 title = {Character-level Convolutional Networks for Text Classification},
 url = {https://proceedings.neurips.cc/paper/2015/file/250cf8b51c773f3f8dc8b4be867a9a02-Paper.pdf},
 year = {2015}
}

@inproceedings{li-roth-2002-learning,
    title = "Learning Question Classifiers",
    author = "Li, Xin  and
      Roth, Dan",
    booktitle = "{COLING} 2002: The 19th International Conference on Computational Linguistics",
    year = "2002",
    url = "https://www.aclweb.org/anthology/C02-1150",
}

@article{jouppi2020domain,
  title={A domain-specific supercomputer for training deep neural networks},
  author={Jouppi, Norman P and Yoon, Doe Hyun and Kurian, George and Li, Sheng and Patil, Nishant and Laudon, James and Young, Cliff and Patterson, David},
  journal={Communications of the ACM},
  volume={63},
  number={7},
  pages={67--78},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{warstadt2018neural,
    title = "Neural Network Acceptability Judgments",
    author = "Warstadt, Alex  and
      Singh, Amanpreet  and
      Bowman, Samuel R.",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "7",
    
    year = "2019",
    url = "https://aclanthology.org/Q19-1040",
    doi = "10.1162/tacl_a_00290",
    pages = "625--641",
    abstract = "This paper investigates the ability of artificial neural networks to judge the grammatical acceptability of a sentence, with the goal of testing their linguistic competence. We introduce the Corpus of Linguistic Acceptability (CoLA), a set of 10,657 English sentences labeled as grammatical or ungrammatical from published linguistics literature. As baselines, we train several recurrent neural network models on acceptability classification, and find that our models outperform unsupervised models by Lau et al. (2016) on CoLA. Error-analysis on specific grammatical phenomena reveals that both Lau et al.{'}s models and ours learn systematic generalizations like subject-verb-object order. However, all models we test perform far below human level on a wide range of grammatical constructions.",
}

@article{saxton2019analysing,
  title={Analysing mathematical reasoning abilities of neural models},
  author={Saxton, David and Grefenstette, Edward and Hill, Felix and Kohli, Pushmeet},
  journal={Proceedings of the International Conference on Learning Representations},
  year={2019},
  url={https://arxiv.org/pdf/1904.01557}
}

@inproceedings{hovy-etal-2001-toward,
    title = "Toward Semantics-Based Answer Pinpointing",
    author = "Hovy, Eduard  and
      Gerber, Laurie  and
      Hermjakob, Ulf  and
      Lin, Chin-Yew  and
      Ravichandran, Deepak",
    booktitle = "Proceedings of the First International Conference on Human Language Technology Research",
    year = "2001",
    url = "https://www.aclweb.org/anthology/H01-1069",
}

@inproceedings{pilehvar-camacho-collados-2019-wic,
    title = "{W}i{C}: the Word-in-Context Dataset for Evaluating Context-Sensitive Meaning Representations",
    author = "Pilehvar, Mohammad Taher  and
      Camacho-Collados, Jose",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    
    year = "2019",
    
    
    url = "https://aclanthology.org/N19-1128",
    
    pages = "1267--1273",
    abstract = "By design, word embeddings are unable to model the dynamic nature of words{'} semantics, i.e., the property of words to correspond to potentially different meanings. To address this limitation, dozens of specialized meaning representation techniques such as sense or contextualized embeddings have been proposed. However, despite the popularity of research on this topic, very few evaluation benchmarks exist that specifically focus on the dynamic semantics of words. In this paper we show that existing models have surpassed the performance ceiling of the standard evaluation dataset for the purpose, i.e., Stanford Contextual Word Similarity, and highlight its shortcomings. To address the lack of a suitable benchmark, we put forward a large-scale Word in Context dataset, called WiC, based on annotations curated by experts, for generic evaluation of context-sensitive representations. WiC is released in https://pilehvar.github.io/wic/.",
}

@inproceedings{choi-etal-2018-quac,
    title = "{Q}u{AC}: Question Answering in Context",
    author = "Choi, Eunsol  and
      He, He  and
      Iyyer, Mohit  and
      Yatskar, Mark  and
      Yih, Wen-tau  and
      Choi, Yejin  and
      Liang, Percy  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    
    year = "2018",
    
    
    url = "https://aclanthology.org/D18-1241",
    
    pages = "2174--2184",
    abstract = "We present QuAC, a dataset for Question Answering in Context that contains 14K information-seeking QA dialogs (100K questions in total). The dialogs involve two crowd workers: (1) a student who poses a sequence of freeform questions to learn as much as possible about a hidden Wikipedia text, and (2) a teacher who answers the questions by providing short excerpts from the text. QuAC introduces challenges not found in existing machine comprehension datasets: its questions are often more open-ended, unanswerable, or only meaningful within the dialog context, as we show in a detailed qualitative evaluation. We also report results for a number of reference models, including a recently state-of-the-art reading comprehension architecture extended to model dialog context. Our best model underperforms humans by 20 F1, suggesting that there is significant room for future work on this data. Dataset, baseline, and leaderboard available at \url{http://quac.ai}.",
}

@article{reddy-etal-2019-coqa,
    title = "{C}o{QA}: A Conversational Question Answering Challenge",
    author = "Reddy, Siva  and
      Chen, Danqi  and
      Manning, Christopher D.",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "7",
    
    year = "2019",
    url = "https://aclanthology.org/Q19-1016",
    
    pages = "249--266",
    abstract = "Humans gather information through conversations involving a series of interconnected questions and answers. For machines to assist in information gathering, it is therefore essential to enable them to answer conversational questions. We introduce CoQA, a novel dataset for building Conversational Question Answering systems. Our dataset contains 127k questions with answers, obtained from 8k conversations about text passages from seven diverse domains. The questions are conversational, and the answers are free-form text with their corresponding evidence highlighted in the passage. We analyze CoQA in depth and show that conversational questions have challenging phenomena not present in existing reading comprehension datasets (e.g., coreference and pragmatic reasoning). We evaluate strong dialogue and reading comprehension models on CoQA. The best system obtains an F1 score of 65.4{\%}, which is 23.4 points behind human performance (88.8{\%}), indicating that there is ample room for improvement. We present CoQA as a challenge to the community at https://stanfordnlp.github.io/coqa.",
}

@inproceedings{ladhak-etal-2020-wikilingua,
    title = "{W}iki{L}ingua: A New Benchmark Dataset for Cross-Lingual Abstractive Summarization",
    author = "Ladhak, Faisal  and
      Durmus, Esin  and
      Cardie, Claire  and
      McKeown, Kathleen",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    
    year = "2020",
    
    
    url = "https://aclanthology.org/2020.findings-emnlp.360",
    
    pages = "4034--4048",
    abstract = "We introduce WikiLingua, a large-scale, multilingual dataset for the evaluation of cross-lingual abstractive summarization systems. We extract article and summary pairs in 18 languages from WikiHow, a high quality, collaborative resource of how-to guides on a diverse set of topics written by human authors. We create gold-standard article-summary alignments across languages by aligning the images that are used to describe each how-to step in an article. As a set of baselines for further studies, we evaluate the performance of existing cross-lingual abstractive summarization methods on our dataset. We further propose a method for direct cross-lingual summarization (i.e., without requiring translation at inference time) by leveraging synthetic data and Neural Machine Translation as a pre-training step. Our method significantly outperforms the baseline approaches, while being more cost efficient during inference.",
}

@inproceedings{wang-ling-2016-neural,
    title = "Neural Network-Based Abstract Generation for Opinions and Arguments",
    author = "Wang, Lu  and
      Ling, Wang",
    booktitle = "Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    
    year = "2016",
    
    
    url = "https://www.aclweb.org/anthology/N16-1007",
    
    pages = "47--57",
}

@inproceedings{gliwa-etal-2019-samsum,
    title = "{SAMS}um Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization",
    author = "Gliwa, Bogdan  and
      Mochol, Iwona  and
      Biesek, Maciej  and
      Wawer, Aleksander",
    booktitle = "Proceedings of the 2nd Workshop on New Frontiers in Summarization",
    
    year = "2019",
    
    
    url = "https://aclanthology.org/D19-5409",
    
    pages = "70--79",
    abstract = "This paper introduces the SAMSum Corpus, a new dataset with abstractive dialogue summaries. We investigate the challenges it poses for automated summarization by testing several models and comparing their results with those obtained on a corpus of news articles. We show that model-generated summaries of dialogues achieve higher ROUGE scores than the model-generated summaries of news {--} in contrast with human evaluators{'} judgement. This suggests that a challenging task of abstractive dialogue summarization requires dedicated models and non-standard quality measures. To our knowledge, our study is the first attempt to introduce a high-quality chat-dialogues corpus, manually annotated with abstractive summarizations, which can be used by the research community for further studies.",
}

@inproceedings{grusky-etal-2018-newsroom,
    title = "{N}ewsroom: A Dataset of 1.3 Million Summaries with Diverse Extractive Strategies",
    author = "Grusky, Max  and
      Naaman, Mor  and
      Artzi, Yoav",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    
    year = "2018",
    
    
    url = "https://aclanthology.org/N18-1065",
    
    pages = "708--719",
    abstract = "We present NEWSROOM, a summarization dataset of 1.3 million articles and summaries written by authors and editors in newsrooms of 38 major news publications. Extracted from search and social media metadata between 1998 and 2017, these high-quality summaries demonstrate high diversity of summarization styles. In particular, the summaries combine abstractive and extractive strategies, borrowing words and phrases from articles at varying rates. We analyze the extraction strategies used in NEWSROOM summaries against other datasets to quantify the diversity and difficulty of our new data, and train existing methods on the data to evaluate its utility and challenges. The dataset is available online at summari.es.",
}

@inproceedings{napoles-etal-2012-annotated,
    title = "Annotated {G}igaword",
    author = "Napoles, Courtney  and
      Gormley, Matthew  and
      Van Durme, Benjamin",
    booktitle = "Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction ({AKBC}-{WEKEX})",
    
    year = "2012",
    
    
    url = "https://aclanthology.org/W12-3018",
    pages = "95--100",
}

@article{puri2019zero,
  title={Zero-shot text classification with generative language models},
  author={Puri, Raul and Catanzaro, Bryan},
  year={2019},
  url={https://arxiv.org/abs/1912.10165}
}

@inproceedings{anli,
    title = "Adversarial {NLI}: A New Benchmark for Natural Language Understanding",
    author = "Nie, Yixin  and
      Williams, Adina  and
      Dinan, Emily  and
      Bansal, Mohit  and
      Weston, Jason  and
      Kiela, Douwe",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    
    year = "2020",
    
    
    url = "https://aclanthology.org/2020.acl-main.441",
    
    pages = "4885--4901",
    abstract = "We introduce a new large-scale NLI benchmark dataset, collected via an iterative, adversarial human-and-model-in-the-loop procedure. We show that training models on this new dataset leads to state-of-the-art performance on a variety of popular NLI benchmarks, while posing a more difficult challenge with its new test set. Our analysis sheds light on the shortcomings of current state-of-the-art models, and shows that non-expert annotators are successful at finding their weaknesses. The data collection method can be applied in a never-ending learning scenario, becoming a moving target for NLU, rather than a static benchmark that will quickly saturate.",
}

@inproceedings{mostafazadeh-etal-2016-corpus,
    title = "A Corpus and Cloze Evaluation for Deeper Understanding of Commonsense Stories",
    author = "Mostafazadeh, Nasrin  and
      Chambers, Nathanael  and
      He, Xiaodong  and
      Parikh, Devi  and
      Batra, Dhruv  and
      Vanderwende, Lucy  and
      Kohli, Pushmeet  and
      Allen, James",
    booktitle = "Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    
    year = "2016",
    
    
    url = "https://aclanthology.org/N16-1098",
    
    pages = "839--849",
}

@inproceedings{holtzman-etal-2021-surface,
    title = "Surface Form Competition: Why the Highest Probability Answer Isn{'}t Always Right",
    author = "Holtzman, Ari  and
      West, Peter  and
      Shwartz, Vered  and
      Choi, Yejin  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    year = "2021",
    url = "https://aclanthology.org/2021.emnlp-main.564",
}

@inproceedings{zellers-etal-2019-hellaswag,
    title = "{H}ella{S}wag: Can a Machine Really Finish Your Sentence?",
    author = "Zellers, Rowan  and
      Holtzman, Ari  and
      Bisk, Yonatan  and
      Farhadi, Ali  and
      Choi, Yejin",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    
    year = "2019",
    
    
    url = "https://aclanthology.org/P19-1472",
    
    pages = "4791--4800",
    abstract = "Recent work by Zellers et al. (2018) introduced a new task of commonsense natural language inference: given an event description such as {``}A woman sits at a piano,{''} a machine must select the most likely followup: {``}She sets her fingers on the keys.{''} With the introduction of BERT, near human-level performance was reached. Does this mean that machines can perform human level commonsense inference? In this paper, we show that commonsense inference still proves difficult for even state-of-the-art models, by presenting HellaSwag, a new challenge dataset. Though its questions are trivial for humans ({\textgreater}95{\%} accuracy), state-of-the-art models struggle ({\textless}48{\%}). We achieve this via Adversarial Filtering (AF), a data collection paradigm wherein a series of discriminators iteratively select an adversarial set of machine-generated wrong answers. AF proves to be surprisingly robust. The key insight is to scale up the length and complexity of the dataset examples towards a critical {`}Goldilocks{'} zone wherein generated text is ridiculous to humans, yet often misclassified by state-of-the-art models. Our construction of HellaSwag, and its resulting difficulty, sheds light on the inner workings of deep pretrained models. More broadly, it suggests a new path forward for NLP research, in which benchmarks co-evolve with the evolving state-of-the-art in an adversarial way, so as to present ever-harder challenges.",
}

@inproceedings{SSS112418,
	author = {Melissa Roemmele and Cosmin Bejan and Andrew Gordon},
	title = {Choice of Plausible Alternatives: An Evaluation of Commonsense Causal Reasoning},
	booktitle = {AAAI Spring Symposium Series},
	year = {2011},
	url = {https://www.aaai.org/ocs/index.php/SSS/SSS11/paper/view/2418}
}


@inproceedings{Bisk2020,
  author = {Yonatan Bisk and Rowan Zellers and
            Ronan Le Bras and Jianfeng Gao
            and Yejin Choi},
  title = {{PIQA}: Reasoning about Physical Commonsense in
           Natural Language},
  booktitle = {Thirty-Fourth AAAI Conference on
               Artificial Intelligence},
  year = {2020},
  url={https://arxiv.org/abs/1911.11641}
}

@inproceedings{rajpurkar-etal-2018-know,
    title = "Know What You Don{'}t Know: Unanswerable Questions for {SQ}u{AD}",
    author = "Rajpurkar, Pranav  and
      Jia, Robin  and
      Liang, Percy",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    year = "2018",
    url = "https://aclanthology.org/P18-2124",
    pages = "784--789",
}

@inproceedings{huang-etal-2019-cosmos,
    title = "Cosmos {QA}: Machine Reading Comprehension with Contextual Commonsense Reasoning",
    author = "Huang, Lifu  and
      Le Bras, Ronan  and
      Bhagavatula, Chandra  and
      Choi, Yejin",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    
    year = "2019",
    
    
    url = "https://aclanthology.org/D19-1243",
    
    pages = "2391--2401",
    abstract = "Understanding narratives requires reading between the lines, which in turn, requires interpreting the likely causes and effects of events, even when they are not mentioned explicitly. In this paper, we introduce Cosmos QA, a large-scale dataset of 35,600 problems that require commonsense-based reading comprehension, formulated as multiple-choice questions. In stark contrast to most existing reading comprehension datasets where the questions focus on factual and literal understanding of the context paragraph, our dataset focuses on reading between the lines over a diverse collection of people{'}s everyday narratives, asking such questions as {``}what might be the possible reason of ...?'', or {``}what would have happened if ...'' that require reasoning beyond the exact text spans in the context. To establish baseline performances on Cosmos QA, we experiment with several state-of-the-art neural architectures for reading comprehension, and also propose a new architecture that improves over the competitive baselines. Experimental results demonstrate a significant gap between machine (68.4{\%}) and human performance (94{\%}), pointing to avenues for future research on commonsense machine comprehension. Dataset, code and leaderboard is publicly available at https://wilburone.github.io/cosmos.",
}

@inproceedings{brown2020language,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D. and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {1877--1901},
 title = {Language Models are Few-Shot Learners},
 url = {https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
 volume = {33},
 year = {2020}
}




@misc{zhao2021calibrate,
      title={Calibrate Before Use: Improving Few-Shot Performance of Language Models}, 
      author={Tony Z. Zhao and Eric Wallace and Shi Feng and Dan Klein and Sameer Singh},
      year={2021},
      eprint={2102.09690},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{liu2021makes,
      title={What Makes Good In-Context Examples for GPT-$3$?}, 
      author={Jiachang Liu and Dinghan Shen and Yizhe Zhang and Bill Dolan and Lawrence Carin and Weizhu Chen},
      year={2021},
      eprint={2101.06804},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


%% Retrieval
@misc{izacard2021leveraging,
      title={Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering}, 
      author={Gautier Izacard and Edouard Grave},
      year={2021},
      eprint={2007.01282},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

%% PET papers
@misc{schick2021exploiting,
      title={Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference}, 
      author={Timo Schick and Hinrich Schütze},
      year={2021},
      eprint={2001.07676},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{schick2021its,
      title={It's Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners}, 
      author={Timo Schick and Hinrich Schütze},
      year={2021},
      eprint={2009.07118},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{tam2021improving,
      title={Improving and Simplifying Pattern Exploiting Training}, 
      author={Derek Tam and Rakesh R Menon and Mohit Bansal and Shashank Srivastava and Colin Raffel},
      year={2021},
      eprint={2103.11955},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@article{yang2019xlnet,
  title={Xlnet: Generalized autoregressive pretraining for language understanding},
  author={Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Ruslan and Le, Quoc V},
  journal={arXiv preprint arXiv:1906.08237},
  year={2019},
}


@article{reif2021recipe,
  title={A Recipe For Arbitrary Text Style Transfer with Large Language Models},
  author={Emily Reif and Daphne Ippolito and Ann Yuan and Andy Coenen and Chris Callison-Burch and Jason Wei},
  year={2021},
  journal={arXiv preprint arXiv:2109.03910},
  url={https://arxiv.org/abs/2109.03910},
}

@inproceedings{he-etal-2015-question,
    title = "Question-Answer Driven Semantic Role Labeling: Using Natural Language to Annotate Natural Language",
    author = "He, Luheng  and
      Lewis, Mike  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    
    year = "2015",
    
    
    url = "https://aclanthology.org/D15-1076",
    
    pages = "643--653",
}

@inproceedings{gao-etal-2021-making,
    title = "Making Pre-trained Language Models Better Few-shot Learners",
    author = "Gao, Tianyu  and
      Fisch, Adam  and
      Chen, Danqi",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    
    year = "2021",
    
    
    url = "https://aclanthology.org/2021.acl-long.295",
    
    pages = "3816--3830",
    abstract = "The recent GPT-3 model (Brown et al., 2020) achieves remarkable few-shot performance solely by leveraging a natural-language prompt and a few task demonstrations as input context. Inspired by their findings, we study few-shot learning in a more practical scenario, where we use smaller language models for which fine-tuning is computationally efficient. We present LM-BFF{---}better few-shot fine-tuning of language models{---}a suite of simple and complementary techniques for fine-tuning language models on a small number of annotated examples. Our approach includes (1) prompt-based fine-tuning together with a novel pipeline for automating prompt generation; and (2) a refined strategy for dynamically and selectively incorporating demonstrations into each context. Finally, we present a systematic evaluation for analyzing few-shot performance on a range of NLP tasks, including classification and regression. Our experiments demonstrate that our methods combine to dramatically outperform standard fine-tuning procedures in this low resource setting, achieving up to 30{\%} absolute improvement, and 11{\%} on average across all tasks. Our approach makes minimal assumptions on task resources and domain expertise, and hence constitutes a strong task-agnostic method for few-shot learning.",
}

@inproceedings{levy-etal-2017-zero,
    title = "Zero-Shot Relation Extraction via Reading Comprehension",
    author = "Levy, Omer  and
      Seo, Minjoon  and
      Choi, Eunsol  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 21st Conference on Computational Natural Language Learning ({C}o{NLL} 2017)",
    
    year = "2017",
    
    
    url = "https://aclanthology.org/K17-1034",
    
    pages = "333--342",
    abstract = "We show that relation extraction can be reduced to answering simple reading comprehension questions, by associating one or more natural-language questions with each relation slot. This reduction has several advantages: we can (1) learn relation-extraction models by extending recent neural reading-comprehension techniques, (2) build very large training sets for those models by combining relation-specific crowd-sourced questions with distant supervision, and even (3) do zero-shot learning by extracting new relation types that are only specified at test-time, for which we have no labeled training examples. Experiments on a Wikipedia slot-filling task demonstrate that the approach can generalize to new questions for known relation types with high accuracy, and that zero-shot generalization to unseen relation types is possible, at lower accuracy levels, setting the bar for future work on this task.",
}

@inproceedings{li-etal-2020-unified,
    title = "A Unified {MRC} Framework for Named Entity Recognition",
    author = "Li, Xiaoya  and
      Feng, Jingrong  and
      Meng, Yuxian  and
      Han, Qinghong  and
      Wu, Fei  and
      Li, Jiwei",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    
    year = "2020",
    
    
    url = "https://aclanthology.org/2020.acl-main.519",
    
    pages = "5849--5859",
    abstract = "The task of named entity recognition (NER) is normally divided into nested NER and flat NER depending on whether named entities are nested or not.Models are usually separately developed for the two tasks, since sequence labeling models, the most widely used backbone for flat NER, are only able to assign a single label to a particular token, which is unsuitable for nested NER where a token may be assigned several labels. In this paper, we propose a unified framework that is capable of handling both flat and nested NER tasks. Instead of treating the task of NER as a sequence labeling problem, we propose to formulate it as a machine reading comprehension (MRC) task. For example, extracting entities with the per label is formalized as extracting answer spans to the question {``}\textit{which person is mentioned in the text}''.This formulation naturally tackles the entity overlapping issue in nested NER: the extraction of two overlapping entities with different categories requires answering two independent questions. Additionally, since the query encodes informative prior knowledge, this strategy facilitates the process of entity extraction, leading to better performances for not only nested NER, but flat NER. We conduct experiments on both nested and flat NER datasets.Experiment results demonstrate the effectiveness of the proposed formulation. We are able to achieve a vast amount of performance boost over current SOTA models on nested NER datasets, i.e., +1.28, +2.55, +5.44, +6.37,respectively on ACE04, ACE05, GENIA and KBP17, along with SOTA results on flat NER datasets, i.e., +0.24, +1.95, +0.21, +1.49 respectively on English CoNLL 2003, English OntoNotes 5.0, Chinese MSRA and Chinese OntoNotes 4.0.",
}

@inproceedings{wu-etal-2020-corefqa,
    title = "{C}oref{QA}: Coreference Resolution as Query-based Span Prediction",
    author = "Wu, Wei  and
      Wang, Fei  and
      Yuan, Arianna  and
      Wu, Fei  and
      Li, Jiwei",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    
    year = "2020",
    
    
    url = "https://aclanthology.org/2020.acl-main.622",
    
    pages = "6953--6963",
    abstract = "In this paper, we present CorefQA, an accurate and extensible approach for the coreference resolution task. We formulate the problem as a span prediction task, like in question answering: A query is generated for each candidate mention using its surrounding context, and a span prediction module is employed to extract the text spans of the coreferences within the document using the generated query. This formulation comes with the following key advantages: (1) The span prediction strategy provides the flexibility of retrieving mentions left out at the mention proposal stage; (2) In the question answering framework, encoding the mention and its context explicitly in a query makes it possible to have a deep and thorough examination of cues embedded in the context of coreferent mentions; and (3) A plethora of existing question answering datasets can be used for data augmentation to improve the model{'}s generalization capability. Experiments demonstrate significant performance boost over previous models, with 83.1 (+3.5) F1 score on the CoNLL-2012 benchmark and 87.5 (+2.5) F1 score on the GAP benchmark.",
}

@inproceedings{chai2020description,
  title={Description based text classification with reinforcement learning},
  author={Chai, Duo and Wu, Wei and Han, Qinghong and Wu, Fei and Li, Jiwei},
  booktitle={Proceedings of the International Conference on Machine Learning},
  pages={1371--1382},
  year={2020},
  organization={PMLR},
  url={http://proceedings.mlr.press/v119/chai20a/chai20a.pdf}
}

@inproceedings{kumar2016ask,
  title={Ask me anything: Dynamic memory networks for natural language processing},
  author={Kumar, Ankit and Irsoy, Ozan and Ondruska, Peter and Iyyer, Mohit and Bradbury, James and Gulrajani, Ishaan and Zhong, Victor and Paulus, Romain and Socher, Richard},
  booktitle={Proceedings of the International Conference on Machine Learning},
  pages={1378--1387},
  year={2016},
  organization={PMLR},
  url={https://arxiv.org/abs/1506.07285},
}

@article{wang2021zl3,
  title={Towards Zero-Label Language Learning},
  author={Zirui Wang and Adams Wei Yu and Orhan Firat and Yuan Cao},
  year={2021},
  journal={arXiv preprint arXiv:2109.09193},
  url={https://arxiv.org/abs/2109.09193},
}

@article{gpt2,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019},
  url={https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf}
}

@misc{schick2021generating,
      title={Generating Datasets with Pretrained Language Models}, 
      author={Timo Schick and Hinrich Schütze},
      year={2021},
      eprint={2104.07540},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@inproceedings{maas2011learning,
  title={Learning word vectors for sentiment analysis},
  author={Maas, Andrew and Daly, Raymond E and Pham, Peter T and Huang, Dan and Ng, Andrew Y and Potts, Christopher},
  booktitle={Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies},
  pages={142--150},
  year={2011}
}

@article{zhang2015character,
  title={Character-level convolutional networks for text classification},
  author={Zhang, Xiang and Zhao, Junbo and LeCun, Yann},
  journal={arXiv preprint arXiv:1509.01626},
  year={2015}
}

@article{song2019mass,
  title={{MASS}: Masked sequence to sequence pre-training for language generation},
  author={Song, Kaitao and Tan, Xu and Qin, Tao and Lu, Jianfeng and Liu, Tie-Yan},
  journal={Proceedings of the International Conference on Machine Learning},
  year={2019},
  url={https://arxiv.org/abs/1905.02450}
}

@article{xie2019unsupervised,
  title={Unsupervised data augmentation for consistency training},
  author={Xie, Qizhe and Dai, Zihang and Hovy, Eduard and Luong, Minh-Thang and Le, Quoc V},
  journal={arXiv preprint arXiv:1904.12848},
  year={2019}
}

@inproceedings{reynolds2021prompt,
  title={Prompt programming for large language models: Beyond the few-shot paradigm},
  author={Reynolds, Laria and McDonell, Kyle},
  booktitle={Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--7},
  year={2021}
}

@article{adiwardana2020towards,
  title={Towards a human-like open-domain chatbot},
  author={Adiwardana, Daniel and Luong, Minh-Thang and So, David R and Hall, Jamie and Fiedel, Noah and Thoppilan, Romal and Yang, Zi and Kulshreshtha, Apoorv and Nemade, Gaurav and Lu, Yifeng and others},
  journal={arXiv preprint arXiv:2001.09977},
  year={2020}
}

@article{he2020deberta,
  title={Deberta: Decoding-enhanced bert with disentangled attention},
  author={He, Pengcheng and Liu, Xiaodong and Gao, Jianfeng and Chen, Weizhu},
  journal={arXiv preprint arXiv:2006.03654},
  year={2020}
}

@article{amazonyelp2015,
    author = {Kotzias, Dimitrios and Denil, Misha and de Freitas, Nando and Smyth, Padhraic},
    title = {From Group to Individual Labels Using Deep Features},
    year = {2015},
    journal = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
    url = {https://dl.acm.org/doi/10.1145/2783258.2783380}
}

@inproceedings{lewis-etal-2020-bart,
    title = "{BART}: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",
    author = "Lewis, Mike  and
      Liu, Yinhan  and
      Goyal, Naman  and
      Ghazvininejad, Marjan  and
      Mohamed, Abdelrahman  and
      Levy, Omer  and
      Stoyanov, Veselin  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    
    year = "2020",
    
    
    url = "https://aclanthology.org/2020.acl-main.703",
    
    pages = "7871--7880",
    abstract = "We present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. It uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and other recent pretraining schemes. We evaluate a number of noising approaches, finding the best performance by both randomly shuffling the order of sentences and using a novel in-filling scheme, where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa on GLUE and SQuAD, and achieves new state-of-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 3.5 ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine translation, with only target language pretraining. We also replicate other pretraining schemes within the BART framework, to understand their effect on end-task performance.",
}

@article{schick2020s,
  title={It's Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners},
  author={Schick, Timo and Sch{\"u}tze, Hinrich},
  journal={arXiv preprint arXiv:2009.07118},
  year={2020}
}

@ARTICLE{prefix_tuning,
  title         = "{Prefix-Tuning}: Optimizing Continuous Prompts for
                   Generation",
  author        = "Li, Xiang Lisa and Liang, Percy",
  month         =  jan,
  year          =  2021,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2101.00190",
          url       = {http://arxiv.org/abs/2101.00190},
}


@inproceedings{sentencepiece,
  author    = {Taku Kudo and
               John Richardson},
  editor    = {Eduardo Blanco and
               Wei Lu},
  title     = {SentencePiece: {A} simple and language independent subword tokenizer
               and detokenizer for Neural Text Processing},
  booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2018: System Demonstrations, Brussels,
               Belgium, October 31 - November 4, 2018},
  pages     = {66--71},
  publisher = {Association for Computational Linguistics},
  year      = {2018},
  url       = {https://doi.org/10.18653/v1/d18-2012},
  doi       = {10.18653/v1/d18-2012},
  timestamp = {Tue, 28 Jan 2020 10:28:21 +0100},
  biburl    = {https://dblp.org/rec/conf/emnlp/KudoR18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{mikolov2010recurrent,
  title={Recurrent neural network based language model.},
  author={Mikolov, Tomas and Karafi{\'a}t, Martin and Burget, Lukas and Cernock{\`y}, Jan and Khudanpur, Sanjeev},
  booktitle={INTERSPEECH},
  year={2010}
}
@article{JozefowiczVSSW16,
  author    = {Rafal J{\'{o}}zefowicz and
               Oriol Vinyals and
               Mike Schuster and
               Noam Shazeer and
               Yonghui Wu},
  title     = {Exploring the Limits of Language Modeling},
  journal   = {arXiv preprint arXiv:1602.02410},
  year      = {2016},
}
@inproceedings{dai2015semi,
  title={Semi-supervised sequence learning},
  author={Dai, Andrew M and Le, Quoc V},
  booktitle={Proceedings of the Conference on Neural Information Processing Systems},
  year={2015},
  url={https://papers.nips.cc/paper/2015/file/7137debd45ae4d0ab9aa953017286b20-Paper.pdf}
}

@inproceedings{howard-ruder-2018-universal,
    title = "Universal Language Model Fine-tuning for Text Classification",
    author = "Howard, Jeremy  and
      Ruder, Sebastian",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    
    year = "2018",
    
    
    url = "https://aclanthology.org/P18-1031",
    
    pages = "328--339",
    abstract = "Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24{\%} on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100 times more data. We open-source our pretrained models and code.",
}


@misc{radford2018improving,
  title={Improving Language Understanding by Generative Pre-Training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  year={2018},
    howpublished={\url{https://blog.openai.com/language-unsupervised}}
}
@inproceedings{sutskever2011generating,
  title={Generating text with recurrent neural networks},
  author={Sutskever, Ilya and Martens, James and Hinton, Geoffrey E},
  booktitle={Proceedings of the International Conference on Machine Learning (ICML)},
  year={2011}
}

@inproceedings{shazeer2018adafactor,
  title={Adafactor: Adaptive learning rates with sublinear memory cost},
  author={Shazeer, Noam and Stern, Mitchell},
  booktitle={International Conference on Machine Learning},
  pages={4596--4604},
  year={2018},
  organization={PMLR},
  url={https://arxiv.org/abs/1804.04235}
}

@article{collobert2011natural,
  title={Natural language processing (almost) from scratch},
  author={Collobert, Ronan and Weston, Jason and Bottou, L{\'e}on and Karlen, Michael and Kavukcuoglu, Koray and Kuksa, Pavel},
  journal={Journal of {M}achine {L}earning {R}esearch},
  volume={12},
  pages={2493--2537},
  year={2011},
  url={https://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf}
}
@inproceedings{clark2019bam,
    title = "{BAM}! Born-Again Multi-Task Networks for Natural Language Understanding",
    author = "Clark, Kevin  and
      Luong, Minh-Thang  and
      Khandelwal, Urvashi  and
      Manning, Christopher D.  and
      Le, Quoc V.",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    
    year = "2019",
    
    
    url = "https://aclanthology.org/P19-1595",
    
    pages = "5931--5937",
    abstract = "It can be challenging to train multi-task neural networks that outperform or even match their single-task counterparts. To help address this, we propose using knowledge distillation where single-task models teach a multi-task model. We enhance this training with teacher annealing, a novel method that gradually transitions the model from distillation to supervised learning, helping the multi-task model surpass its single-task teachers. We evaluate our approach by multi-task fine-tuning BERT on the GLUE benchmark. Our method consistently improves over standard single-task and multi-task training.",
}

@article{luong2015multi,
  title={Multi-task sequence to sequence learning},
  author={Luong, Minh-Thang and Le, Quoc V and Sutskever, Ilya and Vinyals, Oriol and Kaiser, Lukasz},
  journal={Proceedings of ICLR},
  year={2016},
  url={https://arxiv.org/abs/1511.06114}
}

@inproceedings{liu2019multi,
    title = "Multi-Task Deep Neural Networks for Natural Language Understanding",
    author = "Liu, Xiaodong  and
      He, Pengcheng  and
      Chen, Weizhu  and
      Gao, Jianfeng",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    
    year = "2019",
    
    
    url = "https://aclanthology.org/P19-1441",
    
    pages = "4487--4496",
    abstract = "In this paper, we present a Multi-Task Deep Neural Network (MT-DNN) for learning representations across multiple natural language understanding (NLU) tasks. MT-DNN not only leverages large amounts of cross-task data, but also benefits from a regularization effect that leads to more general representations to help adapt to new tasks and domains. MT-DNN extends the model proposed in Liu et al. (2015) by incorporating a pre-trained bidirectional transformer language model, known as BERT (Devlin et al., 2018). MT-DNN obtains new state-of-the-art results on ten NLU tasks, including SNLI, SciTail, and eight out of nine GLUE tasks, pushing the GLUE benchmark to 82.7{\%} (2.2{\%} absolute improvement) as of February 25, 2019 on the latest GLUE test set. We also demonstrate using the SNLI and SciTail datasets that the representations learned by MT-DNN allow domain adaptation with substantially fewer in-domain labels than the pre-trained BERT representations. Our code and pre-trained models will be made publicly available.",
}

@misc{gao2025stargen,
      title={A Taxonomy for Evaluating Generalist Robot Policies}, 
      author={Jensen Gao and Suneel Belkhale and Sudeep Dasari and Ashwin Balakrishna and Dhruv Shah and Dorsa Sadigh},
      year={2025},
      eprint={2503.01238},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2503.01238}, 
}


@article{velay2018seq2seq,
  title={Seq2Seq and Multi-Task Learning for joint intent and content extraction for domain specific interpreters},
  author={Velay, Marc and Daniel, Fabrice},
  year={2018},
  journal={arXiv preprint arXiv:1808.00423},
  url={https://arxiv.org/abs/1808.00423}
}

@article{ruder2017overview,
  title={An overview of multi-task learning in deep neural networks},
  author={Ruder, Sebastian},
  year={2017},
  journal={arXiv preprint arXiv:1706.05098},
  url={https://arxiv.org/abs/1706.05098}
}

@article{wei2021finetuned,
  title={Finetuned language models are zero-shot learners},
  author={Wei, Jason and Bosma, Maarten and Zhao, Vincent Y and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M and Le, Quoc V},
  journal={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2022},
  url={https://openreview.net/forum?id=gEZrGCozdqR}
}

@inproceedings{smith2018decaylr,
title={Don't Decay the Learning Rate, Increase the Batch Size},
author={Samuel L. Smith and Pieter-Jan Kindermans and Quoc V. Le},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=B1Yy1BxCZ},
}


@misc{xla,
  author = {XLA},
  title = {{XLA}: Optimizing Compiler for {TensorFlow}},
  howpublished = "\url{https://www.tensorflow.org/xla}",
  note = {[Online; accessed December-2023]},
  year = 2019,
}

@software{megatronLMgithub,
title = {{M}egatron-{LM}},
url= {https://github.com/NVIDIA/Megatron-LM},
author = {Nvidia {M}egatron-{LM}},
}

@inproceedings{narayanan2021efficient,
  title={Efficient large-scale language model training on GPU clusters using megatron-LM},
  author={Narayanan, Deepak and Shoeybi, Mohammad and Casper, Jared and LeGresley, Patrick and Patwary, Mostofa and Korthikanti, Vijay and Vainbrand, Dmitri and Kashinkunti, Prethvi and Bernauer, Julie and Catanzaro, Bryan and others},
  booktitle={Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={1--15},
  year={2021}
}

@misc{sustainability2021google,
title={{S}ustainability at {Google}.{C}arbon neutral since 2007.{C}arbon free by 2030.},
 url = {https://sustainability.google/},
 year = {2022},
 author={Google Sustainability},
 }

@inproceedings{jouppi2017datacenter,
  title={In-datacenter performance analysis of a tensor processing unit},
  author={Jouppi, Norman P and Young, Cliff and Patil, Nishant and Patterson, David and Agrawal, Gaurav and Bajwa, Raminder and Bates, Sarah and Bhatia, Suresh and Boden, Nan and Borchers, Al and others},
  booktitle={Proceedings of the 44th annual international symposium on computer architecture},
  pages={1--12},
  year={2017}
}

@inproceedings{huang2019gpipe,
  title={{GPipe}: Efficient training of giant neural networks using pipeline parallelism},
  author={Huang, Yanping and Cheng, Youlong and Bapna, Ankur and Firat, Orhan and Chen, Dehao and Chen, Mia and Lee, HyoukJoong and Ngiam, Jiquan and Le, Quoc V and Wu, Yonghui and others},
  booktitle={Advances in neural information processing systems},
  pages={103--112},
  year={2019}
}


@inproceedings{shazeer2018mesh,
  title={{Mesh-TensorFlow}: Deep learning for supercomputers},
  author={Shazeer, Noam and Cheng, Youlong and Parmar, Niki and Tran, Dustin and Vaswani, Ashish and Koanantakool, Penporn and Hawkins, Peter and Lee, HyoukJoong and Hong, Mingsheng and Young, Cliff and others},
  booktitle={Advances in Neural Information Processing Systems},
  pages={10414--10423},
  year={2018}
}

@inproceedings{crankshaw2017clipper,
  title={Clipper: A low-latency online prediction serving system},
  author={Crankshaw, Daniel and Wang, Xin and Zhou, Guilio and Franklin, Michael J and Gonzalez, Joseph E and Stoica, Ion},
  booktitle={14th {USENIX} Symposium on Networked Systems Design and Implementation ({NSDI} 17)},
  pages={613--627},
  year={2017}
}

@inproceedings{malinowski2020sideways,
  title={Sideways: Depth-Parallel Training of Video Models},
  author={Malinowski, Mateusz and Swirszcz, Grzegorz and Carreira, Joao and Patraucean, Viorica},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11834--11843},
  year={2020}
}

@inproceedings{rhu2016vdnn,
  title={{vDNN}: Virtualized deep neural networks for scalable, memory-efficient neural network design},
  author={Rhu, Minsoo and Gimelshein, Natalia and Clemons, Jason and Zulfiqar, Arslan and Keckler, Stephen W},
  booktitle={2016 49th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)},
  pages={1--13},
  year={2016},
  organization={IEEE}
}

@article{pudipeddi2020training,
  title={Training Large Neural Networks with Constant Memory using a New Execution Algorithm},
  author={Pudipeddi, Bharadwaj and Mesmakhosroshahi, Maral and Xi, Jinwen and Bharadwaj, Sujeeth},
  journal={arXiv preprint arXiv:2002.05645},
  year={2020}
}

@inproceedings{hwang2019large,
  title={Large-Scale Training Framework for Video Annotation},
  author={Hwang, Seong Jae and Lee, Joonseok and Varadarajan, Balakrishnan and Gordon, Ariel and Xu, Zheng and Natsev, Apostol},
  booktitle={Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={2394--2402},
  year={2019}
}

@misc{wu2019emmental,
  title={Emmental: A framework for building multimodal multi-task learning systems},
  author={Wu, Sen},
  year={2019},
  howpublished = "\url{https://github.com/SenWu/emmental}",
}

@article{kaiser2017one,
  title={One model to learn them all},
  author={Kaiser, Lukasz and Gomez, Aidan N and Shazeer, Noam and Vaswani, Ashish and Parmar, Niki and Jones, Llion and Uszkoreit, Jakob},
  journal={arXiv preprint arXiv:1706.05137},
  year={2017}
}

@article{jouppi2020tpu,
  author    = {Norman P. Jouppi and
               Doe Hyun Yoon and
               George Kurian and
               Sheng Li and
               Nishant Patil and
               James Laudon and
               Cliff Young and
               David A. Patterson},
  title     = {A domain-specific supercomputer for training deep neural networks},
  journal   = {Commun. {ACM}},
  volume    = {63},
  number    = {7},
  pages     = {67--78},
  year      = {2020},
  url       = {https://doi.org/10.1145/3360307},
  doi       = {10.1145/3360307},
}

@inproceedings {abadi2016tensorflow,
  author = {Mart{\'\i}n Abadi and
            Paul Barham and
            Jianmin Chen and
            Zhifeng Chen and
            Andy Davis and
            Jeffrey Dean and
            Matthieu Devin and
            Sanjay Ghemawat and
            Geoffrey Irving and
            Michael Isard and
            Manjunath Kudlur and
            Josh Levenberg and
            Rajat Monga and
            Sherry Moore and
            Derek G. Murray and
            Benoit Steiner and
            Paul Tucker and
            Vijay Vasudevan and
            Pete Warden and
            Martin Wicke and
            Yuan Yu and
            Xiaoqiang Zheng},
  title = {{TensorFlow}: A System for Large-Scale Machine Learning},
  booktitle = {12th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 16)},
  year = {2016},
  isbn = {978-1-931971-33-1},
  address = {Savannah, GA},
  pages = {265--283},
  url = {https://www.usenix.org/conference/osdi16/technical-sessions/presentation/abadi},
  publisher = {{USENIX} Association},
  month = nov,
}

@inproceedings{akidau2013millwheel,
  title	= {{MillWheel}: Fault-Tolerant Stream Processing at {Internet} Scale},
  author	= {Tyler Akidau and
               Alex Balikov and
               Kaya Bekiroglu and
               Slava Chernyak and
               Josh Haberman and
               Reuven Lax and
               Sam McVeety and
               Daniel Mills and
               Paul Nordstrom and
               Sam Whittle},
  year	= {2013},
  booktitle	= {Very Large Data Bases},
  pages	= {734--746}
}

@InProceedings{murray2013naiad,
  author = {Murray, Derek and
            McSherry, Frank and
            Isaacs, Rebecca and
            Isard, Michael and
            Barham, Paul and
            Abadi, Martin},
  title = {Naiad: A Timely Dataflow System},
  booktitle = {Proceedings of the 24th ACM Symposium on Operating Systems Principles (SOSP)},
  year = {2013},
  month = {November},
  publisher = {ACM},
  url = {https://www.microsoft.com/en-us/research/publication/naiad-a-timely-dataflow-system-2/},
  edition = {Proceedings of the 24th ACM Symposium on Operating Systems Principles (SOSP)},
}

@inproceedings{yu2018dynamic,
  title	= {Dynamic Control Flow in Large-Scale Machine Learning},
  author	= {Yuan Yu and
             Martin Abadi and
             Paul Barham and
             Eugene Brevdo and
             Mike Burrows and
             Andy Davis and
             Jeff Dean and
             Sanjay Ghemawat and
             Tim Harley and
             Peter Hawkins and
             Michael Isard and
             Manjunath Kudlur and
             Rajat Monga and
             Derek Murray and
             Xiaoqiang Zheng},
  year	= {2018},
  URL	= {https://arxiv.org/pdf/1805.01772.pdf},
  booktitle	= {Proceedings of EuroSys 2018}
}

@inproceedings{paszke2017automatic,
  title={Automatic differentiation in {PyTorch}},
  author={Paszke, Adam and
         Gross, Sam and
         Chintala, Soumith and
         Chanan, Gregory and
         Yang, Edward and
         DeVito, Zachary and
         Lin, Zeming and
         Desmaison, Alban and
         Antiga, Luca and
         Lerer, Adam},
  booktitle={NIPS-W},
  year={2017}
}

@inproceedings{shazeer2017outrageously,
  title	= {Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer},
  author = {Noam Shazeer and
            Azalia Mirhoseini and
            Krzysztof Maziarz and
            Andy Davis and
            Quoc Le and
            Geoffrey Hinton and
            Jeff Dean},
  year	= {2017},
  booktitle = {ICLR (Poster)},
  url = {http://dblp.uni-trier.de/db/conf/iclr/iclr2017.html#ShazeerMMDLHD17},
  publisher = {OpenReview.net}
}

@inproceedings{devlin2019bert,
  title = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author = {Devlin, Jacob  and
            Chang, Ming-Wei  and
            Lee, Kenton  and
            Toutanova, Kristina},
  booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  month = {jun},
  year = {2019},
  address = {Minneapolis, Minnesota},
  publisher = {Association for Computational Linguistics},
  url = {https://www.aclweb.org/anthology/N19-1423},
  doi = {10.18653/v1/N19-1423},
  pages = {4171--4186},
}

@incollection{krizhevsky2012imagenet,
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle = {Advances in Neural Information Processing Systems},
  publisher = {Curran Associates, Inc.},
  title = {{ImageNet} Classification with Deep Convolutional Neural Networks},
  url = {https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
  volume = {25},
  year = {2012}
}

@inproceedings{ma2018modeling,
  title={Modeling task relationships in multi-task learning with multi-gate mixture-of-experts},
  author={Ma, Jiaqi and Zhao, Zhe and Yi, Xinyang and Chen, Jilin and Hong, Lichan and Chi, Ed H},
  booktitle={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={1930--1939},
  year={2018}
}
@article{pascanu2012,
  author    = {Razvan Pascanu and
               Tom{\'{a}}s Mikolov and
               Yoshua Bengio},
  title     = {Understanding the exploding gradient problem},
  journal   = {CoRR},
  volume    = {abs/1211.5063},
  year      = {2012},
  url       = {http://arxiv.org/abs/1211.5063},
  eprinttype = {arXiv},
  eprint    = {1211.5063},
  timestamp = {Mon, 28 Dec 2020 11:31:02 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1211-5063.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{kudo2018sentencepiece,
    title = "{S}entence{P}iece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing",
    author = "Kudo, Taku  and
      Richardson, John",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-2012",
    doi = "10.18653/v1/D18-2012",
    pages = "66--71",
    abstract = "This paper describes SentencePiece, a language-independent subword tokenizer and detokenizer designed for Neural-based text processing, including Neural Machine Translation. It provides open-source C++ and Python implementations for subword units. While existing subword segmentation tools assume that the input is pre-tokenized into word sequences, SentencePiece can train subword models directly from raw sentences, which allows us to make a purely end-to-end and language independent system. We perform a validation experiment of NMT on English-Japanese machine translation, and find that it is possible to achieve comparable accuracy to direct subword training from raw sentences. We also compare the performance of subword training and segmentation with various configurations. SentencePiece is available under the Apache 2 license at \url{https://github.com/google/sentencepiece}.",
}


@inproceedings{clarke1994mpi,
  author={Clarke, Lyndon
          and Glendinning, Ian
          and Hempel, Rolf},
  title={The {MPI} Message Passing Interface Standard},
  booktitle={Programming Environments for Massively Parallel Distributed Systems},
  year={1994},
  pages={213--218},
  isbn={978-3-0348-8534-8}
}

@inproceedings{he2016deep,
  author={He, Kaiming and
          Zhang, Xiangyu and
          Ren, Shaoqing and
          Sun, Jian},
  booktitle={2016 IEEE Conference on Computer Vision and
           Pattern Recognition (CVPR)},
  title={Deep Residual Learning for Image Recognition},
  year={2016},
  pages={770-778},
  doi={10.1109/CVPR.2016.90},
  url = {https://arxiv.org/abs/1512.03385v1}
}

@misc{rayplacementgroupdocs,
    key={rayplacementgroupdocs},
    author = {{The Ray Team}},
    title = {Ray: Placement Groups},
    howpublished = "\url{https://docs.ray.io/en/master/placement-group.html)}",
    version = {v2.0.0.dev0},
    year = 2021,
}


@inproceedings{paszke2019pytorch,
  author = {Paszke, Adam and
            Gross, Sam and
            Massa, Francisco and
            Lerer, Adam and
            Bradbury, James and
            Chanan, Gregory and
            Killeen, Trevor and
            Lin, Zeming and
            Gimelshein, Natalia and
            Antiga, Luca and
            Desmaison, Alban and
            Köpf, Andreas and
            Yang, Edward and
            DeVito, Zach and
            Raison, Martin and
            Tejani, Alykhan and
            Chilamkurthy, Sasank and
            Steiner, Benoit and
            Fang, Lu and
            Bai, Junjie and
            Chintala, Soumith},
  publisher = {Curran Associates, Inc.},
  title = {{PyTorch}: An Imperative Style, High-Performance Deep Learning Library},
  booktitle = {Advances in Neural Information Processing Systems},
  url = {https://proceedings.neurips.cc/paper/2019/file/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf},
  volume = {32},
  year = {2019}
}



@inproceedings{narayanan2019pipedream,
  author = {Narayanan, Deepak and Harlap, Aaron and Phanishayee, Amar and Seshadri, Vivek and Devanur, Nikhil and Granger, Greg and Gibbons, Phil and Zaharia, Matei},
  title = {{PipeDream}: Generalized Pipeline Parallelism for {DNN} Training},
  booktitle = {ACM Symposium on Operating Systems Principles (SOSP 2019)},
  year = {2019},
  month = {October},
  url = {https://www.microsoft.com/en-us/research/publication/pipedream-generalized-pipeline-parallelism-for-dnn-training/},
}

@inproceedings{moritz2018ray,
  author = {Moritz, Philipp and
            Nishihara, Robert and
            Wang, Stephanie and
            Tumanov, Alexey and
            Liaw, Richard and
            Liang, Eric and
            Elibol, Melih and
            Yang, Zongheng and
            Paul, William and
            Jordan, Michael I. and
            Stoica, Ion},
  title = {Ray: A Distributed Framework for Emerging {AI} Applications},
  year = {2018},
  isbn = {9781931971478},
  publisher = {USENIX Association},
  booktitle = {Proceedings of the 13th USENIX Conference on Operating Systems Design and Implementation},
  pages = {561–577},
  numpages = {17},
  series = {OSDI'18}
}


@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{rajbhandari2021zeroinfinity,
  title={{ZeRO-Infinity}: Breaking the {GPU} Memory Wall for Extreme Scale Deep Learning}, 
      author={Samyam Rajbhandari and Olatunji Ruwase and Jeff Rasley and Shaden Smith and Yuxiong He},
  journal={arXiv preprint arXiv:2104.07857},
  year={2021}
}


@inproceedings{kirk2007cuda,
  author = {Kirk, David},
  title = {{NVIDIA} {CUDA} Software and {GPU} Parallel Computing Architecture},
  year = {2007},
  isbn = {9781595938930},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/1296907.1296909},
  doi = {10.1145/1296907.1296909},
  booktitle = {Proceedings of the 6th International Symposium on Memory Management},
  pages = {103–104},
  numpages = {2},
  location = {Montreal, Quebec, Canada},
  series = {ISMM '07}
}

@misc{nvswitch2019,
  author = {NVIDIA},
  title = {{NVIDIA} {NVSwitch} - Technical Overview},
  howpublished = "\url{https://images.nvidia.com/content/pdf/nvswitch-technical-overview.pdf}",
  note = {[Online; accessed October-2019]},
  year = 2019,
}

@misc{tfds,
  author = {TensorFlow},
  title = {{TensorFlow Datasets}: {A} collection of ready-to-use datasets.},
  howpublished = "\url{https://www.tensorflow.org/datasets}",
  note = {[Online; accessed May-2021]},
  year = 2021,
}

@article{agrawal2019tensorflow,
  title={{TensorFlow} {Eager}: A multi-stage, {Python}-embedded {DSL} for machine learning},
  author={Agrawal, Akshay and Modi, Akshay Naresh and Passos, Alexandre and Lavoie, Allen and Agarwal, Ashish and Shankar, Asim and Ganichev, Igor and Levenberg, Josh and Hong, Mingsheng and Monga, Rajat and others},
  journal={arXiv preprint arXiv:1903.01855},
  year={2019}
}

@article{naumov2020deep,
  title={Deep learning training in {Facebook} data centers: Design of scale-up and scale-out systems},
  author={Naumov, Maxim and Kim, John and Mudigere, Dheevatsa and Sridharan, Srinivas and Wang, Xiaodong and Zhao, Whitney and Yilmaz, Serhat and Kim, Changkyu and Yuen, Hector and Ozdal, Mustafa and others},
  journal={arXiv preprint arXiv:2003.09518},
  year={2020}
}

@article{shallue2018measuring,
  title={Measuring the effects of data parallelism on neural network training},
  author={Shallue, Christopher J and Lee, Jaehoon and Antognini, Joseph and Sohl-Dickstein, Jascha and Frostig, Roy and Dahl, George E},
  journal={arXiv preprint arXiv:1811.03600},
  year={2018}
}

@misc{gpudirect2021,
  author = {NVIDIA},
  title = {{NVIDIA} {GPUDirect} Technology},
  howpublished = "\url{http://developer.download.nvidia.com/devzone/devcenter/cuda/docs/GPUDirect_Technology_Overview.pdf}",
  note = {[Online; accessed February-2021]},
  year = 2021,
}

misc{murray2021tfdata,
  title={{tf.data}: {A} Machine Learning Data Processing Framework}, 
  author={Derek G. Murray and Jiri Simsa and Ana Klimovic and Ihor Indyk},
  year={2021},
  eprint={2101.12127},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}

@article{tfdata-vldb21,
  author    = {Derek Gordon Murray and
               Jiri Simsa and
               Ana Klimovic and
               Ihor Indyk},
  title     = {{tf.data}: {A} Machine Learning Data Processing Framework},
  journal   = {Proceedings of the 47th International Conference on Very Large Data Bases (VLDB)},
  year      = {2021},
}

@article{switchtransformer2021,
  title={Switch {Transformers}: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity},
  author={William Fedus and Barret Zoph and Noam Shazeer},
  journal={arXiv preprint arXiv:2101.03961},
  year={2021}
}



@article{shoeybi2019megatron,
  author    = {Mohammad Shoeybi and
               Mostofa Patwary and
               Raul Puri and
               Patrick LeGresley and
               Jared Casper and
               Bryan Catanzaro},
  title     = {{Megatron-LM}: Training Multi-Billion Parameter Language Models Using
               Model Parallelism},
  journal   = {CoRR},
  volume    = {abs/1909.08053},
  year      = {2019},
  url       = {http://arxiv.org/abs/1909.08053},
  archivePrefix = {arXiv},
  eprint    = {1909.08053},
  timestamp = {Tue, 24 Sep 2019 11:33:51 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1909-08053.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@misc{anil2021scalable,
      title={Scalable Second Order Optimization for Deep Learning}, 
      author={Rohan Anil and Vineet Gupta and Tomer Koren and Kevin Regan and Yoram Singer},
      year={2021},
      eprint={2002.09018},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{googlecloudtpu,
  author = {Google},
  title = {Cloud {TPU}},
  howpublished = "\url{https://cloud.google.com/tpu}",
  note = {[Online; accessed March-2021]},
  year = 2021,
}

@article{arvind1986dataflow,
  author = {Arvind and Culler, David E.},
  title = {Dataflow Architectures},
  journal = {Annual Review of Computer Science},
  volume = {1},
  number = {1},
  pages = {225-253},
  year = {1986},
  doi = {10.1146/annurev.cs.01.060186.001301},
}

@inproceedings{yang2021pipemare,
  title={Pipemare: Asynchronous pipeline parallel {DNN} training},
  author={Yang, Bowen and Zhang, Jian and Li, Jonathan and R{\'e}, Christopher and Aberger, Christopher and De Sa, Christopher},
  booktitle={Proceedings of Machine Learning and Systems},
  year={2021}
}

@inproceedings{barham2019hotos,
author = {Barham, Paul and Isard, Michael},
title = {Machine Learning Systems Are Stuck in a Rut},
year = {2019},
isbn = {9781450367271},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3317550.3321441},
doi = {10.1145/3317550.3321441},
booktitle = {Proceedings of the Workshop on Hot Topics in Operating Systems},
pages = {177–183},
numpages = {7},
location = {Bertinoro, Italy},
series = {HotOS '19}
}

@inproceedings{xue2019fast,
  title={Fast distributed deep learning over {RDMA}},
  author={Xue, Jilong and Miao, Youshan and Chen, Cheng and Wu, Ming and Zhang, Lintao and Zhou, Lidong},
  booktitle={Proceedings of the Fourteenth EuroSys Conference 2019},
  pages={1--14},
  year={2019}
}

@inproceedings{pham2018efficient,
  title={Efficient neural architecture search via parameters sharing},
  author={Pham, Hieu and Guan, Melody and Zoph, Barret and Le, Quoc and Dean, Jeff},
  booktitle={International Conference on Machine Learning},
  pages={4095--4104},
  year={2018},
  organization={PMLR}
}


@inproceedings{min-etal-2022-rethinking,
    title = "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?",
    author = "Min, Sewon  and
      Lyu, Xinxi  and
      Holtzman, Ari  and
      Artetxe, Mikel  and
      Lewis, Mike  and
      Hajishirzi, Hannaneh  and
      Zettlemoyer, Luke",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.759",
    doi = "10.18653/v1/2022.emnlp-main.759",
    pages = "11048--11064",
    abstract = "Large language models (LMs) are able to in-context learn{---}perform a new task via inference alone by conditioning on a few input-label pairs (demonstrations) and making predictions for new inputs. However, there has been little understanding of how the model learns and which aspects of the demonstrations contribute to end task performance. In this paper, we show that ground truth demonstrations are in fact not required{---}randomly replacing labels in the demonstrations barely hurts performance on a range of classification and multi-choce tasks, consistently over 12 different models including GPT-3. Instead, we find that other aspects of the demonstrations are the key drivers of endtask performance, including the fact that they provide a few examples of (1) the label space, (2) the distribution of the input text, and (3) the overall format of the sequence. Together, our analysis provides a new way of understanding how and why in-context learning works, while opening up new questions about how much can be learned from large language models through inference alone.",
}

@inproceedings{zhang-etal-2023-prompting,
author = {Zhang, Biao and Haddow, Barry and Birch, Alexandra},
title = {Prompting large language model for machine translation: a case study},
year = {2023},
publisher = {JMLR.org},
abstract = {Research on prompting has shown it to have excellent performance with little or even no supervised training across many tasks. However, prompting for machine translation is still under-explored in the literature. We fill this gap by offering a systematic study on prompting strategies for translation, examining various factors for prompt template and demonstration example selection. We further explore the use of monolingual data and the feasibility of cross-lingual, cross-domain, and sentence-to-document transfer learning in prompting. Extensive experiments with GLM-130B (Zeng et al., 2022) as the testbed show that 1) the number and the quality of prompt examples matter, where using suboptimal examples degenerates translation; 2) several features of prompt examples, such as semantic similarity, show significant Spearman correlation with their prompting performance; yet, none of the correlations are strong enough; 3) using pseudo parallel prompt examples constructed from monolingual data via zero-shot prompting could improve translation; and 4) improved performance is achievable by transferring knowledge from prompt examples selected in other settings. We finally provide an analysis on the model outputs and discuss several problems that prompting still suffers from.},
booktitle = {Proceedings of the 40th International Conference on Machine Learning},
articleno = {1722},
numpages = {19},
series = {ICML'23}
}

@article{saab2024capabilities,
  title={Capabilities of {G}emini models in medicine},
  author={Saab, Khaled and Tu, Tao and Weng, Wei-Hung and Tanno, Ryutaro and Stutz, David and Wulczyn, Ellery and Zhang, Fan and Strother, Tim and Park, Chunjong and Vedadi, Elahe and others},
  journal={arXiv preprint arXiv:2404.18416},
  year={2024}
}

@article{agarwal2024many,
 title={Many-Shot In-Context Learning},
     author={Rishabh Agarwal and Avi Singh and Lei M. Zhang and Bernd Bohnet and Stephanie Chan and Ankesh Anand and Zaheer Abbas and Azade Nova and John D. Co-Reyes and Eric Chu and Feryal Behbahani and Aleksandra Faust and Hugo Larochelle},
      year={2024},
      eprint={2404.11018}, 
      journal   = {CoRR},
      volume={abs/2404.11018},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{li2023context,
  title={In-context learning with many demonstration examples},
  author={Li, Mukai and Gong, Shansan and Feng, Jiangtao and Xu, Yiheng and Zhang, Jun and Wu, Zhiyong and Kong, Lingpeng},
  journal={arXiv preprint arXiv:2302.04931},
  year={2023}
}

@article{bertsch2024context,
  title={In-Context Learning with Long-Context Models: An In-Depth Exploration},
  author={Bertsch, Amanda and Ivgi, Maor and Alon, Uri and Berant, Jonathan and Gormley, Matthew R and Neubig, Graham},
  journal={arXiv preprint arXiv:2405.00200},
  year={2024}
}

@article{jones2023bilex,
  title={Bilex rx: Lexical data augmentation for massively multilingual machine translation},
  author={Jones, Alex and Caswell, Isaac and Saxena, Ishank and Firat, Orhan},
  journal={arXiv preprint arXiv:2303.15265},
  year={2023}
}

@misc{bohnet2024longspan,
      title={Long-Span Question-Answering: Automatic Question Generation and QA-System Ranking via Side-by-Side Evaluation}, 
      author={Bernd Bohnet and Kevin Swersky and Rosanne Liu and Pranjal Awasthi and Azade Nova and Javier Snaider and Hanie Sedghi and Aaron T Parisi and Michael Collins and Angeliki Lazaridou and Orhan Firat and Noah Fiedel},
      year={2024},
      eprint={2406.00179},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{jeon2018multi,
  title={Multi-tenant {GPU} clusters for deep learning workloads: Analysis and implications},
  author={Jeon, Myeongjae and Venkataraman, Shivaram and Qian, Junjie and Phanishayee, Amar and Xiao, Wencong and Yang, Fan},
  journal={Technical report, Microsoft Research},
  year={2018}
}

@inproceedings{wang2021ticktock,
 author = {Guanhua Wang and Kehan Wang and Kenan Jiang and Xiangjun Li and Ion Stoica},
 booktitle = {Proceedings of Machine Learning and Systems},
 title = {Wavelet: Efficient {DNN} Training with {Tick-Tock} Scheduling},
 year = {2021}
}

@inproceedings{gupta2011pegasus,
  title={Pegasus: Coordinated scheduling for virtualized accelerator-based systems},
  author={Gupta, Vishakha and Schwan, Karsten and Tolia, Niraj and Talwar, Vanish and Ranganathan, Parthasarathy},
  booktitle={2011 USENIX Annual Technical Conference (USENIX ATC’11)},
  volume={31},
  year={2011}
}

@inproceedings{kwon2020nimble,
  title={Nimble: Lightweight and Parallel {GPU} Task Scheduling for Deep Learning},
  author={Kwon, Woosuk and Yu, Gyeong-In and Jeong, Eunji and Chun, Byung-Gon},
  booktitle = {Advances in Neural Information Processing Systems},
  year={2020}
}



@article{zhao2022vpipe,
  author={Zhao, Shixiong and Li, Fanxin and Chen, Xusheng and Guan, Xiuxian and Jiang, Jianyu and Huang, Dong and Qing, Yuhao and Wang, Sen and Wang, Peng and Zhang, Gong and Li, Cheng and Luo, Ping and Cui, Heming},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={{vPipe}: A Virtualized Acceleration System for Achieving Efficient and Scalable Pipeline Parallel {DNN} Training}, 
  year={2022},
  volume={33},
  number={3},
  pages={489-506},
ote = "To appear",
}

@inproceedings{xiao2020antman,
author = {Wencong Xiao and Shiru Ren and Yong Li and Yang Zhang and Pengyang Hou and Zhi Li and Yihui Feng and Wei Lin and Yangqing Jia},
title = {AntMan: Dynamic Scaling on {GPU} Clusters for Deep Learning},
booktitle = {14th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 20)},
year = {2020},
pages = {533--548},
publisher = {{USENIX} Association},
month = nov,
}

@inproceedings{weng2022mlaas,
	author = {Qizhen Weng and Wencong Xiao and Yinghao Yu and Wei Wang and Cheng Wang and Jian He and Yong Li and Liping Zhang and Wei Lin and Yu Ding},
	title = {{MLaaS} in the Wild: Workload Analysis and Scheduling in Large-Scale Heterogeneous {GPU} Clusters},
	booktitle = {19th {USENIX} Symposium on Networked Systems Design and Implementation ({NSDI} 22)},
	year = {2022},
	address = {Renton, WA},
	publisher = {{USENIX} Association},
	month = apr,
	note = "To appear",
}

@inproceedings{bai2020pipeswitch,
author = {Zhihao Bai and Zhen Zhang and Yibo Zhu and Xin Jin},
title = {{PipeSwitch}: Fast Pipelined Context Switching for Deep Learning Applications},
booktitle = {14th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 20)},
year = {2020},
publisher = {{USENIX} Association},
month = nov,
}

@article{bommasani2021foundation,
  author    = {Rishi Bommasani and Drew A. Hudson et. al.},
  url       = {https://arxiv.org/abs/2108.07258},
  eprinttype = {arXiv},
  eprint    = {},
  title     = {On the Opportunities and Risks of Foundation Models},
  year      = {2021},
  journal={arXiv preprint arXiv:2108.07258},
}

@inproceedings{jeon2019philly,
author = {Myeongjae Jeon and Shivaram Venkataraman and Amar Phanishayee and Junjie Qian and Wencong Xiao and Fan Yang},
title = {Analysis of Large-Scale Multi-Tenant {GPU} Clusters for {DNN} Training Workloads},
booktitle = {2019 {USENIX} Annual Technical Conference ({USENIX} {ATC} 19)},
year = {2019},
isbn = {978-1-939133-03-8},
address = {Renton, WA},
pages = {947--960},
url = {https://www.usenix.org/conference/atc19/presentation/jeon},
publisher = {{USENIX} Association},
month = jul,
}

@inproceedings{chaudhary2020gandivafair,
author = {Chaudhary, Shubham and Ramjee, Ramachandran and Sivathanu, Muthian and Kwatra, Nipun and Viswanatha, Srinidhi},
title = {Balancing Efficiency and Fairness in Heterogeneous {GPU} Clusters for Deep Learning},
year = {2020},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3342195.3387555},
doi = {10.1145/3342195.3387555},
booktitle = {Proceedings of the Fifteenth European Conference on Computer Systems},
series = {EuroSys '20}
}

@inproceedings{bird2004nltk,
    title = "{NLTK}: The Natural Language Toolkit",
    author = "Bird, Steven  and
      Loper, Edward",
    booktitle = "Proceedings of the {ACL} Interactive Poster and Demonstration Sessions",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P04-3031",
    pages = "214--217",
}

@inproceedings{webster2020automatically,
title	= {Automatically Identifying Gender Bias in Machine Translation using Perturbations},
author	= {Hila Gonen and Hila Gonen},
year	= {2020},
URL	= {https://arxiv.org/abs/2004.14065}
}

@inproceedings{NEURIPS2020_gpt3,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {1877--1901},
 publisher = {Curran Associates, Inc.},
 title = {Language Models are Few-Shot Learners},
 url = {https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
 volume = {33},
 year = {2020}
}


@inproceedings{stanovsky-etal-2019-evaluating,
    title = "Evaluating Gender Bias in Machine Translation",
    author = "Stanovsky, Gabriel  and
      Smith, Noah A.  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1164",
    doi = "10.18653/v1/P19-1164",
    pages = "1679--1684",
}

@misc{webster2020scalable,
      title={Scalable Cross Lingual Pivots to Model Pronoun Gender for Translation}, 
      author={Kellie Webster and Emily Pitler},
      year={2020},
      eprint={2006.08881},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{allamanis2017survey,
author = {Allamanis, Miltiadis and Barr, Earl T. and Devanbu, Premkumar and Sutton, Charles},
title = {A Survey of Machine Learning for Big Code and Naturalness},
year = {2018},
issue_date = {July 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3212695},
doi = {10.1145/3212695},
journal = {ACM Comput. Surv.},
month = {jul},
articleno = {81},
numpages = {37},
}

@article{copilot-security,
  author    = {Hammond Pearce and
               Baleegh Ahmad and
               Benjamin Tan and
               Brendan Dolan{-}Gavitt and
               Ramesh Karri},
  title     = {An Empirical Cybersecurity Evaluation of {GitHub Copilot's} Code Contributions},
  journal   = {CoRR},
  volume    = {abs/2108.09293},
  year      = {2021},
  url       = {https://arxiv.org/abs/2108.09293},
  eprinttype = {arXiv},
  eprint    = {2108.09293},
  timestamp = {Mon, 29 Nov 2021 07:42:42 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2108-09293.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{Schuster2020-an,
  title     = "You Autocomplete Me: Poisoning Vulnerabilities in Neural Code
               Completion",
  booktitle = "30th {USENIX} Security Symposium ({{USENIX}} Security 21)",
  author    = "Schuster, Roei and Song, Congzheng and Tromer, Eran and
               Shmatikov, Vitaly",
  year      =  2020
}

@INPROCEEDINGS{Qi2015-rh,
  title     = "An analysis of patch plausibility and correctness for
               generate-and-validate patch generation systems",
  booktitle = "Proceedings of the 2015 International Symposium on Software
               Testing and Analysis",
  author    = "Qi, Zichao and Long, Fan and Achour, Sara and Rinard, Martin",
  publisher = "Association for Computing Machinery",
  pages     = "24--36",
  series    = "ISSTA 2015",
  month     =  jul,
  year      =  2015,
  address   = "New York, NY, USA",
  keywords  = "Function Elimination, Patch Analysis, Automatic Repair",
  location  = "Baltimore, MD, USA"
}

@article{suzgun2022challenging,
  title={Challenging big-bench tasks and whether chain-of-thought can solve them},
  author={Suzgun, Mirac and Scales, Nathan and Sch{\"a}rli, Nathanael and Gehrmann, Sebastian and Tay, Yi and Chung, Hyung Won and Chowdhery, Aakanksha and Le, Quoc V and Chi, Ed H and Zhou, Denny and others},
  journal={arXiv preprint arXiv:2210.09261},
  year={2022}
}

@INPROCEEDINGS{9011031,
  author={Biten, Ali Furkan and Tito, Rubèn and Mafla, Andrés and Gomez, Lluis and Rusiñol, Marçal and Jawahar, C.V. and Valveny, Ernest and Karatzas, Dimosthenis},
  booktitle={2019 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Scene Text Visual Question Answering}, 
  year={2019},
  volume={},
  number={},
  pages={4290-4300},
  keywords={Visualization;Task analysis;Knowledge discovery;Text recognition;Cognition;Computer vision;Semantics},
  doi={10.1109/ICCV.2019.00439}}

@inproceedings{welbl-etal-2021-challenges-detoxifying,
    title = "Challenges in Detoxifying Language Models",
    author = "Welbl, Johannes  and
      Glaese, Amelia  and
      Uesato, Jonathan  and
      Dathathri, Sumanth  and
      Mellor, John  and
      Hendricks, Lisa Anne  and
      Anderson, Kirsty  and
      Kohli, Pushmeet  and
      Coppin, Ben  and
      Huang, Po-Sen",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-emnlp.210",
    doi = "10.18653/v1/2021.findings-emnlp.210",
    pages = "2447--2469",
    abstract = "Large language models (LM) generate remarkably fluent text and can be efficiently adapted across NLP tasks. Measuring and guaranteeing the quality of generated text in terms of safety is imperative for deploying LMs in the real world; to this end, prior work often relies on automatic evaluation of LM toxicity. We critically discuss this approach, evaluate several toxicity mitigation strategies with respect to both automatic and human evaluation, and analyze consequences of toxicity mitigation in terms of model bias and LM quality. We demonstrate that while basic intervention strategies can effectively optimize previously established automatic metrics on the REALTOXICITYPROMPTS dataset, this comes at the cost of reduced LM coverage for both texts about, and dialects of, marginalized groups. Additionally, we find that human raters often disagree with high automatic toxicity scores after strong toxicity reduction interventions{---}highlighting further the nuances involved in careful evaluation of LM toxicity.",
}

@article{gopher,
  author    = {Jack W. Rae and
               Sebastian Borgeaud and
               Trevor Cai and
               Katie Millican and
               Jordan Hoffmann and
               H. Francis Song and
               John Aslanides and
               Sarah Henderson and
               Roman Ring and
               Susannah Young and
               Eliza Rutherford and
               Tom Hennigan and
               Jacob Menick and
               Albin Cassirer and
               Richard Powell and
               George van den Driessche and
               Lisa Anne Hendricks and
               Maribeth Rauh and
               Po{-}Sen Huang and
               Amelia Glaese and
               Johannes Welbl and
               Sumanth Dathathri and
               Saffron Huang and
               Jonathan Uesato and
               John Mellor and
               Irina Higgins and
               Antonia Creswell and
               Nat McAleese and
               Amy Wu and
               Erich Elsen and
               Siddhant M. Jayakumar and
               Elena Buchatskaya and
               David Budden and
               Esme Sutherland and
               Karen Simonyan and
               Michela Paganini and
               Laurent Sifre and
               Lena Martens and
               Xiang Lorraine Li and
               Adhiguna Kuncoro and
               Aida Nematzadeh and
               Elena Gribovskaya and
               Domenic Donato and
               Angeliki Lazaridou and
               Arthur Mensch and
               Jean{-}Baptiste Lespiau and
               Maria Tsimpoukelli and
               Nikolai Grigorev and
               Doug Fritz and
               Thibault Sottiaux and
               Mantas Pajarskas and
               Toby Pohlen and
               Zhitao Gong and
               Daniel Toyama and
               Cyprien de Masson d'Autume and
               Yujia Li and
               Tayfun Terzi and
               Vladimir Mikulik and
               Igor Babuschkin and
               Aidan Clark and
               Diego de Las Casas and
               Aurelia Guy and
               Chris Jones and
               James Bradbury and
               Matthew Johnson and
               Blake A. Hechtman and
               Laura Weidinger and
               Iason Gabriel and
               William S. Isaac and
               Edward Lockhart and
               Simon Osindero and
               Laura Rimell and
               Chris Dyer and
               Oriol Vinyals and
               Kareem Ayoub and
               Jeff Stanway and
               Lorrayne Bennett and
               Demis Hassabis and
               Koray Kavukcuoglu and
               Geoffrey Irving},
  title     = {Scaling Language Models: Methods, Analysis {\&} Insights from
               Training {Gopher}},
  journal   = {CoRR},
  volume    = {abs/2112.11446},
  year      = {2021}
}

@misc{gehman2020realtoxicityprompts,
      title={RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models}, 
      author={Samuel Gehman and Suchin Gururangan and Maarten Sap and Yejin Choi and Noah A. Smith},
      year={2020},
      eprint={2009.11462},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{xu2021gspmd,
  title={{GSPMD}: general and scalable parallelization for ML computation graphs},
  author={Xu, Yuanzhong and Lee, HyoukJoong and Chen, Dehao and Hechtman, Blake and Huang, Yanping and Joshi, Rahul and Krikun, Maxim and Lepikhin, Dmitry and Ly, Andy and Maggioni, Marcello and 
  Pang, Ruoming and Shazeer, Noam  and Wang, Shibo and Wang, Tao and Wu, Yonghui  and Chen,Zhifeng},
  journal={arXiv preprint arXiv:2105.04663},
  year={2021}
}

@article{isard2022pathways,
title={Pathways: Asynchronous Distributed Dataflow for {ML}},
author={
Barham, Paul and Chowdhery, Aakanksha and Dean, Jeff and Ghemawat, Sanjay and Hand, Steven and Hurt, Dan and Isard, Michael and Lim, Hyeontaek and Pang, Ruoming and Roy, Sudip and Saeta, Brennan and Schuh, Parker and Sepassi, Ryan and Shafey, Laurent El and Thekkath, Chandramohan A. and Wu, Yonghui 
},
journal={To appear in MLSys 2022},
url = "https://arxiv.org/abs/2203.12533",
year={2022}
}

@article{chinchilla,
  title={Training Compute-Optimal Large Language Models},
   author = {Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and Hennigan, Tom and Noland, Eric and Millican, Katie and Driessche, George van den and Damoc, Bogdan and Guy, Aurelia and Osindero, Simon and Simonyan, Karen and Elsen, Erich and Rae, Jack W. and Vinyals, Oriol and Sifre, Laurent},
  journal={arXiv preprint arXiv:2203.15556},
  URL="https://arxiv.org/abs/2203.15556",
  year={2022}
}
  
 

@inproceedings{toral-etal-2019-neural,
    title = "Neural Machine Translation for {E}nglish{--}{K}azakh with Morphological Segmentation and Synthetic Data",
    author = "Toral, Antonio  and
      Edman, Lukas  and
      Yeshmagambetova, Galiya  and
      Spenader, Jennifer",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W19-5343",
    doi = "10.18653/v1/W19-5343",
    pages = "386--392",
    abstract = "This paper presents the systems submitted by the University of Groningen to the English{--} Kazakh language pair (both translation directions) for the WMT 2019 news translation task. We explore the potential benefits of (i) morphological segmentation (both unsupervised and rule-based), given the agglutinative nature of Kazakh, (ii) data from two additional languages (Turkish and Russian), given the scarcity of English{--}Kazakh data and (iii) synthetic data, both for the source and for the target language. Our best submissions ranked second for Kazakh→English and third for English→Kazakh in terms of the BLEU automatic evaluation metric.",
}

@inproceedings{li-etal-2019-niutrans,
    title = "The {N}iu{T}rans Machine Translation Systems for {WMT}19",
    author = "Li, Bei  and
      Li, Yinqiao  and
      Xu, Chen  and
      Lin, Ye  and
      Liu, Jiqiang  and
      Liu, Hui  and
      Wang, Ziyang  and
      Zhang, Yuhao  and
      Xu, Nuo  and
      Wang, Zeyang  and
      Feng, Kai  and
      Chen, Hexuan  and
      Liu, Tengbo  and
      Li, Yanyang  and
      Wang, Qiang  and
      Xiao, Tong  and
      Zhu, Jingbo",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W19-5325",
    doi = "10.18653/v1/W19-5325",
    pages = "257--266",
    abstract = "This paper described NiuTrans neural machine translation systems for the WMT 2019 news translation tasks. We participated in 13 translation directions, including 11 supervised tasks, namely EN↔{ZH, DE, RU, KK, LT}, GU→EN and the unsupervised DE↔CS sub-track. Our systems were built on Deep Transformer and several back-translation methods. Iterative knowledge distillation and ensemble+reranking were also employed to obtain stronger models. Our unsupervised submissions were based on NMT enhanced by SMT. As a result, we achieved the highest BLEU scores in {KK↔EN, GU→EN} directions, ranking 2nd in {RU→EN, DE↔CS} and 3rd in {ZH→EN, LT→EN, EN→RU, EN↔DE} among all constrained submissions.",
}

@inproceedings{xia-etal-2019-microsoft,
    title = "{M}icrosoft {R}esearch {A}sia{'}s Systems for {WMT}19",
    author = "Xia, Yingce  and
      Tan, Xu  and
      Tian, Fei  and
      Gao, Fei  and
      He, Di  and
      Chen, Weicong  and
      Fan, Yang  and
      Gong, Linyuan  and
      Leng, Yichong  and
      Luo, Renqian  and
      Wang, Yiren  and
      Wu, Lijun  and
      Zhu, Jinhua  and
      Qin, Tao  and
      Liu, Tie-Yan",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W19-5348",
    doi = "10.18653/v1/W19-5348",
    pages = "424--433",
    abstract = "We Microsoft Research Asia made submissions to 11 language directions in the WMT19 news translation tasks. We won the first place for 8 of the 11 directions and the second place for the other three. Our basic systems are built on Transformer, back translation and knowledge distillation. We integrate several of our rececent techniques to enhance the baseline systems: multi-agent dual learning (MADL), masked sequence-to-sequence pre-training (MASS), neural architecture optimization (NAO), and soft contextual data augmentation (SCA).",
}

@article{DBLP:journals/corr/abs-1908-06938,
  author    = {Zachary M. Ziegler and
               Luke Melas{-}Kyriazi and
               Sebastian Gehrmann and
               Alexander M. Rush},
  title     = {Encoder-Agnostic Adaptation for Conditional Language Generation},
  journal   = {CoRR},
  volume    = {abs/1908.06938},
  year      = {2019},
  url       = {http://arxiv.org/abs/1908.06938},
  eprinttype = {arXiv},
  eprint    = {1908.06938},
  timestamp = {Mon, 26 Aug 2019 13:20:40 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1908-06938.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ladhak2020wikilingua,
    title = "{W}iki{L}ingua: A New Benchmark Dataset for Cross-Lingual Abstractive Summarization",
    author = "Ladhak, Faisal  and
      Durmus, Esin  and
      Cardie, Claire  and
      McKeown, Kathleen",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.findings-emnlp.360",
    doi = "10.18653/v1/2020.findings-emnlp.360",
    pages = "4034--4048",
}

@inproceedings{scialom2020mlsum,
    title = "{MLSUM}: The Multilingual Summarization Corpus",
    author = "Scialom, Thomas  and
      Dray, Paul-Alexis  and
      Lamprier, Sylvain  and
      Piwowarski, Benjamin  and
      Staiano, Jacopo",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.647",
    doi = "10.18653/v1/2020.emnlp-main.647",
    pages = "8051--8067",
    abstract = "We present MLSUM, the first large-scale MultiLingual SUMmarization dataset. Obtained from online newspapers, it contains 1.5M+ article/summary pairs in five different languages {--} namely, French, German, Spanish, Russian, Turkish. Together with English news articles from the popular CNN/Daily mail dataset, the collected data form a large scale multilingual dataset which can enable new research directions for the text summarization community. We report cross-lingual comparative analyses based on state-of-the-art systems. These highlight existing biases which motivate the use of a multi-lingual dataset.",
}


@inproceedings{cs_restaurants,
	address = {Tokyo, Japan},
	title = {Neural {Generation} for {Czech}: {Data} and {Baselines}},
	shorttitle = {Neural {Generation} for {Czech}},
	url = {https://www.aclweb.org/anthology/W19-8670/},
	urldate = {2019-10-18},
	booktitle = {Proceedings of the 12th {International} {Conference} on {Natural} {Language} {Generation} ({INLG} 2019)},
	author = {Dušek, Ondřej and Jurčíček, Filip},
	month = oct,
	year = {2019},
	pages = {563--574},
}

@inproceedings{e2e_cleaned,
	address = {Tokyo, Japan},
	title = {Semantic {Noise} {Matters} for {Neural} {Natural} {Language} {Generation}},
	url = {https://www.aclweb.org/anthology/W19-8652/},
	booktitle = {Proceedings of the 12th {International} {Conference} on {Natural} {Language} {Generation} ({INLG} 2019)},
	author = {Dušek, Ondřej and Howcroft, David M and Rieser, Verena},
	year = {2019},
	pages = {421--426},
}

@inproceedings{novikova-etal-2017-e2e,
    title = "The {E}2{E} Dataset: New Challenges For End-to-End Generation",
    author = "Novikova, Jekaterina  and
      Du{\v{s}}ek, Ond{\v{r}}ej  and
      Rieser, Verena",
    booktitle = "Proceedings of the 18th Annual {SIG}dial Meeting on Discourse and Dialogue",
    month = aug,
    year = "2017",
    address = {Saarbr{\"u}cken, Germany},
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W17-5525",
    doi = "10.18653/v1/W17-5525",
    pages = "201--206",
    abstract = "This paper describes the E2E data, a new dataset for training end-to-end, data-driven natural language generation systems in the restaurant domain, which is ten times bigger than existing, frequently used datasets in this area. The E2E dataset poses new challenges: (1) its human reference texts show more lexical richness and syntactic variation, including discourse phenomena; (2) generating from this set requires content selection. As such, learning from this dataset promises more natural, varied and less template-like system utterances. We also establish a baseline on this dataset, which illustrates some of the difficulties associated with this data.",
}

@inproceedings{gardent2017creating,
  author = 	"Gardent, Claire
		and Shimorina, Anastasia
		and Narayan, Shashi
		and Perez-Beltrachini, Laura",
  title = 	"Creating Training Corpora for NLG Micro-Planners",
  booktitle = 	"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  year = 	"2017",
  publisher = 	"Association for Computational Linguistics",
  pages = 	"179--188",
  location = 	"Vancouver, Canada",
  doi = 	"10.18653/v1/P17-1017",
  url = 	"http://www.aclweb.org/anthology/P17-1017"
}

@inproceedings{castro-ferreira20:bilin-bi-direc-webnl-shared,
  title={The 2020 Bilingual, Bi-Directional WebNLG+ Shared Task Overview and Evaluation Results (WebNLG+ 2020)},
  author={Castro Ferreira, Thiago and
                  Gardent, Claire and
		  Ilinykh, Nikolai and
		  van der Lee, Chris and
		  Mille, Simon and
		  Moussallem, Diego and
		  Shimorina, Anastasia},
  booktitle = {Proceedings of the 3rd WebNLG Workshop on Natural Language Generation from the Semantic Web (WebNLG+ 2020)},
    pages = "55--76",
  year = 	 2020,
  address = 	 {Dublin, Ireland (Virtual)},
  publisher = {Association for Computational Linguistics}}
  
@inproceedings{joshi-etal-2020-state,
    title = "The State and Fate of Linguistic Diversity and Inclusion in the {NLP} World",
    author = "Joshi, Pratik  and
      Santy, Sebastin  and
      Budhiraja, Amar  and
      Bali, Kalika  and
      Choudhury, Monojit",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.560",
    doi = "10.18653/v1/2020.acl-main.560",
    pages = "6282--6293",
    abstract = "Language technologies contribute to promoting multilingualism and linguistic diversity around the world. However, only a very small number of the over 7000 languages of the world are represented in the rapidly evolving language technologies and applications. In this paper we look at the relation between the types of languages, resources, and their representation in NLP conferences to understand the trajectory that different languages have followed over time. Our quantitative investigation underlines the disparity between languages, especially in terms of their resources, and calls into question the {``}language agnostic{''} status of current models and systems. Through this paper, we attempt to convince the ACL community to prioritise the resolution of the predicaments highlighted here, so that no language is left behind.",
}

@article{DBLP:journals/corr/abs-2202-06935,
  author    = {Sebastian Gehrmann and
               Elizabeth Clark and
               Thibault Sellam},
  title     = {Repairing the Cracked Foundation: {A} Survey of Obstacles in Evaluation
               Practices for Generated Text},
  journal   = {CoRR},
  volume    = {abs/2202.06935},
  year      = {2022},
  url       = {https://arxiv.org/abs/2202.06935},
  eprinttype = {arXiv},
  eprint    = {2202.06935},
  timestamp = {Fri, 18 Feb 2022 12:23:53 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2202-06935.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/emnlp/PuCPGS21,
  author    = {Amy Pu and
               Hyung Won Chung and
               Ankur P. Parikh and
               Sebastian Gehrmann and
               Thibault Sellam},
  editor    = {Marie{-}Francine Moens and
               Xuanjing Huang and
               Lucia Specia and
               Scott Wen{-}tau Yih},
  title     = {Learning Compact Metrics for {MT}},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2021, Virtual Event / Punta Cana, Dominican
               Republic, 7-11 November, 2021},
  pages     = {751--762},
  publisher = {Association for Computational Linguistics},
  year      = {2021},
  url       = {https://doi.org/10.18653/v1/2021.emnlp-main.58},
  doi       = {10.18653/v1/2021.emnlp-main.58},
  timestamp = {Thu, 20 Jan 2022 10:02:15 +0100},
  biburl    = {https://dblp.org/rec/conf/emnlp/PuCPGS21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{tydiqa,
title	= {TyDi{QA}: A Benchmark for Information-Seeking Question Answering in Typologically Diverse Languages},
author	= {Jon Clark and Eunsol Choi and Michael Collins and Dan Garrette and Tom Kwiatkowski and Vitaly Nikolaev and Jennimaria Palomaki},
year	= {2020},
URL	= {https://storage.googleapis.com/tydiqa/tydiqa.pdf},
journal	= {Transactions of the Association for Computational Linguistics}
}


@article{nie2019adversarial,
  title={Adversarial NLI: A new benchmark for natural language understanding},
  author={Nie, Yixin and Williams, Adina and Dinan, Emily and Bansal, Mohit and Weston, Jason and Kiela, Douwe},
  journal={arXiv preprint arXiv:1910.14599},
  year={2019}
}

@inproceedings{superglue,
 author = {Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems},
 url = {https://proceedings.neurips.cc/paper/2019/file/4496bf24afe7fab6f046bf4923da8de6-Paper.pdf},
 volume = {32},
 year = {2019}
}

@inproceedings{dua-etal-2019-drop,
    title = "{DROP}: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs",
    author = "Dua, Dheeru  and
      Wang, Yizhong  and
      Dasigi, Pradeep  and
      Stanovsky, Gabriel  and
      Singh, Sameer  and
      Gardner, Matt",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1246",
    doi = "10.18653/v1/N19-1246",
    pages = "2368--2378",
    abstract = "Reading comprehension has recently seen rapid progress, with systems matching humans on the most popular datasets for the task. However, a large body of work has highlighted the brittleness of these systems, showing that there is much work left to be done. We introduce a new reading comprehension benchmark, DROP, which requires Discrete Reasoning Over the content of Paragraphs. In this crowdsourced, adversarially-created, 55k-question benchmark, a system must resolve references in a question, perhaps to multiple input positions, and perform discrete operations over them (such as addition, counting, or sorting). These operations require a much more comprehensive understanding of the content of paragraphs, as they remove the paraphrase-and-entity-typing shortcuts available in prior datasets. We apply state-of-the-art methods from both the reading comprehension and semantic parsing literatures on this dataset and show that the best systems only achieve 38.4{\%} F1 on our generalized accuracy metric, while expert human performance is 96{\%}. We additionally present a new model that combines reading comprehension methods with simple numerical reasoning to achieve 51{\%} F1.",
}

@article{reddy2018coqa,
  author    = {Siva Reddy and
               Danqi Chen and
               Christopher D. Manning},
  title     = {CoQA: {A} Conversational Question Answering Challenge},
  journal   = {CoRR},
  volume    = {abs/1808.07042},
  year      = {2018},
  url       = {http://arxiv.org/abs/1808.07042},
  eprinttype = {arXiv},
  eprint    = {1808.07042},
  timestamp = {Sun, 02 Sep 2018 15:01:56 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1808-07042.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{choi2018quac,
  author    = {Eunsol Choi and
               He He and
               Mohit Iyyer and
               Mark Yatskar and
               Wen{-}tau Yih and
               Yejin Choi and
               Percy Liang and
               Luke Zettlemoyer},
  title     = {Qu{AC} : Question Answering in Context},
  journal   = {CoRR},
  volume    = {abs/1808.07036},
  year      = {2018},
  url       = {http://arxiv.org/abs/1808.07036},
  eprinttype = {arXiv},
  eprint    = {1808.07036},
  timestamp = {Tue, 09 Feb 2021 15:29:35 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1808-07036.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{lai-etal-2017-race,
    title = "{RACE}: Large-scale {R}e{A}ding Comprehension Dataset From Examinations",
    author = "Lai, Guokun  and
      Xie, Qizhe  and
      Liu, Hanxiao  and
      Yang, Yiming  and
      Hovy, Eduard",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D17-1082",
    doi = "10.18653/v1/D17-1082",
    pages = "785--794",
    abstract = "We present RACE, a new dataset for benchmark evaluation of methods in the reading comprehension task. Collected from the English exams for middle and high school Chinese students in the age range between 12 to 18, RACE consists of near 28,000 passages and near 100,000 questions generated by human experts (English instructors), and covers a variety of topics which are carefully designed for evaluating the students{'} ability in understanding and reasoning. In particular, the proportion of questions that requires reasoning is much larger in RACE than that in other benchmark datasets for reading comprehension, and there is a significant gap between the performance of the state-of-the-art models (43{\%}) and the ceiling human performance (95{\%}). We hope this new dataset can serve as a valuable resource for research and evaluation in machine comprehension. The dataset is freely available at \url{http://www.cs.cmu.edu/~glai1/data/race/}and the code is available at \url{https://github.com/qizhex/RACE_AR_baselines}.",
}

@article{bisk2019piqa,
  author    = {Yonatan Bisk and
               Rowan Zellers and
               Ronan Le Bras and
               Jianfeng Gao and
               Yejin Choi},
  title     = {{PIQA:} Reasoning about Physical Commonsense in Natural Language},
  journal   = {CoRR},
  volume    = {abs/1911.11641},
  year      = {2019},
  url       = {http://arxiv.org/abs/1911.11641},
  eprinttype = {arXiv},
  eprint    = {1911.11641},
  timestamp = {Tue, 03 Dec 2019 20:41:07 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1911-11641.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Clark2018ARC,
  title={Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge},
  author={Peter Clark and Isaac Cowhey and Oren Etzioni and Tushar Khot and Ashish Sabharwal and Carissa Schoenick and Oyvind Tafjord},
  journal={ArXiv},
  year={2018},
  volume={abs/1803.05457}
}

@article{paperno2016lambada,
  title={The {LAMBADA} dataset: Word prediction requiring a broad discourse context},
  author={Paperno, Denis and Kruszewski, Germ{\'a}n and Lazaridou, Angeliki and Pham, Quan Ngoc and Bernardi, Raffaella and Pezzelle, Sandro and Baroni, Marco and Boleda, Gemma and Fern{\'a}ndez, Raquel},
  journal={arXiv preprint arXiv:1606.06031},
  year={2016}
}

@inproceedings{mostafazadeh2016storycloze,
  title={A corpus and cloze evaluation for deeper understanding of commonsense stories},
  author={Mostafazadeh, Nasrin and Chambers, Nathanael and He, Xiaodong and Parikh, Devi and Batra, Dhruv and Vanderwende, Lucy and Kohli, Pushmeet and Allen, James},
  booktitle={Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={839--849},
  year={2016}
}

@article{zellers2019hellaswag,
  title={HellaSwag: Can a machine really finish your sentence?},
  author={Zellers, Rowan and Holtzman, Ari and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
  journal={arXiv preprint arXiv:1905.07830},
  year={2019}
}

@article{joshi2017triviaqa,
  title={Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension},
  author={Joshi, Mandar and Choi, Eunsol and Weld, Daniel S and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1705.03551},
  year={2017}
}

@inproceedings{berant2013semantic,
  title={Semantic parsing on freebase from question-answer pairs},
  author={Berant, Jonathan and Chou, Andrew and Frostig, Roy and Liang, Percy},
  booktitle={Proceedings of the 2013 conference on empirical methods in natural language processing},
  pages={1533--1544},
  year={2013}
}


@INPROCEEDINGS{Allamanis2019duplication,
  title     = "The Adverse Effects of Code Duplication in Machine Learning
               Models of Code",
  booktitle = "{SPLASH} Onward!",
  author    = "Allamanis, Miltiadis",
  abstract  = "The field of big code relies on mining large corpora of code to
               perform some learning task. A significant threat to this
               approach has been recently identified by Lopes et al. (2017) who
               found a large amount of near-duplicate code on GitHub. However,
               the impact of code duplication has not been noticed by
               researchers devising machine learning models for source code. In
               this work, we explore the effects of code duplication on machine
               learning models showing that reported performance metrics are
               sometimes inflated by up to 100\% when testing on duplicated
               code corpora compared to the performance on de-duplicated
               corpora which more accurately represent how machine learning
               models of code are used by software engineers. We present a
               duplication index for widely used datasets, list best practices
               for collecting code corpora and evaluating machine learning
               models on them. Finally, we release tools to help the community
               avoid this problem in future research.",
  year      =  2019
}

@inproceedings{Dusek2019NeuralGF,
  title={Neural Generation for Czech: Data and Baselines},
  author={Ondrej Dusek and Filip Jurvc'ivcek},
  year={2019}
}

@ARTICLE{Lopes2017duplication,
  title     = "{D{\'e}j{\`a}Vu}: a map of code duplicates on {GitHub}",
  author    = "Lopes, Cristina V and Maj, Petr and Martins, Pedro and Saini,
               Vaibhav and Yang, Di and Zitny, Jakub and Sajnani, Hitesh and
               Vitek, Jan",
  abstract  = "Previous studies have shown that there is a non-trivial amount
               of duplication in source code. This paper analyzes a corpus of
               4.5 million non-fork projects hosted on GitHub representing over
               428 million files written in Java, C++, Python, and JavaScript.
               We found that this corpus has a mere 85 million unique files. In
               other words, 70\% of the code on GitHub consists of clones of
               previously created files. There is considerable variation
               between language ecosystems. JavaScript has the highest rate of
               file duplication, only 6\% of the files are distinct. Java, on
               the other hand, has the least duplication, 60\% of files are
               distinct. Lastly, a project-level analysis shows that between
               9\% and 31\% of the projects contain at least 80\% of files that
               can be found elsewhere. These rates of duplication have
               implications for systems built on open source software as well
               as for researchers interested in analyzing large code bases. As
               a concrete artifact of this study, we have created
               D{\'e}j{\`a}Vu, a publicly available map of code duplicates in
               GitHub repositories.",
  journal   = "Proc. ACM Program. Lang.",
  publisher = "Association for Computing Machinery",
  volume    =  1,
  number    = "OOPSLA",
  pages     = "1--28",
  month     =  oct,
  year      =  2017,
  address   = "New York, NY, USA",
  keywords  = "Clone Detection, Source Code Analysis"
}


@INPROCEEDINGS{SPOC,
  title     = "{SPoC}: Search-based Pseudocode to Code",
  booktitle = "Advances in Neural Information Processing Systems",
  author    = "Kulal, Sumith and Pasupat, Panupong and Chandra, Kartik and Lee,
               Mina and Padon, Oded and Aiken, Alex and Liang, Percy",
  abstract  = "We consider the task of mapping pseudocode to long programs that
               are functionally correct. Given test cases as a mechanism to
               validate programs, we search over the space of possible
               translations of the pseudocode to find a program that passes the
               validation. However, without proper credit assignment to
               localize the sources of program failures, it is difficult to
               guide search toward more promising programs. We propose to
               perform credit assignment based on signals from compilation
               errors, which constitute 88.7\% of program failures. Concretely,
               we treat the translation of each pseudocode line as a discrete
               portion of the program, and whenever a synthesized program fails
               to compile, an error localization method tries to identify the
               portion of the program responsible for the failure. We then
               focus search over alternative translations of the pseudocode for
               those portions. For evaluation, we collected the SPoC dataset
               (Search-based Pseudocode to Code) containing 18,356 programs
               with human-authored pseudocode and test cases. Under a budget of
               100 program compilations, performing search improves the
               synthesis success rate over using the top-one translation of the
               pseudocode from 25.6\% to 44.7\%.",
  month     =  jun,
  year      =  2019
}

@inproceedings{li-liang-2021-prefix,
    title = "Prefix-Tuning: Optimizing Continuous Prompts for Generation",
    author = "Li, Xiang Lisa  and
      Liang, Percy",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.353",
    doi = "10.18653/v1/2021.acl-long.353",
    pages = "4582--4597",
    abstract = "Fine-tuning is the de facto way of leveraging large pretrained language models for downstream tasks. However, fine-tuning modifies all the language model parameters and therefore necessitates storing a full copy for each task. In this paper, we propose prefix-tuning, a lightweight alternative to fine-tuning for natural language generation tasks, which keeps language model parameters frozen and instead optimizes a sequence of continuous task-specific vectors, which we call the prefix. Prefix-tuning draws inspiration from prompting for language models, allowing subsequent tokens to attend to this prefix as if it were {``}virtual tokens{''}. We apply prefix-tuning to GPT-2 for table-to-text generation and to BART for summarization. We show that by learning only 0.1{\%} of the parameters, prefix-tuning obtains comparable performance in the full data setting, outperforms fine-tuning in low-data settings, and extrapolates better to examples with topics that are unseen during training.",
}

@article{sutskever2014sequence,
  title={Sequence to sequence learning with neural networks},
  author={Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{gebru2021datasheets,
author = {Gebru, Timnit and Morgenstern, Jamie and Vecchione, Briana and Vaughan, Jennifer Wortman and Wallach, Hanna and III, Hal Daum\'{e} and Crawford, Kate},
title = {Datasheets for Datasets},
year = {2021},
issue_date = {December 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {64},
number = {12},
issn = {0001-0782},
url = {https://doi.org/10.1145/3458723},
doi = {10.1145/3458723},
abstract = {Documentation to facilitate communication between dataset creators and consumers.},
journal = {Commun. ACM},
month = {nov},
pages = {86–92},
numpages = {7}
}
@article{webson_and_pavlick2021,
  author    = {Albert Webson and
               Ellie Pavlick},
  title     = {Do Prompt-Based Models Really Understand the Meaning of their Prompts?},
  journal   = {CoRR},
  volume    = {abs/2109.01247},
  year      = {2021},
  url       = {https://arxiv.org/abs/2109.01247},
  eprinttype = {arXiv},
  eprint    = {2109.01247},
  timestamp = {Mon, 20 Sep 2021 16:29:41 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2109-01247.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2105-13626,
  author    = {Linting Xue and
               Aditya Barua and
               Noah Constant and
               Rami Al{-}Rfou and
               Sharan Narang and
               Mihir Kale and
               Adam Roberts and
               Colin Raffel},
  title     = {{ByT5}: Towards a token-free future with pre-trained byte-to-byte models},
  journal   = {CoRR},
  volume    = {abs/2105.13626},
  year      = {2021},
  url       = {https://arxiv.org/abs/2105.13626},
  eprinttype = {arXiv},
  eprint    = {2105.13626},
  timestamp = {Tue, 01 Jun 2021 18:07:59 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2105-13626.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@inproceedings{caswell-etal-2019-tagged,
    title = "Tagged Back-Translation",
    author = "Caswell, Isaac  and
      Chelba, Ciprian  and
      Grangier, David",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 1: Research Papers)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W19-5206",
    doi = "10.18653/v1/W19-5206",
    pages = "53--63",
    abstract = "Recent work in Neural Machine Translation (NMT) has shown significant quality gains from noised-beam decoding during back-translation, a method to generate synthetic parallel data. We show that the main role of such synthetic noise is not to diversify the source side, as previously suggested, but simply to indicate to the model that the given source is synthetic. We propose a simpler alternative to noising techniques, consisting of tagging back-translated source sentences with an extra token. Our results on WMT outperform noised back-translation in English-Romanian and match performance on English-German, redefining the state-of-the-art on the former.",
}

@article{liu2020multilingual,
  title={Multilingual denoising pre-training for neural machine translation},
  author={Liu, Yinhan and Gu, Jiatao and Goyal, Naman and Li, Xian and Edunov, Sergey and Ghazvininejad, Marjan and Lewis, Mike and Zettlemoyer, Luke},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={726--742},
  year={2020},
  publisher={MIT Press}
}

@inproceedings{dixon2018bias,
author = {Dixon, Lucas and Li, John and Sorensen, Jeffrey and Thain, Nithum and Vasserman, Lucy},
title = {Measuring and Mitigating Unintended Bias in Text Classification},
year = {2018},
isbn = {9781450360128},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3278721.3278729},
doi = {10.1145/3278721.3278729},
booktitle = {Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {67–73},
numpages = {7},
keywords = {natural language processing, text classification, fairness, algorithmic bias, machine learning},
location = {New Orleans, LA, USA},
series = {AIES '18}
}

@inproceedings{rottger-etal-2021-hatecheck,
    title = "{H}ate{C}heck: Functional Tests for Hate Speech Detection Models",
    author = {R{\"o}ttger, Paul  and
      Vidgen, Bertie  and
      Nguyen, Dong  and
      Waseem, Zeerak  and
      Margetts, Helen  and
      Pierrehumbert, Janet},
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.4",
    doi = "10.18653/v1/2021.acl-long.4",
    pages = "41--58",
}

@inproceedings{lin-2004-rouge,
    title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    booktitle = "Text Summarization Branches Out",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W04-1013",
    pages = "74--81",
}

@article{geirhos2020a,
  author = "R. Geirhos and J.-H. Jacobsen and C. Michaelis and R. Zemel and W. Brendel and M. Bethge and F. A. Wichmann",
  title = "Shortcut Learning in Deep Neural Networks",
  year = 2020,
  journal = "Nature Machine Intelligence",
  volume = 2,
  pages = "665-673",
  month = "Nov",
  doi = "https://doi.org/10.1038/s42256-020-00257-z",
  url = "https://www.nature.com/articles/s42256-020-00257-z"
}


@inbook{barocasguoetal2021,
author = {Barocas, Solon and Guo, Anhong and Kamar, Ece and Krones, Jacquelyn and Morris, Meredith Ringel and Vaughan, Jennifer Wortman and Wadsworth, W. Duncan and Wallach, Hanna},
title = {Designing Disaggregated Evaluations of AI Systems: Choices, Considerations, and Tradeoffs},
year = {2021},
isbn = {9781450384735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461702.3462610},
abstract = {Disaggregated evaluations of AI systems, in which system performance is assessed and reported separately for different groups of people, are conceptually simple. However, their design involves a variety of choices. Some of these choices influence the results that will be obtained, and thus the conclusions that can be drawn; others influence the impacts---both beneficial and harmful---that a disaggregated evaluation will have on people, including the people whose data is used to conduct the evaluation. We argue that a deeper understanding of these choices will enable researchers and practitioners to design careful and conclusive disaggregated evaluations. We also argue that better documentation of these choices, along with the underlying considerations and tradeoffs that have been made, will help others when interpreting an evaluation's results and conclusions.},
booktitle = {Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {368–378},
numpages = {11}
}

@article{kandpal2022dedup,
  author    = {Nikhil Kandpal and Eric Wallace and Colin Raffel},
  title     = {Deduplicating Training Data Mitigates Privacy Risks in Language Models},
  year      = {2022},
  url       = {https://arxiv.org/abs/2202.06539},
  eprinttype = {arXiv},
  eprint    = {2202.06539},
}

@article{lee2021dedup,
  author    = {Katherine Lee and Daphne Ippolito and Andrew Nystrom and Chiyuan Zhang and Douglas Eck and Chris Callison-Burch and Nicholas Carlini},
  title     = {Deduplicating Training Data Makes Language Models Better},
  year      = {2021},
  url       = {https://arxiv.org/abs/2107.06499},
  eprinttype = {arXiv},
  eprint    = {2107.06499},
}

@article{sue2006invisible,
  title={The Invisible Whiteness of Being: Whiteness, White Supremacy, White Privilege, and Racism.},
  author={Sue, Derald Wing},
  year={2006},
  publisher={John Wiley \& Sons, Inc.}
}

@article{DBLP:journals/corr/abs-2010-10239,
  author    = {Markus Freitag and
               Orhan Firat},
  title     = {Complete Multilingual Neural Machine Translation},
  journal   = {CoRR},
  volume    = {abs/2010.10239},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.10239},
  eprinttype = {arXiv},
  eprint    = {2010.10239},
  timestamp = {Mon, 26 Oct 2020 15:39:44 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-10239.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2010-11125,
  author    = {Angela Fan and
               Shruti Bhosale and
               Holger Schwenk and
               Zhiyi Ma and
               Ahmed El{-}Kishky and
               Siddharth Goyal and
               Mandeep Baines and
               Onur Celebi and
               Guillaume Wenzek and
               Vishrav Chaudhary and
               Naman Goyal and
               Tom Birch and
               Vitaliy Liptchinsky and
               Sergey Edunov and
               Edouard Grave and
               Michael Auli and
               Armand Joulin},
  title     = {Beyond English-Centric Multilingual Machine Translation},
  journal   = {CoRR},
  volume    = {abs/2010.11125},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.11125},
  eprinttype = {arXiv},
  eprint    = {2010.11125},
  timestamp = {Mon, 26 Oct 2020 15:39:44 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-11125.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@software{gcloud_classifier,
  author = {{Google Cloud NLP}},
  title = {Google Cloud Classifying Content},
  url = {https://cloud.google.com/natural-language/docs/classifying-text},
  date = {2020-03-30},
}

@software{gcloud_info,
  author = {{Google Cloud NLP}},
  title = {Google Cloud InfoType Detector},
  url = {https://cloud.google.com/dlp/docs/infotypes-reference},
  date = {2020-03-30},
}


@misc{2021pathwaysarchitecture,
    author = {Jeff Dean},
  title = {{I}ntroducing {P}athways: {A} next-generation {AI} architecture},
  url = "{https://blog.google/technology/ai/introducing-pathways-next-generation-ai-architecture/}",
  year = {2021},
  }
  

@inproceedings{lin-etal-2020-pre,
    title = "Pre-training Multilingual Neural Machine Translation by Leveraging Alignment Information",
    author = "Lin, Zehui  and
      Pan, Xiao  and
      Wang, Mingxuan  and
      Qiu, Xipeng  and
      Feng, Jiangtao  and
      Zhou, Hao  and
      Li, Lei",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.210",
    doi = "10.18653/v1/2020.emnlp-main.210",
    pages = "2649--2663",
    abstract = "We investigate the following question for machine translation (MT): can we develop a single universal MT model to serve as the common seed and obtain derivative and improved models on arbitrary language pairs? We propose mRASP, an approach to pre-train a universal multilingual neural machine translation model. Our key idea in mRASP is its novel technique of random aligned substitution, which brings words and phrases with similar meanings across multiple languages closer in the representation space. We pre-train a mRASP model on 32 language pairs jointly with only public datasets. The model is then fine-tuned on downstream language pairs to obtain specialized MT models. We carry out extensive experiments on 42 translation directions across a diverse settings, including low, medium, rich resource, and as well as transferring to exotic language pairs. Experimental results demonstrate that mRASP achieves significant performance improvement compared to directly training on those target pairs. It is the first time to verify that multiple lowresource language pairs can be utilized to improve rich resource MT. Surprisingly, mRASP is even able to improve the translation quality on exotic languages that never occur in the pretraining corpus. Code, data, and pre-trained models are available at https://github. com/linzehui/mRASP.",
}

@inproceedings{Xue2021mT5AM,
  title={{mT5}: A Massively Multilingual Pre-trained Text-to-Text Transformer},
  author={Linting Xue and Noah Constant and Adam Roberts and Mihir Kale and Rami Al-Rfou and Aditya Siddhant and Aditya Barua and Colin Raffel},
  booktitle={NAACL},
  year={2021}
}
@inproceedings{bakshi-etal-2021-structure,
    title = "Structure-to-Text Generation with Self-Training, Acceptability Classifiers and Context-Conditioning for the {GEM} Shared Task",
    author = "Bakshi, Shreyan  and
      Batra, Soumya  and
      Heidari, Peyman  and
      Arun, Ankit  and
      Jain, Shashank  and
      White, Michael",
    booktitle = "Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.gem-1.12",
    doi = "10.18653/v1/2021.gem-1.12",
    pages = "136--147",
    abstract = "We explore the use of self-training and acceptability classifiers with pre-trained models for natural language generation in structure-to-text settings using three GEM datasets (E2E, WebNLG-en, Schema-Guided Dialog). With the Schema-Guided Dialog dataset, we also experiment with including multiple turns of context in the input. We find that self-training with reconstruction matching along with acceptability classifier filtering can improve semantic correctness, though gains are limited in the full-data setting. With context-conditioning, we find that including multiple turns in the context encourages the model to align with the user{'}s word and phrasing choices as well as to generate more self-consistent responses. In future versions of the GEM challenge, we encourage the inclusion of few-shot tracks to encourage research on data efficiency.",
}

@inproceedings{siddhant2020evaluating,
  title={Evaluating the cross-lingual effectiveness of massively multilingual neural machine translation},
  author={Siddhant, Aditya and Johnson, Melvin and Tsai, Henry and Ari, Naveen and Riesa, Jason and Bapna, Ankur and Firat, Orhan and Raman, Karthik},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={05},
  pages={8854--8861},
  year={2020}
}

 @misc{know_your_data, url={https://knowyourdata.withgoogle.com/}, author={{Know Your Data}}, publisher={Google}} 
 
 @article{abidfarooqizuo2021,
  author    = {Abubakar Abid and
               Maheen Farooqi and
               James Zou},
  title     = {Persistent Anti-Muslim Bias in Large Language Models},
  journal   = {CoRR},
  volume    = {abs/2101.05783},
  year      = {2021},
  url       = {https://arxiv.org/abs/2101.05783},
  eprinttype = {arXiv},
  eprint    = {2101.05783},
  timestamp = {Fri, 22 Jan 2021 15:16:00 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2101-05783.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{deepfix,
  author    = {Rahul Gupta and
               Soham Pal and
               Aditya Kanade and
               Shirish K. Shevade},
  editor    = {Satinder P. Singh and
               Shaul Markovitch},
  title     = {DeepFix: Fixing Common {C} Language Errors by Deep Learning},
  booktitle = {Proceedings of the Thirty-First {AAAI} Conference on Artificial Intelligence,
               February 4-9, 2017, San Francisco, California, {USA}},
  pages     = {1345--1351},
  publisher = {{AAAI} Press},
  year      = {2017},
  url       = {http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14603},
  timestamp = {Wed, 10 Feb 2021 08:43:31 +0100},
  biburl    = {https://dblp.org/rec/conf/aaai/GuptaPKS17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{drrepair,
  author    = {Michihiro Yasunaga and
               Percy Liang},
  title     = {Graph-based, Self-Supervised Program Repair from Diagnostic Feedback},
  booktitle = {Proceedings of the 37th International Conference on Machine Learning,
               {ICML} 2020, 13-18 July 2020, Virtual Event},
  series    = {Proceedings of Machine Learning Research},
  volume    = {119},
  pages     = {10799--10808},
  publisher = {{PMLR}},
  year      = {2020},
  url       = {http://proceedings.mlr.press/v119/yasunaga20a.html},
  timestamp = {Tue, 15 Dec 2020 17:40:19 +0100},
  biburl    = {https://dblp.org/rec/conf/icml/YasunagaL20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{bifi,
  author    = {Michihiro Yasunaga and
               Percy Liang},
  editor    = {Marina Meila and
               Tong Zhang},
  title     = {Break-It-Fix-It: Unsupervised Learning for Program Repair},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning,
               {ICML} 2021, 18-24 July 2021, Virtual Event},
  series    = {Proceedings of Machine Learning Research},
  volume    = {139},
  pages     = {11941--11952},
  publisher = {{PMLR}},
  year      = {2021},
  url       = {http://proceedings.mlr.press/v139/yasunaga21a.html},
  timestamp = {Wed, 25 Aug 2021 17:11:17 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/YasunagaL21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{lieber2021jurassic,
  title={Jurassic-1: Technical Details and Evaluation},
  author={Lieber, Opher and Sharir, Or and Lenz, Barak and Shoham, Yoav},
  journal={White Paper. AI21 Labs},
  year={2021}
}

# Sparse Sinkhorn Attention
# https://arxiv.org/abs/2002.11296
@misc{tay2020sparse,
      title={Sparse Sinkhorn Attention}, 
      author={Yi Tay and Dara Bahri and Liu Yang and Donald Metzler and Da-Cheng Juan},
      year={2020},
      journal={arXiv preprint arXiv:2002.11296},
}

# Efficient Transformers: A Survey
# https://arxiv.org/pdf/2009.06732.pdf

@article{tay2020efficient,
  title={Efficient transformers: A survey},
  author={Tay, Yi and Dehghani, Mostafa and Bahri, Dara and Metzler, Donald},
  journal={arXiv preprint arXiv:2009.06732},
  year={2020}
}

# performer go/performer

@article{choromanski2020rethinking,
  title={Rethinking attention with performers},
  author={Choromanski, Krzysztof and Likhosherstov, Valerii and Dohan, David and Song, Xingyou and Gane, Andreea and Sarlos, Tamas and Hawkins, Peter and Davis, Jared and Mohiuddin, Afroz and Kaiser, Lukasz and others},
  journal={arXiv preprint arXiv:2009.14794},
  year={2020}
}

@article{kitaev2020reformer,
  title={Reformer: The efficient transformer},
  author={Kitaev, Nikita and Kaiser, {\L}ukasz and Levskaya, Anselm},
  journal={arXiv preprint arXiv:2001.04451},
  year={2020}
}

@article{roy2020efficient,
  title={Efficient content-based sparse attention with routing transformers},
  author={Roy, Aurko and Saffar, Mohammad and Vaswani, Ashish and Grangier, David},
  journal={arXiv preprint arXiv:2003.05997},
  year={2020}
}

@article{child2019generating,
  title={Generating long sequences with sparse transformers},
  author={Child, Rewon and Gray, Scott and Radford, Alec and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1904.10509},
  year={2019}
}

@article{gale2019state,
  title={The state of sparsity in deep neural networks},
  author={Gale, Trevor and Elsen, Erich and Hooker, Sara},
  journal={arXiv preprint arXiv:1902.09574},
  year={2019}
}

@inproceedings{DBLP:conf/icml/ZhangZSL20,
  author    = {Jingqing Zhang and
               Yao Zhao and
               Mohammad Saleh and
               Peter J. Liu},
  title     = {{PEGASUS:} Pre-training with Extracted Gap-sentences for Abstractive
               Summarization},
  booktitle = {Proceedings of the 37th International Conference on Machine Learning,
               {ICML} 2020, 13-18 July 2020, Virtual Event},
  series    = {Proceedings of Machine Learning Research},
  volume    = {119},
  pages     = {11328--11339},
  publisher = {{PMLR}},
  year      = {2020},
  url       = {http://proceedings.mlr.press/v119/zhang20ae.html},
  timestamp = {Tue, 15 Dec 2020 17:40:19 +0100},
  biburl    = {https://dblp.org/rec/conf/icml/ZhangZSL20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{mmlu,
  title={Measuring Massive Multitask Language Understanding},
  author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
  journal={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2021}
}
@article{maynez2020faithfulness,
  title={On faithfulness and factuality in abstractive summarization},
  author={Maynez, Joshua and Narayan, Shashi and Bohnet, Bernd and McDonald, Ryan},
  journal={arXiv preprint arXiv:2005.00661},
  year={2020}
}


@misc{palm2,
      title={{PaLM 2 Technical Report}}, 
      author={Rohan Anil and Andrew M. Dai and Orhan Firat and Melvin Johnson and Dmitry Lepikhin and Alexandre Passos and Siamak Shakeri and Emanuel Taropa and Paige Bailey and Zhifeng Chen and others},
      journal={arXiv preprint arXiv:2305.10403},
  year={2023}
}




%misc{palm2,
%      title={{PaLM 2 Technical Report}}, 
%      author={Rohan Anil and Andrew M. Dai and Orhan Firat and Melvin Johnson and Dmitry Lepikhin and Alexandre Passos and Siamak Shakeri and Emanuel Taropa and Paige Bailey and Zhifeng Chen and Eric Chu and Jonathan H. Clark and Laurent El Shafey and Yanping Huang and Kathy Meier-Hellstern and Gaurav Mishra and Erica Moreira and Mark Omernick and Kevin Robinson and Sebastian Ruder and Yi Tay and Kefan Xiao and Yuanzhong Xu and Yujing Zhang and Gustavo Hernandez Abrego and Junwhan Ahn and Jacob Austin and Paul Barham and Jan Botha and James Bradbury and Siddhartha Brahma and Kevin Brooks and Michele Catasta and Yong Cheng and Colin Cherry and Christopher A. Choquette-Choo and Aakanksha Chowdhery and Clément Crepy and Shachi Dave and Mostafa Dehghani and Sunipa Dev and Jacob Devlin and Mark Díaz and Nan Du and Ethan Dyer and Vlad Feinberg and Fangxiaoyu Feng and Vlad Fienber and Markus Freitag and Xavier Garcia and Sebastian Gehrmann and Lucas Gonzalez and Guy Gur-Ari and Steven Hand and Hadi Hashemi and Le Hou and Joshua Howland and Andrea Hu and Jeffrey Hui and Jeremy Hurwitz and Michael Isard and Abe Ittycheriah and Matthew Jagielski and Wenhao Jia and Kathleen Kenealy and Maxim Krikun and Sneha Kudugunta and Chang Lan and Katherine Lee and Benjamin Lee and Eric Li and Music Li and Wei Li and YaGuang Li and Jian Li and Hyeontaek Lim and Hanzhao Lin and Zhongtao Liu and Frederick Liu and Marcello Maggioni and Aroma Mahendru and Joshua Maynez and Vedant Misra and Maysam Moussalem and Zachary Nado and John Nham and Eric Ni and Andrew Nystrom and Alicia Parrish and Marie Pellat and Martin Polacek and Alex Polozov and Reiner Pope and Siyuan Qiao and Emily Reif and Bryan Richter and Parker Riley and Alex Castro Ros and Aurko Roy and Brennan Saeta and Rajkumar Samuel and Renee Shelby and Ambrose Slone and Daniel Smilkov and David R. So and Daniel Sohn and Simon Tokumine and Dasha Valter and Vijay Vasudevan and Kiran Vodrahalli and Xuezhi Wang and Pidong Wang and Zirui Wang and Tao Wang and John Wieting and Yuhuai Wu and Kelvin Xu and Yunhan Xu and Linting Xue and Pengcheng Yin and Jiahui Yu and Qiao Zhang and Steven Zheng and Ce Zheng and Weikang Zhou and Denny Zhou and Slav Petrov and Yonghui Wu},
%      journal={arXiv preprint arXiv:2305.10403},
%  year={2023}
%}

@article{llama,
  title={Llama: Open and efficient foundation language models},
  author={Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timoth{\'e}e Lacroix and Baptiste Rozi{\`e}re and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@misc{claude,
    title={{Model Card and Evaluations for Claude Models}},
    author={Anthropic},
    year={2023}
}

@misc{claudeprompting,
    title={{Long context prompting for Claude 2.1}},
    author={Anthropic},
    year={2023}
}

@article{roberts2020much,
  title={How much knowledge can you pack into the parameters of a language model?},
  author={Roberts, Adam and Raffel, Colin and Shazeer, Noam},
  journal={arXiv preprint arXiv:2002.08910},
  year={2020}
}

@article{bai2022constitutional,
  title={Constitutional {AI}: Harmlessness from {AI} feedback},
  author={Yuntao Bai and Saurav Kadavath and Sandipan Kundu and Amanda Askell and Jackson Kernion and Andy Jones and Anna Chen and Anna Goldie and Azalia Mirhoseini and Cameron McKinnon and Carol Chen and Catherine Olsson and Christopher Olah and Danny Hernandez and Dawn Drain and Deep Ganguli and Dustin Li and Eli Tran-Johnson and Ethan Perez and Jamie Kerr and Jared Mueller and Jeffrey Ladish and Joshua Landau and Kamal Ndousse and Kamile Lukosuite and Liane Lovitt and Michael Sellitto and Nelson Elhage and Nicholas Schiefer and Noemi Mercado and Nova DasSarma and Robert Lasenby and Robin Larson and Sam Ringer and Scott Johnston and Shauna Kravec and Sheer El Showk and Stanislav Fort and Tamera Lanham and Timothy Telleen-Lawton and Tom Conerly and Tom Henighan and Tristan Hume and Samuel R. Bowman and Zac Hatfield-Dodds and Ben Mann and Dario Amodei and Nicholas Joseph and Sam McCandlish and Tom Brown and Jared Kaplan},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022}
}

% article{thoppilan2022lamda,
%   title={Lamda: Language models for dialog applications},
%   author={Thoppilan, Romal and De Freitas, Daniel and Hall, Jamie and Shazeer, Noam and Kulshreshtha, Apoorv and Cheng, Heng-Tze and Jin, Alicia and Bos, Taylor and Baker, Leslie and Du, Yu and others},
%   journal={arXiv preprint arXiv:2201.08239},
%   year={2022}
% }

@article{kim2021scalable,
  title={Scalable and efficient moe training for multitask multilingual models},
  author={Kim, Young Jin and Awan, Ammar Ahmad and Muzio, Alexandre and Salinas, Andres Felipe Cruz and Lu, Liyang and Hendy, Amr and Rajbhandari, Samyam and He, Yuxiong and Awadalla, Hany Hassan},
  journal={arXiv preprint arXiv:2109.10465},
  year={2021}
}

@article{roller2021hash,
  title={Hash layers for large sparse models},
  author={Roller, Stephen and Sukhbaatar, Sainbayar and Weston, Jason and others},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={17555--17566},
  year={2021}
}

@article{rashkin2023measuring,
  title={Measuring attribution in natural language generation models},
  author={Rashkin, Hannah and Nikolaev, Vitaly and Lamm, Matthew and Aroyo, Lora and Collins, Michael and Das, Dipanjan and Petrov, Slav and Tomar, Gaurav Singh and Turc, Iulia and Reitter, David},
  journal={Computational Linguistics},
  volume={49},
  number={4},
  pages={777--840},
  year={2023},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@article{QA2023attributed,
      title={Attributed Question Answering: Evaluation and Modeling for Attributed Large Language Models}, 
      author={Bernd Bohnet and Vinh Q. Tran and Pat Verga and Roee Aharoni and Daniel Andor and Livio Baldini Soares and Massimiliano Ciaramita and Jacob Eisenstein and Kuzman Ganchev and Jonathan Herzig and Kai Hui and Tom Kwiatkowski and Ji Ma and Jianmo Ni and Lierni Sestorain Saralegui and Tal Schuster and William W. Cohen and Michael Collins and Dipanjan Das and Donald Metzler and Slav Petrov and Kellie Webster},
      url={https://arxiv.org/abs/2212.08037},
      year={2022},
     
}

@article{googleaiprinciples,
  title={{Google's AI Principles}},
  author={Google},
  year={2023},
  url={https://ai.google/responsibility/principles/},
}

@article{gpt4,
      title={{GPT-4 Technical Report}}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{ardila2019common,
  title={Common voice: A massively-multilingual speech corpus},
  author={Ardila, Rosana and Branson, Megan and Davis, Kelly and Henretty, Michael and Kohler, Michael and Meyer, Josh and Morais, Reuben and Saunders, Lindsay and Tyers, Francis M and Weber, Gregor},
  journal={arXiv preprint arXiv:1912.06670},
  year={2019}
}

@misc{gpt4v,
      title={{GPT-4V(ision) System Card}}, 
      author={OpenAI},
      year={2023},
}

@article{parti,
  title={Scaling autoregressive models for content-rich text-to-image generation},
  author={Jiahui Yu and Yuanzhong Xu and Jing Yu Koh and Thang Luong and Gunjan Baid and Zirui Wang and Vijay Vasudevan and Alexander Ku and Yinfei Yang and Burcu Karagol Ayan and Ben Hutchinson and Wei Han and Zarana Parekh and Xin Li and Han Zhang and Jason Baldridge and Yonghui Wu},
  journal={arXiv preprint arXiv:2206.10789},
  volume={2},
  number={3},
  pages={5},
  year={2022},
  publisher={Jun}
}

@inproceedings{latent_diffusion,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}

@article{usm,
  title={Google usm: Scaling automatic speech recognition beyond 100 languages},
  author={Yu Zhang and Wei Han and James Qin and Yongqiang Wang and Ankur Bapna and Zhehuai Chen and Nanxin Chen and Bo Li and Vera Axelrod and Gary Wang and Zhong Meng and Ke Hu and Andrew Rosenberg and Rohit Prabhavalkar and Daniel S. Park and Parisa Haghani and Jason Riesa and Ginger Perng and Hagen Soltau and Trevor Strohman and Bhuvana Ramabhadran and Tara Sainath and Pedro Moreno and Chung-Cheng Chiu and Johan Schalkwyk and Françoise Beaufays and Yonghui Wu},
  journal={arXiv preprint arXiv:2303.01037},
  year={2023}
}

@inproceedings{whisper,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={28492--28518},
  year={2023},
  organization={PMLR}
}


@misc{whisper-v3,
  author={{OpenAI}},
  title = {Whisper},
  year = 2023,
  url = {https://github.com/openai/whisper},
}


@article{imagen,
  title={Photorealistic text-to-image diffusion models with deep language understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily L and Ghasemipour, Kamyar and Gontijo Lopes, Raphael and Karagol Ayan, Burcu and Salimans, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={36479--36494},
  year={2022}
}

@inproceedings{dalle,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={8821--8831},
  year={2021},
  organization={PMLR}
}

@article{dalle2,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  volume={1},
  number={2},
  pages={3},
  year={2022}
}

@article{gato,
  title={A generalist agent},
  author={Scott Reed and Konrad Zolna and Emilio Parisotto and Sergio Gomez Colmenarejo and Alexander Novikov and Gabriel Barth-Maron and Mai Gimenez and Yury Sulsky and Jackie Kay and Jost Tobias Springenberg and Tom Eccles and Jake Bruce and Ali Razavi and Ashley Edwards and Nicolas Heess and Yutian Chen and Raia Hadsell and Oriol Vinyals and Mahyar Bordbar and Nando de Freitas},
  journal={arXiv preprint arXiv:2205.06175},
  year={2022}
}

@misc{agarwal2024manyshot,
      title={Many-Shot In-Context Learning}, 
      author={Rishabh Agarwal and Avi Singh and Lei M. Zhang and Bernd Bohnet and Stephanie Chan and Ankesh Anand and Zaheer Abbas and Azade Nova and John D. Co-Reyes and Eric Chu and Feryal Behbahani and Aleksandra Faust and Hugo Larochelle},
      year={2024},
      eprint={2404.11018},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{llama2,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and Lukas Blecher and Cristian Canton Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel Kloumann and Artem Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and Ranjan Subramanian and Xiaoqing Ellen Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@inproceedings{vedantam2015cider,
  title={Cider: Consensus-based image description evaluation},
  author={Vedantam, Ramakrishna and Lawrence Zitnick, C and Parikh, Devi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4566--4575},
  year={2015}
}

@article{mqa,
  title={Fast transformer decoding: One write-head is all you need},
  author={Shazeer, Noam},
  journal={arXiv preprint arXiv:1911.02150},
  year={2019}
}

@inproceedings{tpuv4,
  title={Tpu v4: An optically reconfigurable supercomputer for machine learning with hardware support for embeddings},
  author={Jouppi, Norman P and Kurian, George and Li, Sheng and Ma, Peter and Nagarajan, Rahul and Nai, Lifeng and Patil, Nishant and Subramanian, Suvinay and Swing, Andy and Towles, Brian and Young, Cliff and Zhou, Xiang and Zhou, Zongwei and Patterson, David A},
  booktitle={Proceedings of the 50th Annual International Symposium on Computer Architecture},
  pages={1--14},
  year={2023}
}

@software{jax,
  author = {James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and George Necula and Adam Paszke and Jake Vander{P}las and Skye Wanderman-{M}ilne and Qiao Zhang},
  title = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
  url = {http://github.com/google/jax},
  version = {0.3.13},
  year = {2018},
}

@inproceedings{jupiter,
  title={Jupiter evolving: transforming google's datacenter network via optical circuit switches and software-defined networking},
  author={Poutievski, Leon and Mashayekhi, Omid and Ong, Joon and Singh, Arjun and Tariq, Mukarram and Wang, Rui and Zhang, Jianan and Beauregard, Virginia and Conner, Patrick and Gribble, Steve and others},
  booktitle={Proceedings of the ACM SIGCOMM 2022 Conference},
  pages={66--85},
  year={2022}
}

@inproceedings{pony,
title	= {Improving Network Availability with Protective ReRoute},
author	= {David Wetherall and Abdul Kabbani and Van Jacobson and Jim Winget and Yuchung Cheng and Brad Morrey and Uma Parthavi Moravapalle and Phillipa Gill and Steven Knight and Amin Vahdat},
year	= {2023},
URL	= {https://dl.acm.org/doi/10.1145/3603269.3604867},
booktitle	= {SIGCOMM 2023}
}



@inproceedings{b4,
title	= {B4 and After: Managing Hierarchy, Partitioning, and Asymmetry for Availability and Scale in Google's Software-Defined WAN},
author	= {Chi-yao Hong and Subhasree Mandal and Mohammad A. Alfares and Min Zhu and Rich Alimi and Kondapa Naidu Bollineni and Chandan Bhagat and Sourabh Jain and Jay Kaimal and Jeffrey Liang and Kirill Mendelev and Steve Padgett and Faro Thomas Rabe and Saikat Ray and Malveeka Tewari and Matt Tierney and Monika Zahn and Jon Zolla and Joon Ong and Amin Vahdat},
year	= {2018},
URL	= {https://conferences.sigcomm.org/sigcomm/2018/program_tuesday.html},
booktitle	= {SIGCOMM'18}
}

@article{distbelief,
  title={Large scale distributed deep networks},
  author={Dean, Jeffrey and Corrado, Greg and Monga, Rajat and Chen, Kai and Devin, Matthieu and Mao, Mark and Ranzato, Marc'aurelio and Senior, Andrew and Tucker, Paul and Yang, Ke and others},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012}
}

@article{pathways,
  title={Pathways: Asynchronous distributed dataflow for {ML}},
  author={Paul Barham and Aakanksha Chowdhery and Jeff Dean and Sanjay Ghemawat and Steven Hand and Dan Hurt and Michael Isard and Hyeontaek Lim and Ruoming Pang and Sudip Roy and Brennan Saeta and Parker Schuh and Ryan Sepassi and Laurent El Shafey and Chandramohan A. Thekkath and Yonghui Wu},
  journal={Proceedings of Machine Learning and Systems},
  volume={4},
  pages={430--449},
  year={2022}
}


@misc{kavukcuogluprinciples,
  title={{How our principles helped define AlphaFold’s release. Google DeepMind}},
  author={Kavukcuoglu, K and Kohli, P and Ibrahim, L and Bloxwich, D and Brown, S},
  year={2022}
}

@article{weidinger2021ethical,
  title={Ethical and social risks of harm from language models},
  author={Weidinger, Laura and Mellor, John and Rauh, Maribeth and Griffin, Conor and Uesato, Jonathan and Huang, Po-Sen and Cheng, Myra and Glaese, Mia and Balle, Borja and Kasirzadeh, Atoosa and others},
  journal={arXiv preprint arXiv:2112.04359},
  year={2021}
}

@ARTICLE{cosmic,
  author={Michalak, Sarah E. and DuBois, Andrew J. and Storlie, Curtis B. and Quinn, Heather M. and Rust, William N. and DuBois, David H. and Modl, David G. and Manuzzato, Andrea and Blanchard, Sean P.},
  journal={IEEE Transactions on Device and Materials Reliability}, 
  title={Assessment of the Impact of Cosmic-Ray-Induced Neutrons on Hardware in the Roadrunner Supercomputer}, 
  year={2012},
  volume={12},
  number={2},
  pages={445-454},
  doi={10.1109/TDMR.2012.2192736}}

@INPROCEEDINGS{sdc2,
  author={Vishwanathan, Manoj and Shah, Ronak and Kim, Kyung Ki and Choi, Minsu},
  booktitle={2015 International SoC Design Conference (ISOCC)}, 
  title={Silent Data Corruption (SDC) vulnerability of GPU on various GPGPU workloads}, 
  year={2015},
  volume={},
  number={},
  pages={11-12},
  doi={10.1109/ISOCC.2015.7401681}}

@inproceedings{hochschild2021cores,
  title={Cores that don't count},
  author={Hochschild, Peter H and Turner, Paul and Mogul, Jeffrey C and Govindaraju, Rama and Ranganathan, Parthasarathy and Culler, David E and Vahdat, Amin},
  booktitle={Proceedings of the Workshop on Hot Topics in Operating Systems},
  pages={9--16},
  year={2021}
}

@article{shevlane2023model,
  title={Model evaluation for extreme risks},
  author={Toby Shevlane and Sebastian Farquhar and Ben Garfinkel and Mary Phuong and Jess Whittlestone and Jade Leung and Daniel Kokotajlo and Nahema Marchal and Markus Anderljung and Noam Kolt and Lewis Ho and Divya Siddarth and Shahar Avin and Will Hawkins and Been Kim and Iason Gabriel and Vijay Bolina and Jack Clark and Yoshua Bengio and Paul Christiano and Allan Dafoe},
  journal={arXiv preprint arXiv:2305.15324},
  year={2023}
}

@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}

@article{zhou2023don,
  title={Don't Make Your LLM an Evaluation Benchmark Cheater},
  author={Zhou, Kun and Zhu, Yutao and Chen, Zhipeng and Chen, Wentong and Zhao, Wayne Xin and Chen, Xu and Lin, Yankai and Wen, Ji-Rong and Han, Jiawei},
  journal={arXiv preprint arXiv:2311.01964},
  year={2023}
}

@misc{zhou2023lima,
      title={LIMA: Less Is More for Alignment}, 
      author={Chunting Zhou and Pengfei Liu and Puxin Xu and Srini Iyer and Jiao Sun and Yuning Mao and Xuezhe Ma and Avia Efrat and Ping Yu and Lili Yu and Susan Zhang and Gargi Ghosh and Mike Lewis and Luke Zettlemoyer and Omer Levy},
      year={2023},
      eprint={2305.11206},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@article{gophercite,
  title={Teaching language models to support answers with verified quotes},
  author={Jacob Menick and Maja Trebacz and Vladimir Mikulik and John Aslanides and Francis Song and Martin Chadwick and Mia Glaese and Susannah Young and Lucy Campbell-Gillingham and Geoffrey Irving and Nat McAleese},
  journal={arXiv preprint arXiv:2203.11147},
  year={2022}
}

@article{peng2023check,
  title={Check your facts and try again: Improving large language models with external knowledge and automated feedback},
  author={Peng, Baolin and Galley, Michel and He, Pengcheng and Cheng, Hao and Xie, Yujia and Hu, Yu and Huang, Qiuyuan and Liden, Lars and Yu, Zhou and Chen, Weizhu and others},
  journal={arXiv preprint arXiv:2302.12813},
  year={2023}
}

@article{hu2023won,
  title={Won't Get Fooled Again: Answering Questions with False Premises},
  author={Hu, Shengding and Luo, Yifan and Wang, Huadong and Cheng, Xingyi and Liu, Zhiyuan and Sun, Maosong},
  journal={arXiv preprint arXiv:2307.02394},
  year={2023}
}
      
@inproceedings{textvqa,
	title={Towards {VQA} models that can read},
	author={Singh, Amanpreet and Natarajan, Vivek and Shah, Meet and Jiang, Yu and Chen, Xinlei and Batra, Dhruv and Parikh, Devi and Rohrbach, Marcus},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={8317--8326},
	year={2019}
}

@inproceedings{docvqa,
	title={{Docvqa}: A dataset for vqa on document images},
	author={Mathew, Minesh and Karatzas, Dimosthenis and Jawahar, CV},
	booktitle={Proceedings of the IEEE/CVF winter conference on applications of computer vision},
	pages={2200--2209},
	year={2021}
}


@INPROCEEDINGS {dude,
author = {J. Landeghem and R. Powalski and R. Tito and D. Jurkiewicz and M. Blaschko and L. Borchmann and M. Coustaty and S. Moens and M. Pietruszka and B. Ackaert and T. Stanislawek and P. Joziak and E. Valveny},
booktitle = {2023 IEEE/CVF International Conference on Computer Vision (ICCV)},
title = {Document Understanding Dataset and Evaluation (DUDE)},
year = {2023},
pages = {19471-19483},
}


@inproceedings{tatdqa,
author = {Zhu, Fengbin and Lei, Wenqiang and Feng, Fuli and Wang, Chao and Zhang, Haozhou and Chua, Tat-Seng},
title = {Towards Complex Document Understanding By Discrete Reasoning},
booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
year = {2022},
pages = {4857–4866},
}

@inproceedings{matcha,
    title = "{M}at{C}ha: Enhancing Visual Language Pretraining with Math Reasoning and Chart Derendering",
    author = "Liu, Fangyu  and
      Piccinno, Francesco  and
      Krichene, Syrine  and
      Pang, Chenxi  and
      Lee, Kenton  and
      Joshi, Mandar  and
      Altun, Yasemin  and
      Collier, Nigel  and
      Eisenschlos, Julian",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.714",
    doi = "10.18653/v1/2023.acl-long.714",
    pages = "12756--12770",
    abstract = "Visual language data such as plots, charts, and infographics are ubiquitous in the human world. However, state-of-the-art vision-language models do not perform well on these data. We propose MatCha (Math reasoning and Chart derendering pretraining) to enhance visual language models{'} capabilities in jointly modeling charts/plots and language data. Specifically, we propose several pretraining tasks that cover plot deconstruction and numerical reasoning which are the key capabilities in visual language modeling. We perform the MatCha pretraining starting from Pix2Struct, a recently proposed image-to-text visual language model. On standard benchmarks such as PlotQA and ChartQA, the MatCha model outperforms state-of-the-art methods by as much as nearly 20{\%}. We also examine how well MatCha pretraining transfers to domains such as screenshots, textbook diagrams, and document figures and observe overall improvement, verifying the usefulness of MatCha pretraining on broader visual language tasks.",
}

@inproceedings{chartqa,
	title={{ChartQA}: A Benchmark for Question Answering about Charts with Visual and Logical Reasoning},
	author={Masry, Ahmed and Long, Do and Tan, Jia Qing and Joty, Shafiq and Hoque, Enamul},
	booktitle={Findings of ACL},
	year={2022}
}
@article{BradleyTerry,
  annote = {Describes the Bradley-Terry method for estimating
                  probability distributions from pairwise comparisons},
  author = {Bradley, Ralph A. and Terry, Milton E.},
  journal = {Biometrika},
  keywords = {imported},
  pages = {324--345},
  timestamp = {2009-10-20T18:51:19.000+0200},
  title = {The Rank Analysis of Incomplete Block Designs --- {I.
                  The} Method of Paired Comparisons},
  volume = 39,
  year = 1952
}
@inproceedings{infographicvqa,
	title={Infographicvqa},
	author={Mathew, Minesh and Bagal, Viraj and Tito, Rub{\`e}n and Karatzas, Dimosthenis and Valveny, Ernest and Jawahar, CV},
	booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
	pages={1697--1706},
	year={2022}
}

@inproceedings{ai2d,
	title={A diagram is worth a dozen images},
	author={Kembhavi, Aniruddha and Salvato, Mike and Kolve, Eric and Seo, Minjoon and Hajishirzi, Hannaneh and Farhadi, Ali},
	booktitle={ECCV},
	year={2016},
}


@inproceedings{vqav2,
	title={Making the {V} in {VQA} matter: Elevating the role of image understanding in visual question answering},
	author={Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={6904--6913},
	year={2017}
}

@inproceedings{vatex,
	title={{VATEX}: A large-scale, high-quality multilingual dataset for video-and-language research},
	author={Wang, Xin and Wu, Jiawei and Chen, Junkun and Li, Lei and Wang, Yuan-Fang and Wang, William Yang},
	booktitle={ICCV},
	year={2019}
}

@inproceedings{youcook2,
	author={Zhou, Luowei and Xu, Chenliang and Corso, Jason J},
	title = {Towards Automatic Learning of Procedures From Web Instructional Videos},
	booktitle = {{AAAI} Conference on Artificial Intelligence},
	pages={7590--7598},
	year = {2018},
}

@inproceedings{nextqa,
	title={{NExT-QA}: Next phase of question-answering to explaining temporal actions},
	author={Xiao, Junbin and Shang, Xindi and Yao, Angela and Chua, Tat-Seng},
	booktitle={CVPR},
	year={2021}
}

@inproceedings{activitynetqa,
	title={{ActivityNet-QA}: A dataset for understanding complex web videos via question answering},
	author={Yu, Zhou and Xu, Dejing and Yu, Jun and Yu, Ting and Zhao, Zhou and Zhuang, Yueting and Tao, Dacheng},
	booktitle={AAAI},
	year={2019}
}

@inproceedings{xm3600,
	title={{Crossmodal-3600}: A Massively Multilingual Multimodal Evaluation Dataset},
	author={Ashish V. Thapliyal and Jordi Pont-Tuset and Xi Chen and Radu Soricut},
	booktitle={EMNLP},
	year={2022}
}

@article{lin2023video,
  title={Video-LLaVA: Learning United Visual Representation by Alignment Before Projection},
  author={Lin, Bin and Zhu, Bin and Ye, Yang and Ning, Munan and Jin, Peng and Yuan, Li},
  journal={arXiv preprint arXiv:2311.10122},
  year={2023}
}


@article{alphazero,
  title={Mastering chess and shogi by self-play with a general reinforcement learning algorithm},
  author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
  journal={arXiv preprint arXiv:1712.01815},
  year={2017}
}

% article{mgsm,
%   title={Language models are multilingual chain-of-thought reasoners},
%   author={Shi, Freda and Suzgun, Mirac and Freitag, Markus and Wang, Xuezhi and Srivats, Suraj and Vosoughi, Soroush and Chung, Hyung Won and Tay, Yi and Ruder, Sebastian and Zhou, Denny and others},
%   journal={ICLR},
%   year={2023}
% }

@misc{codeforces,
  title = {{Codeforces} Website},
  howpublished = {\url{http://codeforces.com}},
}

@misc{gemini-demo,
  title = {{Demo Examples} on {Gemini} Website},
  author = {"Gemini Demos"},
  year = {2023},
  howpublished = {\url{http://deepmind.google/technologies/gemini}},
}

@misc{kasai2022realtimeqa,
  author    = {Jungo Kasai and Keisuke Sakaguchi and Yoichi Takahashi and Ronan Le Bras and Akari Asai and Xinyan Yu and Dragomir Radev and Noah A. Smith and Yejin Choi and Kentaro Inui},
  title     = {{R}eal{T}ime {QA}: What's the Answer Right Now?},
  year      = {2022},
  url       = {https://arxiv.org/abs/2207.13332},
}

@article{kocisky-etal-2018-narrativeqa,
    title = "The {N}arrative{QA} Reading Comprehension Challenge",
    author = "Ko{\v{c}}isk{\'y}, Tom{\'a}{\v{s}}  and
      Schwarz, Jonathan  and
      Blunsom, Phil  and
      Dyer, Chris  and
      Hermann, Karl Moritz  and
      Melis, G{\'a}bor  and
      Grefenstette, Edward",
    editor = "Lee, Lillian  and
      Johnson, Mark  and
      Toutanova, Kristina  and
      Roark, Brian",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "6",
    year = "2018",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/Q18-1023",
    doi = "10.1162/tacl_a_00023",
    pages = "317--328",
}

@inproceedings{shaham-etal-2022-scrolls,
title = "{SCROLLS}: Standardized {C}ompa{R}ison Over Long Language Sequences",
author = "Shaham, Uri and Segal, Elad and Ivgi, Maor and Efrat, Avia and Yoran, Ori and Haviv, Adi and Gupta, Ankit and Xiong, Wenhan and Geva, Mor and Berant, Jonathan and Levy, Omer",
booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
month = dec,
year = "2022",
address = "Abu Dhabi, United Arab Emirates",
publisher = "Association for Computational Linguistics",
url = "https://aclanthology.org/2022.emnlp-main.823",
pages = "12007--12021"
}

@inproceedings{federmann-etal-2022-ntrex,
    title = "{NTREX}-128 {--} News Test References for {MT} Evaluation of 128 Languages",
    author = "Federmann, Christian and Kocmi, Tom and Xin, Ying",
    booktitle = "Proceedings of the First Workshop on Scaling Up Multilingual Evaluation",
    month = "nov",
    year = "2022",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.sumeval-1.4",
    pages = "21--24",
}

@article{flores200,
  author    = {NLLB Team and Marta R. Costa-jussà and James Cross and Onur Çelebi and Maha Elbayad and Kenneth Heafield and Kevin Heffernan and Elahe Kalbassi and  Janice Lam and Daniel Licht and Jean Maillard and Anna Sun and Skyler Wang and Guillaume Wenzek and Al Youngblood and Bapi Akula and Loic Barrault and Gabriel Mejia Gonzalez and Prangthip Hansanti and John Hoffman and Semarley Jarrett and Kaushik Ram Sadagopan and Dirk Rowe and Shannon Spruit and Chau Tran and Pierre Andrews and Necip Fazil Ayan and Shruti Bhosale and Sergey Edunov and Angela Fan and Cynthia Gao and Vedanuj Goswami and Francisco Guzmán and Philipp Koehn and Alexandre Mourachko and Christophe Ropers and Safiyyah Saleem and Holger Schwenk and Jeff Wang},
  title     = {No Language Left Behind: Scaling Human-Centered Machine Translation},
  year      = {2022}
}

@inproceedings{Tafjord2020ProofWriterGI,
  title={{ProofWriter}: Generating Implications, Proofs, and Abductive Statements over Natural Language},
  author={Oyvind Tafjord and Bhavana Dalvi and Peter Clark},
  booktitle={Findings},
  year={2020},
  url={https://api.semanticscholar.org/CorpusID:229371222}
}

@article{deepmind2022clrs,
  title={The CLRS Algorithmic Reasoning Benchmark},
  author={Petar Veli\v{c}kovi\'{c} and Adri\`{a} Puigdom\`{e}nech Badia and
    David Budden and Razvan Pascanu and Andrea Banino and Misha Dashevskiy and
    Raia Hadsell and Charles Blundell},
  journal={arXiv preprint arXiv:2205.15659},
  year={2022}
}



@inproceedings{panayotov2015librispeech,
  title={Librispeech: an asr corpus based on public domain audio books},
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2015 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={5206--5210},
  year={2015},
  organization={IEEE}
}
@article{wang2021voxpopuli,
  title={VoxPopuli: A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation},
  author={Wang, Changhan and Riviere, Morgane and Lee, Ann and Wu, Anne and Talnikar, Chaitanya and Haziza, Daniel and Williamson, Mary and Pino, Juan and Dupoux, Emmanuel},
  journal={arXiv preprint arXiv:2101.00390},
  year={2021}
}
@article{wang2020covost,
  title={Covost 2 and massively multilingual speech-to-text translation},
  author={Wang, Changhan and Wu, Anne and Pino, Juan},
  journal={arXiv preprint arXiv:2007.10310},
  year={2020}
}
@inproceedings{conneau2023fleurs,
  title={Fleurs: Few-shot learning evaluation of universal representations of speech},
  author={Conneau, Alexis and Ma, Min and Khanuja, Simran and Zhang, Yu and Axelrod, Vera and Dalmia, Siddharth and Riesa, Jason and Rivera, Clara and Bapna, Ankur},
  booktitle={2022 IEEE Spoken Language Technology Workshop (SLT)},
  pages={798--805},
  year={2023},
  organization={IEEE}
}

@conference{majumdar2025predictive,
  title={Predictive red teaming: Breaking policies without breaking robots},
  author={Majumdar, Anirudha and Sharma, Mohit and Kalashnikov, Dmitry and Singh, Sumeet and Sermanet, Pierre and Sindhwani, Vikas},
  booktitle={Conference on Robot Learning (CORL)},
  url={https://predictive-red-team.github.io/},
  year={2025}
}

@conference{sermanet2025generating,
    author = {Sermanet, Pierre and Majumdar, Anirudha and Irpan, Alex and Kalashnikov, Dmitry and Sindhwani, Vikas},
    booktitle = {Conference on Robot Learning (CORL)},
    title = {Generating Robot Constitutions \& Benchmarks for Semantic Safety},
    url={https://asimov-benchmark.github.io/},
    year = {2025}
}

@article{puatruaucean2023perception,
  title={Perception Test: A Diagnostic Benchmark for Multimodal Video Models},
  author={P{\u{a}}tr{\u{a}}ucean, Viorica and Smaira, Lucas and Gupta, Ankush and Continente, Adri{\`a} Recasens and Markeeva, Larisa and Banarse, Dylan and Koppula, Skanda and Heyward, Joseph and Malinowski, Mateusz and Yang, Yi and Doersch, Carl and Matejovicova, Tatiana and Sulsky, Yury and Miech, Antoine and Frechette, Alex and Klimczak, Hanna and Koster, Raphael and Zhang, Junlin and Winkler, Stephanie and Aytar, Yusuf and Osindero, Simon and Damen, Dima and Zisserman, Andrew and Carreira, J{o{\u{a}}o}},
  journal={arXiv preprint arXiv:2305.13786},
  year={2023}
}

@article{yu2023self,
  title={Self-Chained Image-Language Model for Video Localization and Question Answering},
  author={Yu, Shoubin and Cho, Jaemin and Yadav, Prateek and Bansal, Mohit},
  journal={arXiv preprint arXiv:2305.06988},
  year={2023}
}

@inproceedings{lu2021inter,
  title = {Inter-GPS: Interpretable Geometry Problem Solving with Formal Language and Symbolic Reasoning},
  author = {Lu, Pan and Gong, Ran and Jiang, Shibiao and Qiu, Liang and Huang, Siyuan and Liang, Xiaodan and Zhu, Song-Chun},
  booktitle = {The Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL-IJCNLP 2021)},
  year = {2021}
}

@article{owid-plastic-pollution,
    author = {Hannah Ritchie and Veronika Samborska and Max Roser},
    title = {Plastic Pollution},
    journal = {Our World in Data},
    year = {2023},
    note = {https://ourworldindata.org/plastic-pollution}
}

@misc{hwang2023memecap,
      title={MemeCap: A Dataset for Captioning and Interpreting Memes}, 
      author={EunJeong Hwang and Vered Shwartz},
      year={2023},
      eprint={2305.13703},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{oktatasi2023matematika,
  title        = {Matematika {\'I}r{\'a}sb{\'e}li Vizsga},
  author       = {{Oktat{\'a}si Hivatal}},
  howpublished = {K{\"o}z{\'e}pszint{\H u} {\'I}r{\'a}sb{\'e}li Vizsga},
  year         = {2023},
  month        = {May},
  day          = {9},
  note         = {Angol Nyelven},
  language     = {Hungarian},
  type         = {Exam Paper},
  url          = {https://dload-oktatas.educatio.hu/erettsegi/feladatok_2023tavasz_kozep/k_matang_23maj_fl.pdf}
}

@inproceedings{tom2023findings,
  title={Findings of the 2023 Conference on Machine Translation (WMT23): LLMs Are Here But Not Quite There Yet},
  author={Tom, Kocmi and Avramidis, Eleftherios and Bawden, Rachel and Bojar, Ond{\v{r}}ej and Dvorkovich, Anton and Federmann, Christian and Fishel, Mark and Freitag, Markus and Gowda, Thamme and Grundkiewicz, Roman and others},
  booktitle={WMT23-Eighth Conference on Machine Translation},
  pages={198--216},
  year={2023}
}

@misc{riquelme2021scaling,
      title={Scaling Vision with Sparse Mixture of Experts}, 
      author={Carlos Riquelme and Joan Puigcerver and Basil Mustafa and Maxim Neumann and Rodolphe Jenatton and André Susano Pinto and Daniel Keysers and Neil Houlsby},
      year={2021},
      eprint={2106.05974},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{clark2022unified,
      title={Unified Scaling Laws for Routed Language Models}, 
      author={Aidan Clark and Diego de las Casas and Aurelia Guy and Arthur Mensch and Michela Paganini and Jordan Hoffmann and Bogdan Damoc and Blake Hechtman and Trevor Cai and Sebastian Borgeaud and George van den Driessche and Eliza Rutherford and Tom Hennigan and Matthew Johnson and Katie Millican and Albin Cassirer and Chris Jones and Elena Buchatskaya and David Budden and Laurent Sifre and Simon Osindero and Oriol Vinyals and Jack Rae and Erich Elsen and Koray Kavukcuoglu and Karen Simonyan},
      year={2022},
      eprint={2202.01169},
      archivePrefix={arXiv},
      URL="https://arxiv.org/abs/2202.01169",
      primaryClass={cs.CL}
}

@misc{bengio2013estimating,
      title={Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation}, 
      author={Yoshua Bengio and Nicholas Léonard and Aaron Courville},
      year={2013},
      eprint={1308.3432},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{davis2014lowrank,
      title={Low-Rank Approximations for Conditional Feedforward Computation in Deep Neural Networks}, 
      author={Andrew Davis and Itamar Arel},
      year={2014},
      eprint={1312.4461},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{pope2023efficiently,
  title={Efficiently scaling transformer inference},
  author={Pope, Reiner and Douglas, Sholto and Chowdhery, Aakanksha and Devlin, Jacob and Bradbury, James and Heek, Jonathan and Xiao, Kefan and Agrawal, Shivani and Dean, Jeff},
  journal={Proceedings of Machine Learning and Systems},
  volume={5},
  year={2023}
}

@article{shannon_48,
  added-at = {2021-09-19T18:40:37.000+0200},
  author = {Shannon, Claude Elwood},
  biburl = {https://www.bibsonomy.org/bibtex/29f88587b33c82f692b61d129eb2f2517/steschum},
  interhash = {754130207906fcec16a53d330eeff348},
  intrahash = {9f88587b33c82f692b61d129eb2f2517},
  journal = {The Bell System Technical Journal},
  keywords = {imported},
  pages = {379--423},
  timestamp = {2021-09-19T18:41:56.000+0200},
  title = {A Mathematical Theory of Communication},
  url = {http://plan9.bell-labs.com/cm/ms/what/shannonday/shannon1948.pdf},
  urldate = {2003-04-22},
  volume = 27,
  year = 1948
}

@inproceedings{LLM_MT,
author = {Brants, Thorsten and Popat, Ashok and Xu, Peng and Och, Franz and Dean, Jeffrey},
year = {2007},
month = {01},
pages = {858-867},
title = {Large Language Models in Machine Translation.}
}

@misc{needle,
author = {Kamradt, Gregory},
url = "https://github.com/gkamradt/LLMTest_NeedleInAHaystack/blob/main/README.md",
year = 2023
}

@misc{needle_magic_number,
author = {Dhinakaran, Aparna},
url = "https://twitter.com/aparnadhinak/status/1744771295940669689",
year = 2024
}

@misc{liu2024world,
      title={World Model on Million-Length Video And Language With RingAttention}, 
      author={Hao Liu and Wilson Yan and Matei Zaharia and Pieter Abbeel},
      year={2024},
      eprint={2402.08268},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{geminiteam2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Gemini-Team and Anil, Rohan and Borgeaud, Sebastian and Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and others},
  journal={arXiv preprint arXiv:2312.11805},
  URL="https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf",
  year={2023},
}


@misc{conneau2022fleurs,
      title={FLEURS: Few-shot Learning Evaluation of Universal Representations of Speech}, 
      author={Alexis Conneau and Min Ma and Simran Khanuja and Yu Zhang and Vera Axelrod and Siddharth Dalmia and Jason Riesa and Clara Rivera and Ankur Bapna},
      year={2022},
      eprint={2205.12446},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{gao2023rarr,
      title={RARR: Researching and Revising What Language Models Say, Using Language Models}, 
      author={Luyu Gao and Zhuyun Dai and Panupong Pasupat and Anthony Chen and Arun Tejasvi Chaganty and Yicheng Fan and Vincent Y. Zhao and Ni Lao and Hongrae Lee and Da-Cheng Juan and Kelvin Guu},
      year={2023},
      eprint={2210.08726},
      archivePrefix={arXiv},
      URL="https://arxiv.org/abs/2210.08726",
      primaryClass={cs.CL}
}

@misc{zheng2023judging,
      title={Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena}, 
      author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric P. Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
      year={2023},
      eprint={2306.05685},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{
mangalam2023egoschema,
title={{EgoSchema}: A Diagnostic Benchmark for Very Long-form Video Language Understanding},
author={Karttikeya Mangalam and Raiymbek Akshulakov and Jitendra Malik},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2023}
}

@misc{nasr2023scalable,
      title={Scalable Extraction of Training Data from (Production) Language Models}, 
      author={Milad Nasr and Nicholas Carlini and Jonathan Hayase and Matthew Jagielski and A. Feder Cooper and Daphne Ippolito and Christopher A. Choquette-Choo and Eric Wallace and Florian Tramèr and Katherine Lee},
      year={2023},
      eprint={2311.17035},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{Schumann_2021, series={AIES ’21},
   title={A Step Toward More Inclusive People Annotations for Fairness},
   url={http://dx.doi.org/10.1145/3461702.3462594},
   DOI={10.1145/3461702.3462594},
   booktitle={Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
   publisher={ACM},
   author={Schumann, Candice and Ricco, Susanna and Prabhu, Utsav and Ferrari, Vittorio and Pantofaru, Caroline},
   year={2021},
   month=jul, collection={AIES ’21} }

@misc{AlphaGo2017,
  author = {Greg Kohs},
  title = {AlphaGo},
  howpublished = {Motion Picture},
  year = {2017},
  note = {Produced by DeepMind Technologies and distributed by Netflix},
}

@inproceedings{kocmi-etal-2023-findings,
    title = "Findings of the 2023 Conference on Machine Translation ({WMT}23): {LLM}s Are Here but Not Quite There Yet",
    author = "Kocmi, Tom  and
      Avramidis, Eleftherios  and
      Bawden, Rachel  and
      Bojar, Ond{\v{r}}ej  and
      Dvorkovich, Anton  and
      Federmann, Christian  and
      Fishel, Mark  and
      Freitag, Markus  and
      Gowda, Thamme  and
      Grundkiewicz, Roman  and
      Haddow, Barry  and
      Koehn, Philipp  and
      Marie, Benjamin  and
      Monz, Christof  and
      Morishita, Makoto  and
      Murray, Kenton  and
      Nagata, Makoto  and
      Nakazawa, Toshiaki  and
      Popel, Martin  and
      Popovi{\'c}, Maja  and
      Shmatova, Mariya",
    editor = "Koehn, Philipp  and
      Haddow, Barry  and
      Kocmi, Tom  and
      Monz, Christof",
    booktitle = "Proceedings of the Eighth Conference on Machine Translation",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.wmt-1.1",
    doi = "10.18653/v1/2023.wmt-1.1",
    pages = "1--42",
    abstract = "This paper presents the results of the General Machine Translation Task organised as part of the 2023 Conference on Machine Translation (WMT). In the general MT task, participants were asked to build machine translation systems for any of 8 language pairs (corresponding to 14 translation directions), to be evaluated on test sets consisting of up to four different domains. We evaluate system outputs with professional human annotators using a combination of source-based Direct Assessment and scalar quality metric (DA+SQM).",
}

@article{balavzevic2024memory,
  title={Memory Consolidation Enables Long-Context Video Understanding},
  author={Bala{\v{z}}evi{\'c}, Ivana and Shi, Yuge and Papalampidi, Pinelopi and Chaabouni, Rahma and Koppula, Skanda and H{\'e}naff, Olivier J},
  journal={arXiv preprint arXiv:2402.05861},
  year={2024}
}

@article{rein2023gpqa,
  title={Gpqa: A graduate-level google-proof q\&a benchmark},
  author={Rein, David and Hou, Betty Li and Stickland, Asa Cooper and Petty, Jackson and Pang, Richard Yuanzhe and Dirani, Julien and Michael, Julian and Bowman, Samuel R},
  journal={arXiv preprint arXiv:2311.12022},
  year={2023}
}

  @misc{enwiki:1221781655,
    author = "{Wikipedia contributors}",
    title = "Skeletal formula --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2024",
    url = "https://en.wikipedia.org/w/index.php?title=Skeletal_formula&oldid=1221781655",
    note = "[Online; accessed 7-May-2024]"
  }
  
  @book{mcmurry2012organic,
  title={Organic Chemistry},
  author={McMurry, J.},
  isbn={9780840054531},
  lccn={2010936830},
  series={International edition},
  url={https://books.google.at/books?id=oVv4Az7VJRYC},
  year={2012},
  publisher={Brooks/Cole Cengage Learning}
}

@inproceedings{NIPS2016_fb875828,
 author = {Andrychowicz, Marcin and Denil, Misha and G\'{o}mez, Sergio and Hoffman, Matthew W and Pfau, David and Schaul, Tom and Shillingford, Brendan and de Freitas, Nando},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Learning to learn by gradient descent by gradient descent},
 url = {https://proceedings.neurips.cc/paper_files/paper/2016/file/fb87582825f9d28a8d42c5e5e5e8b23d-Paper.pdf},
 volume = {29},
 year = {2016}
}

@inproceedings{smith2025steer,
  title={Steer: Flexible robotic manipulation via dense language grounding},
  author={Smith, Laura and Irpan, Alex and Arenas, Montserrat Gonzalez and Kirmani, Sean and Kalashnikov, Dmitry and Shah, Dhruv and Xiao, Ted},
  booktitle={2025 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={16517--16524},
  year={2025},
  organization={IEEE}
}

@inproceedings{berkeley-function-calling-leaderboard,
  title={Berkeley Function Calling Leaderboard},
  author={Fanjia Yan and Huanzhi Mao and Charlie Cheng-Jie Ji and Tianjun Zhang and Shishir G. Patil and Ion Stoica and Joseph E. Gonzalez},
  year={2024},
  howpublished={\url{https://gorilla.cs.berkeley.edu/blogs/8_berkeley_function_calling_leaderboard.html}},
}

@article{belkhale2024rth,
  title={Rt-h: Action hierarchies using language},
  author={Belkhale, Suneel and Ding, Tianli and Xiao, Ted and Sermanet, Pierre and Vuong, Quon and Tompson, Jonathan and Chebotar, Yevgen and Dwibedi, Debidatta and Sadigh, Dorsa},
  journal={arXiv preprint arXiv:2403.01823},
  year={2024}
}

@article{lee2025molmoact,
  title={Molmoact: Action reasoning models that can reason in space},
  author={Lee, Jason and Duan, Jiafei and Fang, Haoquan and Deng, Yuquan and Liu, Shuo and Li, Boyang and Fang, Bohan and Zhang, Jieyu and Wang, Yi Ru and Lee, Sangho and others},
  journal={arXiv preprint arXiv:2508.07917},
  year={2025}
}

@article{intelligence2025pi05,
  title={$\pi_{0.5}$: a Vision-Language-Action Model with Open-World Generalization},
  author={Intelligence, Physical and Black, Kevin and Brown, Noah and Darpinian, James and Dhabalia, Karan and Driess, Danny and Esmail, Adnan and Equi, Michael and Finn, Chelsea and Fusai, Niccolo and others},
  journal={arXiv preprint arXiv:2504.16054},
  year={2025}
}

@article{shi2025hi,
  title={Hi robot: Open-ended instruction following with hierarchical vision-language-action models},
  author={Shi, Lucy Xiaoyang and Ichter, Brian and Equi, Michael and Ke, Liyiming and Pertsch, Karl and Vuong, Quan and Tanner, James and Walling, Anna and Wang, Haohuan and Fusai, Niccolo and others},
  journal={arXiv preprint arXiv:2502.19417},
  year={2025}
}

@misc{safe-vlms,
      title={Can AI Perceive Physical Danger and Intervene?}, 
      author={Abhishek Jindal and Dmitry Kalashnikov and Oscar Chang and Divya Garikapati and Anirudha Majumdar and Pierre Sermanet and Vikas Sindhwani},
      year={2025},
      eprint={2509.21651},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2509.21651}, 
}

@inproceedings{dasigi-etal-2021-dataset,
    title = "A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers",
    author = "Dasigi, Pradeep  and
      Lo, Kyle  and
      Beltagy, Iz  and
      Cohan, Arman  and
      Smith, Noah A.  and
      Gardner, Matt",
    editor = "Toutanova, Kristina  and
      Rumshisky, Anna  and
      Zettlemoyer, Luke  and
      Hakkani-Tur, Dilek  and
      Beltagy, Iz  and
      Bethard, Steven  and
      Cotterell, Ryan  and
      Chakraborty, Tanmoy  and
      Zhou, Yichao",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.365",
    doi = "10.18653/v1/2021.naacl-main.365",
    pages = "4599--4610",
    abstract = "Readers of academic research papers often read with the goal of answering specific questions. Question Answering systems that can answer those questions can make consumption of the content much more efficient. However, building such tools requires data that reflect the difficulty of the task arising from complex reasoning about claims made in multiple parts of a paper. In contrast, existing information-seeking question answering datasets usually contain questions about generic factoid-type information. We therefore present Qasper, a dataset of 5049 questions over 1585 Natural Language Processing papers. Each question is written by an NLP practitioner who read only the title and abstract of the corresponding paper, and the question seeks information present in the full text. The questions are then answered by a separate set of NLP practitioners who also provide supporting evidence to answers. We find that existing models that do well on other QA tasks do not perform well on answering these questions, underperforming humans by at least 27 F1 points when answering them from entire papers, motivating further research in document-grounded, information-seeking QA, which our dataset is designed to facilitate.",
}


@inproceedings{majumdar2024openeqa,
  title={OpenEQA: Embodied Question Answering in the Era of Foundation Models},
  author={Majumdar, Arjun and Ajay, Anurag and Zhang, Xiaohan and Putta, Pranav and Yenamandra, Sriram and Henaff, Mikael and Silwal, Sneha and Mcvay, Paul and Maksymets, Oleksandr and Arnaud, Sergio and others},
  booktitle={2nd Workshop on Mobile Manipulation and Embodied Intelligence at ICRA 2024},
  year={2024}
}

@misc{grok15v,
  author = "x.ai",
  title = "Grok-1.5 Vision Preview",
  url = "https://x.ai/blog/grok-1.5v"
}

@article{INR-081,
url = {http://dx.doi.org/10.1561/1500000081},
year = {2023},
volume = {17},
journal = {Foundations and Trends® in Information Retrieval},
title = {Conversational Information Seeking},
doi = {10.1561/1500000081},
issn = {1554-0669},
number = {3-4},
pages = {244-456},
author = {Hamed Zamani and Johanne R. Trippas and Jeff Dalton and Filip Radlinski}
}

@inproceedings{collins2014trec,
  title={{TREC} 2014 Web Track Overview.},
  author={Collins-Thompson, Kevyn and Macdonald, Craig and Bennett, Paul N. and Diaz, Fernando and Voorhees, Ellen M.},
  booktitle={Proceedings of the Twenty-Third Text REtrieval Conference (TREC 2014)},
  year={2014},
  url={https://trec.nist.gov/pubs/trec23/papers/overview-web.pdf}
}

@inproceedings{yilmaz2015overview,
  title={Overview of the {TREC} 2015 Tasks Track.},
  author={Yilmaz, Emine and Verma, Manisha and Mehrotra, Rishabh and Kanoulas, Evangelos and Carterette, Ben and Craswell, Nick},
  booktitle={Proceedings of the Twenty-Fourth Text REtrieval Conference (TREC 2015)},
  year={2015},
  url={https://trec.nist.gov/pubs/trec24/papers/Overview-T.pdf}
}

@article{10.1145/792550.792552,
author = {Broder, Andrei},
title = {A taxonomy of web search},
year = {2002},
issue_date = {Fall 2002},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {36},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/792550.792552},
doi = {10.1145/792550.792552},
abstract = {Classic IR (information retrieval) is inherently predicated on users searching for information, the so-called "information need". But the need behind a web search is often not informational -- it might be navigational (give me the url of the site I want to reach) or transactional (show me sites where I can perform a certain transaction, e.g. shop, download a file, or find a map). We explore this taxonomy of web searches and discuss how global search engines evolved to deal with web-specific needs.},
journal = {SIGIR Forum},
month = {sep},
pages = {3–10},
numpages = {8}
}

@inproceedings{10.1145/2911451.2914675,
author = {Carterette, Ben and Clough, Paul and Hall, Mark and Kanoulas, Evangelos and Sanderson, Mark},
title = {Evaluating Retrieval over Sessions: The {TREC} Session Track 2011-2014},
year = {2016},
isbn = {9781450340694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2911451.2914675},
doi = {10.1145/2911451.2914675},
abstract = {Information Retrieval (IR) research has traditionally focused on serving the best results for a single query - so-called ad hoc retrieval. However, users typically search iteratively, refining and reformulating their queries during a session. A key challenge in the study of this interaction is the creation of suitable evaluation resources to assess the effectiveness of IR systems over sessions. This paper describes the TREC Session Track, which ran from 2010 through to 2014, which focussed on forming test collections that included various forms of implicit feedback. We describe the test collections; a brief analysis of the differences between datasets over the years; and the evaluation results that demonstrate that the use of user session data significantly improved effectiveness.},
booktitle = {Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {685–688},
numpages = {4},
keywords = {evaluation, test collection, TREC session track},
location = {Pisa, Italy},
series = {SIGIR '16}
}

@inproceedings{clarke2020overview,
  title={Overview of the {TREC} 2020 Health Misinformation Track.},
  author={Clarke, Charles LA and Rizvi, Saira and Smucker, Mark D and Maistro, Maria and Zuccon, Guido},
  booktitle={Proceedings of the Twenty-Ninth Text REtrieval Conference (TREC 2020)},
  year={2020},
  url={https://trec.nist.gov/pubs/trec29/papers/OVERVIEW.HM.pdf}
}

@article{phuong2024,
  title={Evaluating Frontier Models for Dangerous Capabilities},
  author={Phuong, Mary and Aitchison, Matthew and Catt, Elliot and Cogan, Sarah and Kaskasoli, Alexandre and Krakovna, Victoria and Lindner, David and Rahtz, Matthew and Assael, Yannis and Hodkinson, Sarah and Howard, Heidi and Lieberum, Tom and Kumar, Ramana and Abi Raad, Maria and Webson, Albert and Ho, Lewis and Lin, Sharon and Farquhar, Sebastian and Hutter, Marcus and Deletang, Gregoire and Ruoss, Anian and El-Sayed, Seliem and Brown, Sasha and Dragan, Anca and Shah, Rohin and Dafoe, Allan and Shevlane, Toby},
  journal={ar{X}iv preprint:2403.13793},
  year={2024}
}

@inproceedings{wang2019detecting,
  title={Detecting "0-day" vulnerability: An empirical study of secret security patch in {OSS}},
  author={Wang, Xinda and Sun, Kun and Batcheller, Archer and Jajodia, Sushil},
  booktitle={IEEE/IFIP International Conference on Dependable Systems and Networks},
  pages={485--492},
  year={2019},
  organization={IEEE},
  url = "https://csis.gmu.edu/ksun/publications/secretpatch-dsn19.pdf"
}

@inproceedings{wang2021patchdb,
  title={Patch{DB}: A large-scale security patch dataset},
  author={Wang, Xinda and Wang, Shu and Feng, Pengbin and Sun, Kun and Jajodia, Sushil},
  booktitle={IEEE/IFIP International Conference on Dependable Systems and Networks},
  pages={149--160},
  year={2021},
  organization={IEEE}
}

@misc{2023_whitehouse_commitments,
  author = {{The White House}},
  title = {Ensuring Safe, Secure, and Trustworthy {AI}},
  url = {https://www.whitehouse.gov/wp-content/uploads/2023/07/Ensuring-Safe-Secure-and-Trustworthy-AI.pdf},
  year=2023,
  month=jul
}

@article{yang2023intercode,
  title={{InterCode}: Standardizing and Benchmarking Interactive Coding with Execution Feedback},
  author={Yang, John and Prabhakar, Akshara and Narasimhan, Karthik and Yao, Shunyu},
  month=jun,
  year={2023},
  journal = {ArXiv},
  url = {https://arxiv.org/abs/2306.14898}
}

@article{ding2024vulnerability,
  title={Vulnerability Detection with Code Language Models: How Far Are We?},
  author={Ding, Yangruibo and Fu, Yanjun and Ibrahim, Omniyyah and Sitawarin, Chawin and Chen, Xinyun and Alomair, Basel and Wagner, David and Ray, Baishakhi and Chen, Yizheng},
  journal={ar{X}iv preprint:2403.18624},
  year={2024}
}

@article{zhou2021spi,
  title={{SPI}: Automated identification of security patches via commits},
  author={Zhou, Yaqin and Siow, Jing Kai and Wang, Chenyu and Liu, Shangqing and Liu, Yang},
  journal={{ACM} Transactions on Software Engineering and Methodology},
  volume={31},
  number={1},
  pages={1--27},
  year={2021},
  publisher={ACM New York, NY}
}

@inproceedings{chen2023diversevul,
  title={{DiverseVul}: A new vulnerable source code dataset for deep learning based vulnerability detection},
  author={Chen, Yizheng and Ding, Zhoujie and Alowain, Lamya and Chen, Xinyun and Wagner, David},
  booktitle={International Symposium on Research in Attacks, Intrusions and Defenses},
  pages={654--668},
  year={2023},
  month = apr,
  url={https://arxiv.org/abs/2304.00409}
}

@misc{malaviya2024dolomites,
    title={DOLOMITES: Domain-Specific Long-Form Methodical Tasks},
    author={Chaitanya Malaviya and Priyanka Agrawal and Kuzman Ganchev and Pranesh Srinivasan and Fantine Huot and Jonathan Berant and Mark Yatskar and Dipanjan Das and Mirella Lapata and Chris Alberti},
    year={2024},
    eprint={2405.05938},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{carlini2024aligned,
      title={Are aligned neural networks adversarially aligned?}, 
      author={Nicholas Carlini and Milad Nasr and Christopher A. Choquette-Choo and Matthew Jagielski and Irena Gao and Anas Awadalla and Pang Wei Koh and Daphne Ippolito and Katherine Lee and Florian Tramer and Ludwig Schmidt},
      year={2024},
      eprint={2306.15447},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{glukhov2023llm,
  title={Rethinking LLM Censorship as a Security Problem},
  author={Glukhov, David and Shumailov, Ilia and Gal, Yarin and Papernot, Nicolas and Papyan, Vardan},
  journal={International Conference on Machine Learning (ICML)},
  year={2024}
}
@article{eloundou2023gpts,
  title={Gpts are gpts: An early look at the labor market impact potential of large language models},
  author={Eloundou, Tyna and Manning, Sam and Mishkin, Pamela and Rock, Daniel},
  journal={arXiv preprint arXiv:2303.10130},
  year={2023}
}
@inproceedings{felten2018method,
  title={A method to link advances in artificial intelligence to occupational abilities},
  author={Felten, Edward W and Raj, Manav and Seamans, Robert},
  booktitle={AEA Papers and Proceedings},
  volume={108},
  pages={54--57},
  year={2018},
  organization={American Economic Association 2014 Broadway, Suite 305, Nashville, TN 37203}
}

@misc{MAG,
    author = {Macknight and Aung and Gomes},
    howpublished = "Personal Communication"
}

@misc{visser2021kalamangcorpus,
	author = {Visser, Eline},
	title = {The {K}alamang collection: an archive of linguistic and cultural material from {K}aras},
	year = {2020},
	collector = {Eline Visser},
	howpublished = {Lund: Humlab, Lund University Humanities Lab},
	url = {http://hdl.handle.net/10050/00-0000-0000-0003-C3E8-1}
	}

@article{kahneman2011thinking,
  title={Thinking, fast and slow},
  author={Kahneman, Daniel},
  journal={Farrar, Straus and Giroux},
  year={2011}
}

@article{brohan2023rt,
  title={Rt-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2307.15818},
  year={2023}
}

@InProceedings{pmlr-v229-zitkovich23a,
  title = 	 {{RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control}},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  booktitle = 	 {Proceedings of The 7th Conference on Robot Learning},
  pages = 	 {2165--2183},
  year = 	 {2023},
  volume = 	 {229},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--09 Nov},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v229/zitkovich23a/zitkovich23a.pdf},
  url = 	 {https://proceedings.mlr.press/v229/zitkovich23a.html},
  abstract = 	 {We study how vision-language models trained on Internet-scale data can be incorporated directly into end-to-end robotic control to boost generalization and enable emergent semantic reasoning. Our goal is to enable a single end-to-end trained model to both learn to map robot observations to actions and enjoy the benefits of large-scale pretraining on language and vision-language data from the web. To this end, we propose to co-fine-tune state-of-the-art vision-language models on both robotic trajectory data and Internet-scale vision-language tasks, such as visual question answering. In contrast to other approaches, we propose a simple, general recipe to achieve this goal: in order to fit both natural language responses and robotic actions into the same format, we express the actions as text tokens and incorporate them directly into the training set of the model in the same way as natural language tokens. We refer to such category of models as vision-language-action models (VLA) and instantiate an example of such a model, which we call RT-2. Our extensive evaluation (6k evaluation trials) shows that our approach leads to performant robotic policies and enables RT-2 to obtain a range of emergent capabilities from Internet-scale training. This includes significantly improved generalization to novel objects, the ability to interpret commands not present in the robot training data (such as placing an object onto a particular number or icon), and the ability to perform rudimentary reasoning in response to user commands (such as picking up the smallest or largest object, or the one closest to another object). We further show that incorporating chain of thought reasoning allows RT-2 to perform multi-stage semantic reasoning, for example figuring out which object to pick up for use as an improvised hammer (a rock), or which type of drink is best suited for someone who is tired (an energy drink).}
}


@article{kim24openvla,
    title={OpenVLA: An Open-Source Vision-Language-Action Model},
    author={{Moo Jin} Kim and Karl Pertsch and Siddharth Karamcheti and Ted Xiao and Ashwin Balakrishna and Suraj Nair and Rafael Rafailov and Ethan Foster and Grace Lam and Pannag Sanketi and Quan Vuong and Thomas Kollar and Benjamin Burchfiel and Russ Tedrake and Dorsa Sadigh and Sergey Levine and Percy Liang and Chelsea Finn},
    journal = {arXiv preprint arXiv:2406.09246},
    year={2024},
}

@InProceedings{pmlr-v270-kim25c,
  title = 	 {Open{VLA}: An Open-Source {V}ision-{L}anguage-{A}ction Model},
  author =       {Kim, Moo Jin and Pertsch, Karl and Karamcheti, Siddharth and Xiao, Ted and Balakrishna, Ashwin and Nair, Suraj and Rafailov, Rafael and Foster, Ethan P and Sanketi, Pannag R and Vuong, Quan and Kollar, Thomas and Burchfiel, Benjamin and Tedrake, Russ and Sadigh, Dorsa and Levine, Sergey and Liang, Percy and Finn, Chelsea},
  booktitle = 	 {Proceedings of The 8th Conference on Robot Learning},
  pages = 	 {2679--2713},
  year = 	 {2025},
  volume = 	 {270},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--09 Nov},
  publisher =    {PMLR},
  pdf = 	 {https://raw.githubusercontent.com/mlresearch/v270/main/assets/kim25c/kim25c.pdf},
  url = 	 {https://proceedings.mlr.press/v270/kim25c.html},
}

@inproceedings{singh2022optimizing,
  title={Optimizing trajectories with closed-loop dynamic SQP},
  author={Singh, Sumeet and Slotine, Jean-Jacques and Sindhwani, Vikas},
  booktitle={2022 International Conference on Robotics and Automation (ICRA)},
  pages={5249--5254},
  year={2022},
  organization={IEEE}
}

@misc{vemprala2023chatgptrobotics,
      title={{C}hat{GPT} for {R}obotics: Design Principles and Model Abilities}, 
      author={Sai Vemprala and Rogerio Bonatti and Arthur Bucker and Ashish Kapoor},
      year={2023},
      eprint={2306.17582},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2306.17582}, 
}

@article{wen2023any,
  title={Any-point trajectory modeling for policy learning},
  author={Wen, Chuan and Lin, Xingyu and So, John and Chen, Kai and Dou, Qi and Gao, Yang and Abbeel, Pieter},
  journal={2024 Robotics: Science and Systems},
  year={2024}
}

 @article{Zawalski24-ecot,
    title={Robotic Control via Embodied Chain-of-Thought Reasoning},
    author={Michał Zawalski and William Chen and Karl Pertsch and Oier Mees and Chelsea Finn and Sergey Levine},
    journal={Conference on Robot Learning (CoRL) 2024},
    year={2024}
} 

@inproceedings{liang2023code,
  title={Code as policies: Language model programs for embodied control},
  author={Liang, Jacky and Huang, Wenlong and Xia, Fei and Xu, Peng and Hausman, Karol and Ichter, Brian and Florence, Pete and Zeng, Andy},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={9493--9500},
  year={2023},
  organization={IEEE}
}

@misc{gu2023rttrajectoryrobotictaskgeneralization,
  title="{RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches}", 
  author={Jiayuan Gu and Sean Kirmani and Paul Wohlhart and Yao Lu and Montserrat Gonzalez Arenas and Kanishka Rao and Wenhao Yu and Chuyuan Fu and Keerthana Gopalakrishnan and Zhuo Xu and Priya Sundaresan and Peng Xu and Hao Su and Karol Hausman and Chelsea Finn and Quan Vuong and Ted Xiao},
  year={2023},
  eprint={2311.01977},
  archivePrefix={arXiv},
  primaryClass={cs.RO},
  url={https://arxiv.org/abs/2311.01977}, 
}

@article{sundaresan2024rt,
  title={RT-Sketch: Goal-Conditioned Imitation Learning from Hand-Drawn Sketches},
  author={Sundaresan, Priya and Vuong, Quan and Gu, Jiayuan and Xu, Peng and Xiao, Ted and Kirmani, Sean and Yu, Tianhe and Stark, Michael and Jain, Ajinkya and Hausman, Karol and others},
  year={2024}
}

@inproceedings{rukhovich2022imvoxelnet,
  title     = {{ImVoxelNet}: Image to Voxels Projection for Monocular and Multi-View 3D Object Detection},
  author    = {Rukhovich, Danila and Vorontsova, Anna and Konushin, Victor},
  booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
  pages     = {1172--1181},
  year      = {2022},
  doi       = {10.1109/WACV51458.2022.00120}
}

@inproceedings{zhang2021holistic3d,
  title     = {Holistic 3{D} Scene Understanding from a Single Image with Implicit Representation},
  author    = {Zhang, Jiayi and Sui, Yi and Shi, Bo and Ang Jr, Marcelo H. and Lee, Gim Hee},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages     = {8867--8876},
  year      = {2021},
  doi       = {10.1109/CVPR46437.2021.00875}
}

@inproceedings{nie2020total3dunderstanding,
  title     = {{Total3DUnderstanding}: Joint Layout, Object Pose and Mesh Reconstruction for Indoor Scenes from a Single Image},
  author    = {Nie, Yinyu and Han, Xiaoguang and Guo, Sibo and Zheng, Yujing and Chang, Jian and Zhang, Juyong and Yu, Shihong},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages     = {55--64},
  year      = {2020},
  doi       = {10.1109/CVPR42600.2020.00014}
}

@misc{aloha2,
      title={{ALOHA} 2: An Enhanced Low-Cost Hardware for Bimanual Teleoperation}, 
      author={ALOHA-2-Team and Jorge Aldaco and Travis Armstrong and Robert Baruch and Jeff Bingham and Sanky Chan and Kenneth Draper and Debidatta Dwibedi and Chelsea Finn and Pete Florence and Spencer Goodrich and Wayne Gramlich and Torr Hage and Alexander Herzog and Jonathan Hoech and Thinh Nguyen and Ian Storz and Baruch Tabanpour and Leila Takayama and Jonathan Tompson and Ayzaan Wahid and Ted Wahrburg and Sichun Xu and Sergey Yaroshenko and Kevin Zakka and Tony Z. Zhao},
      year={2024},
      eprint={2405.02292},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2405.02292}, 
}

@InProceedings{pmlr-v270-zhao25b,
  title = 	 "{ALOHA Unleashed: A Simple Recipe for Robot Dexterity}",
  author =       {Zhao, Tony Z. and Tompson, Jonathan and Driess, Danny and Florence, Pete and Ghasemipour, Seyed Kamyar Seyed and Finn, Chelsea and Wahid, Ayzaan},
  booktitle = 	 {Proceedings of The 8th Conference on Robot Learning},
  pages = 	 {1910--1924},
  year = 	 {2025},
  volume = 	 {270},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--09 Nov},
  publisher =    {PMLR},
  pdf = 	 {https://raw.githubusercontent.com/mlresearch/v270/main/assets/zhao25b/zhao25b.pdf},
  url = 	 {https://proceedings.mlr.press/v270/zhao25b.html},
  abstract = 	 {Recent work has shown promising results for learning end-to-end robot policies using imitation learning. In this work we address the question of how far can we push imitation learning for challenging dexterous manipulation tasks. We show that a simple recipe of large scale data collection on the ALOHA 2 platform, combined with expressive models such as Diffusion Policies, can be effective in learning challenging bimanual manipulation tasks involving deformable objects and complex contact rich dynamics. We demonstrate our recipe on 5 challenging real-world and 3 simulated tasks and demonstrate improved performance over state-of-the-art baselines.}
}

@InProceedings{Zhao-RSS-23, 
    author    = {Tony Z. Zhao AND Vikash Kumar AND Sergey Levine AND Chelsea Finn}, 
    title     = {{Learning Fine-Grained Bimanual Manipulation with Low-Cost Hardware}}, 
    booktitle = {Proceedings of Robotics: Science and Systems}, 
    year      = {2023}, 
    address   = {Daegu, Republic of Korea}, 
    month     = {July}, 
    doi       = {10.15607/RSS.2023.XIX.016} 
} 

@article{chi2024diffusionpolicy,
	author = {Cheng Chi and Zhenjia Xu and Siyuan Feng and Eric Cousineau and Yilun Du and Benjamin Burchfiel and Russ Tedrake and Shuran Song},
	title ={Diffusion Policy: Visuomotor Policy Learning via Action Diffusion},
	journal = {The International Journal of Robotics Research},
	year = {2024},
}

@misc{black2024pi0,
      title={$\pi_0$: A Vision-Language-Action Flow Model for General Robot Control}, 
      author={Kevin Black and Noah Brown and Danny Driess and Adnan Esmail and Michael Equi and Chelsea Finn and Niccolo Fusai and Lachy Groom and Karol Hausman and Brian Ichter and Szymon Jakubczak and Tim Jones and Liyiming Ke and Sergey Levine and Adrian Li-Bell and Mohith Mothukuri and Suraj Nair and Karl Pertsch and Lucy Xiaoyang Shi and James Tanner and Quan Vuong and Anna Walling and Haohuan Wang and Ury Zhilinsky},
      year={2024},
      eprint={2410.24164},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.24164}, 
}

@inproceedings{brazil2023omni3d,
  title={Omni3d: A large benchmark and model for 3d object detection in the wild},
  author={Brazil, Garrick and Kumar, Abhinav and Straub, Julian and Ravi, Nikhila and Johnson, Justin and Gkioxari, Georgia},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={13154--13164},
  year={2023}
}

@article{kimble2020benchmarking,
  title={Benchmarking protocols for evaluating small parts robotic assembly systems},
  author={Kimble, Kenneth and Van Wyk, Karl and Falco, Joe and Messina, Elena and Sun, Yu and Shibata, Mizuho and Uemura, Wataru and Yokokohji, Yasuyoshi},
  journal={IEEE robotics and automation letters},
  volume={5},
  number={2},
  pages={883--889},
  year={2020},
  publisher={IEEE}
}

@article{beyer2024paligemma,
      title={{PaliGemma: A versatile 3B VLM for transfer}},
      author={Lucas Beyer and Andreas Steiner and André Susano Pinto and Alexander Kolesnikov and Xiao Wang and Daniel Salz and Maxim Neumann and Ibrahim Alabdulmohsin and Michael Tschannen and Emanuele Bugliarello and Thomas Unterthiner and Daniel Keysers and Skanda Koppula and Fangyu Liu and Adam Grycner and Alexey Gritsenko and Neil Houlsby and Manoj Kumar and Keran Rong and Julian Eisenschlos and Rishabh Kabra and Matthias Bauer and Matko Bošnjak and Xi Chen and Matthias Minderer and Paul Voigtlaender and Ioana Bica and Ivana Balazevic and Joan Puigcerver and Pinelopi Papalampidi and Olivier Henaff and Xi Xiong and Radu Soricut and Jeremiah Harmsen and Xiaohua Zhai},
      year={2024},
      journal={arXiv preprint arXiv:2407.07726}
}

@inproceedings{RadfordKHRGASAM21,
  author       = {Alec Radford and
                  Jong Wook Kim and
                  Chris Hallacy and
                  Aditya Ramesh and
                  Gabriel Goh and
                  Sandhini Agarwal and
                  Girish Sastry and
                  Amanda Askell and
                  Pamela Mishkin and
                  Jack Clark and
                  Gretchen Krueger and
                  Ilya Sutskever},
  title        = {Learning Transferable Visual Models From Natural Language Supervision},
  booktitle    = {Proceedings of the 38th International Conference on Macxhine Learning,
                  {ICML} 2021, 18-24 July 2021, Virtual Event},
  series       = {Proceedings of Machine Learning Research},
  volume       = {139},
  pages        = {8748--8763},
  publisher    = {{PMLR}},
  year         = {2021},
  url          = {http://proceedings.mlr.press/v139/radford21a.html},
}

@article{proc4gem,
  title={{Proc4Gem}: Foundation models for physical agency through procedural generation},
  author={Lin, Yixin and Humplik, Jan and Huang, Sandy H. and Hasenclever, Leonard and Romano, Francesco and Saliceti, Stefano and Zheng, Daniel and Chen, Jose Enrique and Barros, Catarina and Collister, Adrian and Young, Matt and Dostmohamed, Adil and Moran, Ben and Caluwaerts, Ken and Giustina, Marissa and Moore, Joss and Connell, Kieran and Nori, Francesco and Heess, Nicolas and Bohez, Steven and Byravan, Arunkumar},
  journal={arXiv preprint},
  url={https://sites.google.com/view/proc4gem},
  month={March},
  year={2025},
}

@inproceedings{chen2024spatialvlm,
  title={Spatialvlm: Endowing vision-language models with spatial reasoning capabilities},
  author={Chen, Boyuan and Xu, Zhuo and Kirmani, Sean and Ichter, Brain and Sadigh, Dorsa and Guibas, Leonidas and Xia, Fei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14455--14465},
  year={2024}
}

@article{hwang2024emma,
  title={Emma: End-to-end multimodal model for autonomous driving},
  author={Hwang, Jyh-Jing and Xu, Runsheng and Lin, Hubert and Hung, Wei-Chih and Ji, Jingwei and Choi, Kristy and Huang, Di and He, Tong and Covington, Paul and Sapp, Benjamin and others},
  journal={arXiv preprint arXiv:2410.23262},
  year={2024}
}

@misc{apollo,
    title = {{Apptronik Apollo General Purpose Humanoid Robot}},
    author = "Apptronik",
    howpublished = "https://apptronik.com/apollo",
    year = {2025}
}

@misc{fr3,
    title = {{Franka Research 3}},
    author = "Franka",
    howpublished = "https://franka.de/franka-research-3-arm",
    year = {2025}
}


@misc{nistassemblyboards,
    title = {{Assembly Performance Metrics and Test Methods}},
    author = "NIST",
    howpublished = "https://www.nist.gov/el/intelligent-systems-division-73500/robotic-grasping-and-manipulation-assembly/assembly",
    year = {2025}
}

@INPROCEEDINGS{6386109,
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
  title={MuJoCo: A physics engine for model-based control}, 
  year={2012},
  volume={},
  number={},
  pages={5026-5033},
  keywords={Engines;Optimization;Computational modeling;Heuristic algorithms;Dynamics;Mathematical model},
  doi={10.1109/IROS.2012.6386109}}

@article{lin2025onetwovla,
  title={OneTwoVLA: A Unified Vision-Language-Action Model with Adaptive Reasoning},
  author={Lin, Fanqi and Nai, Ruiqian and Hu, Yingdong and You, Jiacheng and Zhao, Junming and Gao, Yang},
  journal={arXiv preprint arXiv:2505.11917},
  year={2025}
}
@article{huang2025thinkact,
  title={Thinkact: Vision-language-action reasoning via reinforced visual latent planning},
  author={Huang, Chi-Pin and Wu, Yueh-Hua and Chen, Min-Hung and Wang, Yu-Chiang Frank and Yang, Fu-En},
  journal={arXiv preprint arXiv:2507.16815},
  year={2025}
}
@inproceedings{zitkovich2023rt,
  title={Rt-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Zitkovich, Brianna and Yu, Tianhe and Xu, Sichun and Xu, Peng and Xiao, Ted and Xia, Fei and Wu, Jialin and Wohlhart, Paul and Welker, Stefan and Wahid, Ayzaan and others},
  booktitle={Conference on Robot Learning},
  pages={2165--2183},
  year={2023},
  organization={PMLR}
}
@article{bjorck2025gr00t,
  title={Gr00t n1: An open foundation model for generalist humanoid robots},
  author={Bjorck, Johan and Casta{\~n}eda, Fernando and Cherniadev, Nikita and Da, Xingye and Ding, Runyu and Fan, Linxi and Fang, Yu and Fox, Dieter and Hu, Fengyuan and Huang, Spencer and others},
  journal={arXiv preprint arXiv:2503.14734},
  year={2025}
}
@article{wen2025dexvla,
  title={Dexvla: Vision-language model with plug-in diffusion expert for general robot control},
  author={Wen, Junjie and Zhu, Yichen and Li, Jinming and Tang, Zhibin and Shen, Chaomin and Feng, Feifei},
  journal={arXiv preprint arXiv:2502.05855},
  year={2025}
}
@article{li2023interactive,
  title={Interactive task planning with language models},
  author={Li, Boyi and Wu, Philipp and Abbeel, Pieter and Malik, Jitendra},
  journal={arXiv preprint arXiv:2310.10645},
  year={2023}
}
@article{chen2024automating,
  title={Automating robot failure recovery using vision-language models with optimized prompts},
  author={Chen, Hongyi and Yao, Yunchao and Liu, Ruixuan and Liu, Changliu and Ichnowski, Jeffrey},
  journal={arXiv preprint arXiv:2409.03966},
  year={2024}
}
@inproceedings{zhi2025closed,
  title={Closed-loop open-vocabulary mobile manipulation with gpt-4v},
  author={Zhi, Peiyuan and Zhang, Zhiyuan and Zhao, Yu and Han, Muzhi and Zhang, Zeyu and Li, Zhitian and Jiao, Ziyuan and Jia, Baoxiong and Huang, Siyuan},
  booktitle={2025 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={4761--4767},
  year={2025},
  organization={IEEE}
}