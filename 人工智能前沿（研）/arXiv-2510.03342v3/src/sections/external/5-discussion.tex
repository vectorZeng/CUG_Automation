\section{Discussion}

This work presents Gemini Robotics 1.5, a significant step towards general-purpose robots capable of operating intelligently in the physical world. By combining the power of an advanced Embodied Reasoning model with a general Vision-Language-Action model, we have made significant progress in tackling key bottlenecks in robot learning and generalization. Our core contribution lies in three major innovations:

\begin{itemize}
    \item \textbf{Thinking VLA:} We have shown that enabling the VLA model to "think before acting" through a multi-level internal monologue notably improves its ability to handle more complex, multi-step tasks.
    \item \textbf{Learning across different robot embodiments:} We have shown that \grlatest{} can successfully learn from heterogeneous datasets, including data from across different robot platforms, and transfer learned skills between them.  This breakthrough accelerates learning in the presence of the data scarcity problem that has long hindered the field, accelerating progress towards generalist robots.
    \item \textbf{State-of-the-Art Embodied Reasoning:} The \grlatestER{} model establishes a new state of the art for a wide range of embodied reasoning tasks. Its performance on tasks like visual and spatial thinking, task planning, progress estimation, and success detection is critical for robust, real-world robotic applications. 
\end{itemize}

\smallskip \noindent This tech report demonstrates that the organic combination of these three contributions offers a compelling path to a new generation of general-purpose robots. Embodied thinking provides the intelligence to decompose long-horizon tasks, but this intelligence is only valuable when it can be translated into successful executions, empowered by our capable and general VLA model. This VLA is, in turn, able to share knowledge across different robot embodiments, which can unlock the immense amount of data collected by the entire robotics community. Finally, the system's state-of-the-art embodied reasoning capabilities enhance the robot's perception, semantic understanding, and planning for complex tasks that require both information gathering and multi-step reasoning. Together, these elements form a complete and powerful agentic system, paving the way for robots that can operate with human-like intelligence, adaptability, and safety in complex and dynamic environments.

\smallskip \noindent While Gemini Robotics 1.5 represents a major milestone, this work also highlights several avenues for future research. An important next step is to leverage more scalable data sources beyond traditional robot action data, such as real-world human videos and synthetic videos. Our architectural changes in GR 1.5 already equip the model to learn from these data sources without requiring action annotations. Future efforts will focus on learning from publicly available low-quality video corpora, among other data sources, to further mitigate the data scarcity problem. Additionally, although GR 1.5 demonstrates a new level of generalization, its dexterity remains on par with the previous generation. We will explore new architectures and training methods, such as reinforcement learning, to enhance the robot's dexterity without sacrificing its generality, allowing it to perform more intricate and precise manipulations.