General-purpose robots need a deep understanding of the physical world, advanced reasoning, and general and dexterous control. This report introduces the latest generation of the \grlegacy{} model family: \grlatest{}, a multi-embodiment Vision-Language-Action (VLA) model, and \grlatestER{}, a state-of-the-art Embodied Reasoning (ER) model. We are bringing together three major innovations. First, \grlatest{} features a novel architecture and a Motion Transfer (MT) mechanism, which enables it to learn from heterogeneous, multi-embodiment robot data and makes the VLA more general.
Second, \grlatest{} interleaves actions with a multi-level internal reasoning process in natural language. This enables the robot to ``think before acting'' and notably improves its ability to decompose and execute complex, multi-step tasks, and also makes the robot's behavior more interpretable to the user.
Third, \grlatestER{} establishes a new state-of-the-art for embodied reasoning, i.e., for reasoning capabilities that are critical for robots, such as visual and spatial understanding, task planning, and progress estimation. Together, this family of models takes us a step towards an era of physical agentsâ€”enabling robots to perceive, think and then act so they can solve complex multi-step tasks.
