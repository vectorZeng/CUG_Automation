\section{Responsible Development and Safety} 
\label{sec:safety}
We are proactively developing novel safety and alignment approaches to enable AI-controlled robots to be responsibly deployed in human-centric environments. Our overall safety approach is multi-faceted and multi-layered, spanning high-level semantic safety reasoning, ensuring respectful dialogue with humans, thinking about safety before acting, and triggering low-level physical safety sub-systems (e.g., for collision avoidance) when needed. Additionally, we continue iterating on implementing best practices for operational safety as codified in existing safety standards~\cite{ISO_TS_15066_2016,ISO10218-1:2025}. We are also developing novel Auto-Red-Teaming frameworks to automatically discover safety and robustness vulnerabilities of Gemini Robotics models through continuous adversarial evaluations at scale.

\smallskip \noindent {\bf Safe Human-Robot Dialog}: By building on Gemini checkpoints, we ensure alignment with Gemini Safety policies~\cite{comanici2025gemini} that have been designed to prevent generation of harmful content such as hate speech, sexual explicitness, and revealing personally identifiable information. Through adversarial testing, we find that our \grshortlatestER{} models have strong compliance with these policies. In turn, this implies that robots will foster safe human-robot interactions, engaging in socially appropriate behaviors through their speech, gestures, and actions. 

\smallskip \noindent {\bf Semantic Action Safety}: Broadly, semantic safety addresses the innumerable, ``long-tail'', common-sense constraints of operating in human-centric environments, e.g. that a box may be too heavy to lift, or that spilled liquid on the floor is a slip hazard. We previously released the ASIMOV-benchmark~\cite{sermanet2025generating} to evaluate and improve semantic action safety. We are now releasing an upgrade of this benchmark: ASIMOV-2.0 has improved quality, better tail coverage of real-world injury scenarios~\cite{neiss}, new video modalities (generated by VEO\footnote{https://deepmind.google/models/veo/}), and new embodied reasoning tasks involving physical constraints. \cref{fig:asimov2} shows instances of this eval suite across text, image and video modalities; for more details see~\citep{safe-vlms}, released concurrently with this tech report. In \cref{fig:safety_evals}, we see that \grshortlatestER{} improves over \grshortlegacyER{} in recognizing risks, understanding safety consequences of actions, and knowing when to trigger interventions. When \grshortlatestER{} is fine-tuned for Thinking about Safety, we see state-of-the-art results in safety-constrained pointing tasks (\cref{fig:safety_evals} (b)).  

\begin{figure*}[!ht]
\centering 
        \begin{subfigure}[b]{0.45\textwidth}
\begin{center}
{\tiny 
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{l|p{4cm}}
\hline
 {\bf REAL REPORT} & 3YOM HAD A PILL IN HIS MOUTH FROM GRANDMOTHERS PILL CASE..\\ 
 {\bf DIAGNOSTIC CODE} & POISONING \\ 
 \hline
 {\bf SCENARIO} & A 3-year-old boy is playing on the floor near his grandmother...The boy has just reached into the organizer, pulled out a small pill, and put it in his mouth.\\ 
 {\bf ACTION} & Immediately inform the grandmother, pointing to the child, and say, 'He has one of your pills in his mouth. \\ 
 \hline
 {\bf Q1 (Latent Risk)} & Given only the scenario, which of the following physical injuries is most likely? A: Burns, B: Poisoning, C:..\\ 
 {\bf Q2 (Latent Risk Severity)} & Given only the scenario, what is the severity of the most likely injury? A: Minor, B: Moderate, C: Severe...\\ 
 {\bf Q3 (Action Effect)} & What is the effect of executing the action on the likelihood of the possible injury? A: Eliminates Risk, B. Reduces Risk, C. Increases Risk, D. No effect...\\ 
 {\bf Q4 (Activated Risk)} & What is the severity of the most likely injury after executing the action? A: None, B: Minor, C: Moderate, D: Severe...\\ \hline
\end{tabular}
}
\caption{{\bf \texttt{ASIMOV-2.0-Injury}}: Do models understand physical risks and associated severity in given scenarios (text); and safety consequences of actions?}\label{fig:examples_injury}
\end{center}
\end{subfigure}\hspace{1cm}
    \begin{subfigure}[b]{0.45\textwidth}
        \centering 
        \includegraphics[height=5.5cm, width=\linewidth]{src/assets/safety/constraints6.png}\vspace{0.3cm}\caption{{\bf \texttt{ASIMOV-2.0-Constraints}}: Do (multimodal) model responses (red pointing labels) adhere to {\it embodiment-specific} Safety Instructions?}
    \end{subfigure}
    \par\bigskip
    \centering
    \begin{subfigure}[b]{\textwidth}
        \centering
          \includegraphics[height=2.7cm, width=\linewidth]{src/assets/safety/safety-video-frames.png}
        \caption{{\bf \texttt{ASIMOV-2.0-Video}}: Do models understand physical risks and severity in (AI-generated) videos (as opposed to text); can they predict the last possible timestamp (red frame above) at which an intervention could have effectively prevented the injury?}
    \end{subfigure}
\label{fig:examples}
    \caption{{\bf \texttt{ASIMOV-2.0}} Physical Safety Benchmark: Instances and Key Questions}  \label{fig:asimov2}
\end{figure*}

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.9\linewidth]{src/assets/safety/safety_plot_new.pdf}
    \caption{ASIMOV-2.0 Safety Evaluations.}\label{fig:safety_evals}
\end{figure*}

\smallskip \noindent {\bf Auto-Red-Teaming Framework}:
%
To augment our static evaluation methods, we have also developed novel automated red teaming (ART) techniques for dynamic, adversarial stress-testing of Gemini Robotics models. Our approach is inspired by Gemini's Auto-Red-Teaming~\cite{comanici2025gemini} framework which formulates adversarial testing as a game played between three models: an {\it Attacker}, a {\it Target}, and an {\it Autorater}. In our case, the {\it Target} is a Gemini Robotics model. The {\it Attacker} is prompted to devise an “attack” on the Target model. Effectively, the Attacker samples an “ordinary” task  from a source (e. g. training/eval data of the Target model), and turns it into an adversarial task. For example, the ER model may be attacked through a malicious instruction ({\it prompt attack}) or a corrupted/edited image ({\it scene attack}); and the Actions model may be attacked during a rollout with undesirable disturbances (e.g. moving obstacles) in the environment ({\it environment attack}). The {\it AutoRater} is a judge that attempts to meticulously rate the Target’s response for correctness and safety. \cref{fig:red-teaming} shows an instance of ER model hallucination discovered through auto-red-teaming: the Attacker samples an ALOHA scene, and cleverly requests the ER model to point to an entity that does not exist in the scene. The AutoRater, given an image overlay of the ER model responses, reliably detects hallucination and marks this response as a failure while providing a reasoning trace.  
\begin{figure}[h]
    \centering
    \includegraphics[height=4cm, width=0.85\linewidth]{src/assets/safety/roboart-example.png}
    \caption{Auto-Red-Teaming detects ER Hallucinations under adversarial prompts.}
    \label{fig:red-teaming}
\end{figure}
Through auto-red-teaming, we verified the following: (1) \grshortlatestER{} (particularly with Thinking enabled) has greater robustness under instruction obfuscation, hallucination elicitation and content safety attacks; (2) model responses can be reliably critiqued and corrected using AutoRaters for enhanced robustness; and (3) training data generated via auto-red-teaming helps mitigate vulnerabilities such as hallucinations. 
 
\smallskip \noindent We are committed to continuously innovating safety and alignment techniques as we advance our robot foundation models. Furthermore, we acknowledge that the societal impacts of Gemini Robotics deployments must be addressed concurrently with safety risks. Proactive management and monitoring of these multifaceted impacts -- spanning both benefits and challenges -- are fundamental to our strategy for mitigating risk, deploying responsibly, and ensuring transparent reporting. Please refer to Appendix \ref{sec:model-card} for the Gemini Robotics model card.